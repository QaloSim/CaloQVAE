{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc755bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: DWAVE_API_TOKEN=DEV-1ba72787de429d2af12464f7753c10b9ff6945ad\n",
      "Tue Jul 16 19:17:04 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.67                 Driver Version: 550.67         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A6000               Off |   00000000:1B:00.0 Off |                  Off |\n",
      "| 30%   51C    P2            102W /  300W |    9483MiB /  49140MiB |     28%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000               Off |   00000000:1C:00.0 Off |                  Off |\n",
      "| 30%   60C    P2            178W /  300W |   33052MiB /  49140MiB |     99%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA RTX A6000               Off |   00000000:4F:00.0 Off |                  Off |\n",
      "| 35%   63C    P2            114W /  300W |   31414MiB /  49140MiB |     33%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA RTX A6000               Off |   00000000:50:00.0 Off |                  Off |\n",
      "| 30%   45C    P8             23W /  300W |   11473MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   4  NVIDIA RTX A6000               Off |   00000000:9C:00.0 Off |                  Off |\n",
      "| 30%   50C    P2            238W /  300W |   21895MiB /  49140MiB |     90%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   5  NVIDIA RTX A6000               Off |   00000000:9D:00.0 Off |                  Off |\n",
      "| 30%   57C    P2            242W /  300W |   46892MiB /  49140MiB |    100%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   1831796      C   /usr/bin/python                               260MiB |\n",
      "|    0   N/A  N/A   2201692      C   python                                       9212MiB |\n",
      "|    1   N/A  N/A   1831796      C   /usr/bin/python                              4190MiB |\n",
      "|    1   N/A  N/A   3317040      C   python                                      14424MiB |\n",
      "|    1   N/A  N/A   3325157      C   python                                      14424MiB |\n",
      "|    2   N/A  N/A   3729025      C   python                                      15702MiB |\n",
      "|    2   N/A  N/A   3740802      C   python                                      15702MiB |\n",
      "|    3   N/A  N/A   2089823      C   python                                      11466MiB |\n",
      "|    4   N/A  N/A    494585      C   python                                      21102MiB |\n",
      "|    4   N/A  N/A   2277359      C   /usr/bin/python                               782MiB |\n",
      "|    5   N/A  N/A    820926      C   python                                      46884MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "# %env CUDA_VISIBLE_DEVICES=4\n",
    "%env DWAVE_API_TOKEN=DEV-1ba72787de429d2af12464f7753c10b9ff6945ad\n",
    "!nvidia-smi\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca9bb0e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hydra\n",
    "from hydra.utils import instantiate\n",
    "from hydra import initialize, compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06eecf26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "os.chdir('/home/' + getpass.getuser() + '/CaloQVAE/')\n",
    "sys.path.insert(1, '/home/' + getpass.getuser() + '/CaloQVAE/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "713dff99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[19:17:08.576]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mCaloQVAE                                          \u001b[0mWillkommen!\n",
      "\u001b[1m[19:17:08.578]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mCaloQVAE                                          \u001b[0mLoading configuration.\n"
     ]
    }
   ],
   "source": [
    "#external libraries\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits\n",
    "torch.manual_seed(32)\n",
    "import numpy as np\n",
    "np.random.seed(32)\n",
    "import matplotlib.pyplot as plt\n",
    "import hydra\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import time\n",
    "\n",
    "# PyTorch imports\n",
    "from torch import device, load, save\n",
    "from torch.nn import DataParallel\n",
    "from torch.cuda import is_available\n",
    "\n",
    "# Add the path to the parent directory to augment search for module\n",
    "sys.path.append(os.getcwd())\n",
    "    \n",
    "# Weights and Biases\n",
    "import wandb\n",
    "\n",
    "#self defined imports\n",
    "from CaloQVAE import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2c4521a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[19:17:11.117]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mnumexpr.utils                                     \u001b[0mNote: detected 96 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "\u001b[1m[19:17:11.119]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mnumexpr.utils                                     \u001b[0mNote: NumExpr detected 96 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "\u001b[1m[19:17:11.120]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mnumexpr.utils                                     \u001b[0mNumExpr defaulting to 8 threads.\n",
      "2024-07-16 19:17:11,891 dwave.cloud \u001b[1;95mINFO \u001b[1;0m MainThread Log level for 'dwave.cloud' namespace set to 0\n",
      "\u001b[1m[19:17:11.891]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud                                       \u001b[0mLog level for 'dwave.cloud' namespace set to 0\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from data.dataManager import DataManager\n",
    "from utils.plotting.plotProvider import PlotProvider\n",
    "from engine.engine import Engine\n",
    "from models.modelCreator import ModelCreator\n",
    "\n",
    "from utils.plotting.HighLevelFeatures import HighLevelFeatures as HLF\n",
    "# HLF_1_photons = HLF('photon', filename='/raid/javier/Datasets/CaloVAE/data/atlas/binning_dataset_1_photons.xml', wandb=False)\n",
    "# HLF_1_pions = HLF('pion', filename='/raid/javier/Datasets/CaloVAE/data/atlas/binning_dataset_1_pions.xml', wandb=False)\n",
    "# HLF_1_electron = HLF('electron', filename='/raid/javier/Datasets/CaloVAE/data/atlas_dataset2and3/binning_dataset_2.xml', wandb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b23d35a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(version_base=None, config_path=\"configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a474a49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config.yaml': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "\u001b[1m[19:17:14.628]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0mLoading Data\n",
      "\u001b[1m[19:17:40.195]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f4b41fc7be0>: 80000 events, 625 batches\n",
      "\u001b[1m[19:17:40.200]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f4a83819e70>: 10000 events, 10 batches\n",
      "\u001b[1m[19:17:40.201]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f4b408e0820>: 10000 events, 10 batches\n",
      "\u001b[1m[19:17:42.805]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mmodels.modelCreator                               \u001b[0mInitialising Model Type AtlasConditionalQVAEv2\n",
      "2024-07-16 19:17:42,819 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Fetching definitions of all available solvers\n",
      "\u001b[1m[19:17:42.819]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mFetching definitions of all available solvers\n",
      "2024-07-16 19:17:44,454 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Received solver data for 7 solver(s).\n",
      "\u001b[1m[19:17:44.454]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mReceived solver data for 7 solver(s).\n",
      "2024-07-16 19:17:44,501 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage_system4.1')\n",
      "\u001b[1m[19:17:44.501]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage_system4.1')\n",
      "2024-07-16 19:17:44,552 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage_system6.4')\n",
      "\u001b[1m[19:17:44.552]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage_system6.4')\n",
      "2024-07-16 19:17:44,574 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage2_prototype2.3')\n",
      "\u001b[1m[19:17:44.574]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage2_prototype2.3')\n",
      "2024-07-16 19:17:44,707 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Fetching definitions of all available solvers\n",
      "\u001b[1m[19:17:44.707]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mFetching definitions of all available solvers\n",
      "2024-07-16 19:17:46,165 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Received solver data for 7 solver(s).\n",
      "\u001b[1m[19:17:46.165]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mReceived solver data for 7 solver(s).\n",
      "2024-07-16 19:17:46,214 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage_system4.1')\n",
      "\u001b[1m[19:17:46.214]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage_system4.1')\n",
      "2024-07-16 19:17:46,281 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage_system6.4')\n",
      "\u001b[1m[19:17:46.281]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage_system6.4')\n",
      "2024-07-16 19:17:46,302 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage2_prototype2.3')\n",
      "\u001b[1m[19:17:46.302]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage2_prototype2.3')\n",
      "\u001b[1m[19:17:46.625]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mmodels.autoencoders.AtlasConditionalQVAEv2        \u001b[0mGumBoltAtlasCRBMCNN::decoder SmallPB3Dv1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing NetworkV3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# config=compose(config_name=\"config.yaml\")\n",
    "config=compose(config_name=\"config.yaml\")\n",
    "\n",
    "HLF_1_photons = HLF('photon', filename=config.data.binning_xml_photons, wandb=False)\n",
    "HLF_1_pions = HLF('pion', filename=config.data.binning_xml_pions, wandb=False)\n",
    "HLF_1_electron = HLF('electron', filename=config.data.binning_xml_electrons, wandb=False)\n",
    "\n",
    "wandb.init(project=\"caloqvae\", entity=config.data.entity, config=config, mode='disabled')\n",
    "modelCreator = ModelCreator(cfg=config)\n",
    "dataMgr = DataManager(cfg=config)\n",
    "#initialise data loaders\n",
    "dataMgr.init_dataLoaders()\n",
    "#run pre processing: get/set input dimensions and mean of train dataset\n",
    "dataMgr.pre_processing()\n",
    "\n",
    "if config.model.activation_fct.lower()==\"relu\":\n",
    "    modelCreator.default_activation_fct=torch.nn.ReLU()\n",
    "elif config.model.activation_fct.lower()==\"tanh\":\n",
    "    modelCreator.default_activation_fct=torch.nn.Tanh()\n",
    "else:\n",
    "    logger.warning(\"Setting identity as default activation fct\")\n",
    "    modelCreator.default_activation_fct=torch.nn.Identity()\n",
    "\n",
    "#instantiate the chosen model\n",
    "#loads from file \n",
    "model=modelCreator.init_model(dataMgr=dataMgr)\n",
    "\n",
    "#create the NN infrastructure\n",
    "model.create_networks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5238a51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[19:17:46.867]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mwandb                                             \u001b[0mWatching\n",
      "/home/luian1/.local/lib/python3.10/site-packages/coffea/util.py:154: FutureWarning: In coffea version v0.8.0 (target date: 31 Dec 2022), this will be an error.\n",
      "(Set coffea.deprecations_as_errors = True to get a stack trace now.)\n",
      "ImportError: coffea.hist is deprecated\n",
      "  warnings.warn(message, FutureWarning)\n",
      "\u001b[1m[19:17:47.989]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engineAtlas                                \u001b[0mSetting up engine Atlas.\n",
      "\u001b[1m[19:17:47.989]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engineCaloV3                               \u001b[0mSetting up engine Calo.\n",
      "\u001b[1m[19:17:47.990]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engine                                     \u001b[0mSetting up default engine.\n"
     ]
    }
   ],
   "source": [
    "#Not printing much useful info at the moment to avoid clutter. TODO optimise\n",
    "model.print_model_info()\n",
    "# for name, param in model.named_parameters():\n",
    "#         print(name, param.requires_grad)\n",
    "\n",
    "# Load the model on the GPU if applicable\n",
    "# dev = None\n",
    "# if (config.device == 'gpu') and config.gpu_list:\n",
    "#     logger.info('Requesting GPUs. GPU list :' + str(config.gpu_list))\n",
    "#     devids = [\"cuda:{0}\".format(x) for x in list(config.gpu_list)]\n",
    "#     logger.info(\"Main GPU : \" + devids[0])\n",
    "\n",
    "#     if is_available():\n",
    "#         print(devids[0])\n",
    "#         dev = device(devids[0])\n",
    "#         if len(devids) > 1:\n",
    "#             logger.info(f\"Using DataParallel on {devids}\")\n",
    "#             model = DataParallel(model, device_ids=list(config.gpu_list))\n",
    "#         logger.info(\"CUDA available\")\n",
    "#     else:\n",
    "#         dev = device('cpu')\n",
    "#         logger.info(\"CUDA unavailable\")\n",
    "# else:\n",
    "#     logger.info('Requested CPU or unable to use GPU. Setting CPU as device.')\n",
    "#     dev = device('cpu')\n",
    "# dev = torch.device(\"cuda:0\")\n",
    "dev = \"cuda:{0}\".format(config.gpu_list[0])\n",
    "\n",
    "# Send the model to the selected device\n",
    "# model.to(dev)\n",
    "# Log metrics with wandb\n",
    "wandb.watch(model)\n",
    "\n",
    "# For some reason, need to use postional parameter cfg instead of named parameter\n",
    "# with updated Hydra - used to work with named param but now is cfg=None \n",
    "engine=instantiate(config.engine, config)\n",
    "\n",
    "#TODO for some reason hydra double instantiates the engine in a\n",
    "#newer version if cfg=config is passed as an argument. This is a workaround.\n",
    "#Find out why that is...\n",
    "engine._config=config\n",
    "#add dataMgr instance to engine namespace\n",
    "engine.data_mgr=dataMgr\n",
    "#add device instance to engine namespace\n",
    "engine.device=dev    \n",
    "#instantiate and register optimisation algorithm\n",
    "engine.optimiser = torch.optim.Adam(model.parameters(),\n",
    "                                    lr=config.engine.learning_rate)\n",
    "#add the model instance to the engine namespace\n",
    "engine.model = model\n",
    "# add the modelCreator instance to engine namespace\n",
    "engine.model_creator = modelCreator\n",
    "engine.model = engine.model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55a5adb9-8a2c-402c-be97-296677f584eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config.yaml': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "\u001b[1m[19:17:48.601]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0mLoading Data\n",
      "\u001b[1m[19:18:16.865]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f4a0e803f10>: 80000 events, 625 batches\n",
      "\u001b[1m[19:18:16.867]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f4a0e803f40>: 10000 events, 10 batches\n",
      "\u001b[1m[19:18:16.868]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f4a0e803eb0>: 10000 events, 10 batches\n",
      "\u001b[1m[19:18:20.309]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mmodels.modelCreator                               \u001b[0mInitialising Model Type AtlasConditionalQVAEv2\n",
      "2024-07-16 19:18:20,319 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Fetching definitions of all available solvers\n",
      "\u001b[1m[19:18:20.319]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mFetching definitions of all available solvers\n",
      "2024-07-16 19:18:21,452 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Received solver data for 7 solver(s).\n",
      "\u001b[1m[19:18:21.452]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mReceived solver data for 7 solver(s).\n",
      "2024-07-16 19:18:21,507 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage_system4.1')\n",
      "\u001b[1m[19:18:21.507]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage_system4.1')\n",
      "2024-07-16 19:18:21,561 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage_system6.4')\n",
      "\u001b[1m[19:18:21.561]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage_system6.4')\n",
      "2024-07-16 19:18:21,583 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage2_prototype2.3')\n",
      "\u001b[1m[19:18:21.583]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage2_prototype2.3')\n",
      "2024-07-16 19:18:21,671 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Fetching definitions of all available solvers\n",
      "\u001b[1m[19:18:21.671]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mFetching definitions of all available solvers\n",
      "2024-07-16 19:18:23,217 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Received solver data for 7 solver(s).\n",
      "\u001b[1m[19:18:23.217]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mReceived solver data for 7 solver(s).\n",
      "2024-07-16 19:18:23,304 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage_system4.1')\n",
      "\u001b[1m[19:18:23.304]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage_system4.1')\n",
      "2024-07-16 19:18:23,400 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage_system6.4')\n",
      "\u001b[1m[19:18:23.400]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage_system6.4')\n",
      "2024-07-16 19:18:23,438 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage2_prototype2.3')\n",
      "\u001b[1m[19:18:23.438]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage2_prototype2.3')\n",
      "\u001b[1m[19:18:23.951]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mmodels.autoencoders.AtlasConditionalQVAEv2        \u001b[0mGumBoltAtlasCRBMCNN::decoder SmallPB3Dv1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing NetworkV3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[19:18:24.159]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engineAtlas                                \u001b[0mSetting up engine Atlas.\n",
      "\u001b[1m[19:18:24.160]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engineCaloV3                               \u001b[0mSetting up engine Calo.\n",
      "\u001b[1m[19:18:24.161]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engine                                     \u001b[0mSetting up default engine.\n"
     ]
    }
   ],
   "source": [
    "# config=compose(config_name=\"config.yaml\")\n",
    "config_2=compose(config_name=\"config.yaml\")\n",
    "wandb.init(project=\"caloqvae\", entity=\"qvae\", config=config_2, mode='disabled')\n",
    "modelCreator_2 = ModelCreator(cfg=config_2)\n",
    "dataMgr_2 = DataManager(cfg=config_2)\n",
    "#initialise data loaders\n",
    "dataMgr_2.init_dataLoaders()\n",
    "#run pre processing: get/set input dimensions and mean of train dataset\n",
    "dataMgr_2.pre_processing()\n",
    "\n",
    "if config_2.model.activation_fct.lower()==\"relu\":\n",
    "    modelCreator_2.default_activation_fct=torch.nn.ReLU()\n",
    "elif config_2.model.activation_fct.lower()==\"tanh\":\n",
    "    modelCreator_2.default_activation_fct=torch.nn.Tanh()\n",
    "else:\n",
    "    logger.warning(\"Setting identity as default activation fct\")\n",
    "    modelCreator_2.default_activation_fct=torch.nn.Identity()\n",
    "\n",
    "#instantiate the chosen model\n",
    "#loads from file \n",
    "model_2=modelCreator_2.init_model(dataMgr=dataMgr_2)\n",
    "\n",
    "#create the NN infrastructure\n",
    "model_2.create_networks()\n",
    "\n",
    "engine_2=instantiate(config_2.engine, config_2)\n",
    "\n",
    "#TODO for some reason hydra double instantiates the engine in a\n",
    "#newer version if cfg=config is passed as an argument. This is a workaround.\n",
    "#Find out why that is...\n",
    "engine_2._config=config_2\n",
    "#add dataMgr instance to engine namespace\n",
    "engine_2.data_mgr=dataMgr_2\n",
    "#add device instance to engine namespace\n",
    "engine_2.device=dev    \n",
    "#instantiate and register optimisation algorithm\n",
    "engine_2.optimiser = torch.optim.Adam(model_2.parameters(),\n",
    "                                    lr=config_2.engine.learning_rate)\n",
    "#add the model instance to the engine namespace\n",
    "engine_2.model = model_2\n",
    "# add the modelCreator instance to engine namespace\n",
    "engine_2.model_creator = modelCreator_2\n",
    "engine_2.model = engine_2.model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "158ecfae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[19:18:52.308]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f4cd4ef1ed0>: 80000 events, 625 batches\n",
      "\u001b[1m[19:18:52.311]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f4cd4ef2c20>: 10000 events, 10 batches\n",
      "\u001b[1m[19:18:52.312]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f4a375f3100>: 10000 events, 10 batches\n"
     ]
    }
   ],
   "source": [
    "train_loader,test_loader,val_loader = engine.data_mgr.create_dataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c30117a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###LOAD MODEL\n",
    "# engine.model.prior._weight_dict['03']\n",
    "# engine.model.prior.fullyconnected\n",
    "# engine.model._config.model.fullyconnected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4e8abc0-049d-416c-b6e8-b9d5ea4b3a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Advantage2_prototype2.3'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.model._qpu_sampler.properties[\"chip_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18861900",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[19:18:52.400]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mmodels.modelCreator                               \u001b[0mLoading state\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AtlasConditionalQVAEv2\n",
      "electron-ds2\n",
      "False True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[19:18:52.616]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mmodels.modelCreator                               \u001b[0mLoading weights from file : /fast_scratch_1/caloqvae/luian1/wandb/run-20240713_101327-d3gqz2n9/files/AtlasConditionalQVAEv2_atlas_default_best.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights for module =  _activation_fct\n",
      "Loading weights for module =  _bce_loss\n",
      "Loading weights for module =  _energy_activation_fct\n",
      "Loading weights for module =  _hit_activation_fct\n",
      "Loading weights for module =  _output_loss\n",
      "Loading weights for module =  _hit_loss\n",
      "Loading weights for module =  _hit_smoothing_dist_mod\n",
      "Loading weights for module =  _inference_energy_activation_fct\n",
      "Loading weights for module =  encoder\n",
      "Loading weights for module =  prior\n",
      "Loading weights for module =  decoder\n"
     ]
    }
   ],
   "source": [
    "# wordly-fog-352 | CNN + cond + scaled data + \\pow(1+x, 1/4) BCE + Cyl encoderDec\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-04/19-10-12/wandb/run-20240404_191013-a690v1bu/files/GumBoltAtlasPRBMCNN_atlas_default_latest.pth\"\n",
    "# modelname = 'world-fog-352'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-04/19-10-12/wandb/run-20240404_191013-a690v1bu/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True    \n",
    "    \n",
    "    \n",
    "# # # emissary-think-tank-353 | CNN + cond + scaled data + Cyl EncDec\n",
    "# # run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-05/12-01-16/wandb/run-20240405_120117-67fx57x8/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# # modelname = 'emissary-think-tank-353'\n",
    "# # datascaled = 'reduced'\n",
    "# # with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-05/12-01-16/wandb/run-20240405_120117-67fx57x8/files/config.yaml\", 'r') as file:\n",
    "# #     model_config = yaml.safe_load(file)\n",
    "# #     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "# #     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "# #     scaled=True  \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "# # nothern-microwave-356 | CNN + cond + scaled data + Cyl EncDec\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-08/17-47-59/wandb/run-20240408_174800-83zkah0g/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# modelname = 'nothern-microwave-356'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-08/17-47-59/wandb/run-20240408_174800-83zkah0g/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True \n",
    "    \n",
    "    \n",
    "# # # dark-sky-357 | CNN + cond + scaled data + Cyl EncDec\n",
    "# # run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-08/18-22-13/wandb/run-20240408_182214-ftos7bwv/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# # modelname = 'dark-sky-357'\n",
    "# # datascaled = 'reduced'\n",
    "# # with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-08/18-22-13/wandb/run-20240408_182214-ftos7bwv/files/config.yaml\", 'r') as file:\n",
    "# #     model_config = yaml.safe_load(file)\n",
    "# #     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "# #     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "# #     scaled=True \n",
    "\n",
    "\n",
    "# # # rural-cosmos-358 | CNN + cond + scaled data + Cyl EncDec\n",
    "# # # run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-10/21-09-25/wandb/run-20240410_210926-1fmsh565/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# # run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-10/21-09-25/wandb/run-20240415_105702-1fmsh565/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# # modelname = 'rural-cosmos-358'\n",
    "# # datascaled = 'reduced'\n",
    "# # with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-10/21-09-25/wandb/run-20240415_105702-1fmsh565/files/config.yaml\", 'r') as file:\n",
    "# #     model_config = yaml.safe_load(file)\n",
    "# #     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "# #     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "# #     scaled=True \n",
    "    \n",
    "    \n",
    "# # # rare-lake-359 | CNN + cond + scaled data + Cyl EncDec + logits passed on encoder\n",
    "# # run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-15/17-11-53/wandb/run-20240415_171154-1p5wt0sy/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# # modelname = 'rare-lake-359'\n",
    "# # datascaled = 'reduced'\n",
    "# # with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-15/17-11-53/wandb/run-20240415_171154-1p5wt0sy/files/config.yaml\", 'r') as file:\n",
    "# #     model_config = yaml.safe_load(file)\n",
    "# #     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "# #     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "# #     scaled=True \n",
    "    \n",
    "    \n",
    "# # deft-meadow-360 | CNN + cond + scaled data + Cyl EncDec + logits passed on encoder + no BCE weight\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-17/13-20-06/wandb/run-20240417_132007-grs8jl3h/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# modelname = 'deft-meadow-360'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-17/13-20-06/wandb/run-20240417_132007-grs8jl3h/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True \n",
    "    \n",
    "    \n",
    "# # dazzling-cloud-361 | CNN + cond + scaled data + Cyl EncDec + no BCE weight + clamped logits at 10\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-18/14-02-08/wandb/run-20240418_140209-mjj5yuvx/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# modelname = 'dazzling-cloud-361'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-18/14-02-08/wandb/run-20240418_140209-mjj5yuvx/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True \n",
    "    \n",
    "    \n",
    "# # fast-bee-363 | CNN + cond + scaled data + Cyl EncDec +Fully connected RBM\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-19/19-12-27/wandb/run-20240419_191228-1wkunmev/files/GumBoltAtlasPRBMCNN_atlas_default_latest.pth\"\n",
    "# modelname = 'fast-bee-363'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-19/19-12-27/wandb/run-20240419_191228-1wkunmev/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True \n",
    "\n",
    "\n",
    "# # deep-snowball-367 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log energy encoded\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-22/19-21-15/wandb/run-20240422_192116-p4gannm2/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# modelname = 'deep-snowball-367'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-22/19-21-15/wandb/run-20240422_192116-p4gannm2/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True  \n",
    "    \n",
    "    \n",
    "# # # soft-violet-374 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log energy encoded + Zephyr\n",
    "# # run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-24/15-23-11/wandb/run-20240424_152312-wn4msoz2/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# # modelname = 'soft-violet-374'\n",
    "# # datascaled = 'reduced'\n",
    "# # with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-24/15-23-11/wandb/run-20240424_152312-wn4msoz2/files/config.yaml\", 'r') as file:\n",
    "# #     model_config = yaml.safe_load(file)\n",
    "# #     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "# #     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "# #     scaled=True \n",
    "    \n",
    "    \n",
    "# # # dutiful-bird-375 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log energy encoded + CRBM\n",
    "# # run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-24/20-12-01/wandb/run-20240424_201202-so4nwdou/files/GumBoltAtlasPRBMCNN_atlas_default_latest.pth\"\n",
    "# # modelname = 'dutiful-bird-375'\n",
    "# # datascaled = 'reduced'\n",
    "# # with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-24/20-12-01/wandb/run-20240424_201202-so4nwdou/files/config.yaml\", 'r') as file:\n",
    "# #     model_config = yaml.safe_load(file)\n",
    "# #     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "# #     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "# #     scaled=True \n",
    "    \n",
    "    \n",
    "# # # sunny-firebrand-376 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log energy encoded + Zephyr+ CRBM\n",
    "# # run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-25/13-08-39/wandb/run-20240425_130840-nmqieu71/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# # modelname = 'sunny-firebrand-376'\n",
    "# # datascaled = 'reduced'\n",
    "# # with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-25/13-08-39/wandb/run-20240425_130840-nmqieu71/files/config.yaml\", 'r') as file:\n",
    "# #     model_config = yaml.safe_load(file)\n",
    "# #     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "# #     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "# #     scaled=True \n",
    "    \n",
    "\n",
    "# # graceful-plasma-378 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log energy encoded + Zephyr+ CRBM\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-29/17-29-12/wandb/run-20240429_172912-uzp3fv73/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# modelname = 'graceful-plasma-378'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-29/17-29-12/wandb/run-20240429_172912-uzp3fv73/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True\n",
    "    \n",
    "\n",
    "# # # solar-wildflower-379 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log energy encoded + CRBM\n",
    "# # run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-30/13-53-54/wandb/run-20240430_135355-73aho6c2/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# # modelname = 'solar-wildflower-379'\n",
    "# # datascaled = 'reduced'\n",
    "# # with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-30/13-53-54/wandb/run-20240430_135355-73aho6c2/files/config.yaml\", 'r') as file:\n",
    "# #     model_config = yaml.safe_load(file)\n",
    "# #     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "# #     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "# #     scaled=True\n",
    "\n",
    "\n",
    "# # feasible-dust-380 | CNN + cond + scaled data + Cyl EncDec + lin energy encoded + CRBM\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-01/13-05-50/wandb/run-20240501_130551-4rr2g0s4/files/GumBoltAtlasPRBMCNN_atlas_default_latest.pth\"\n",
    "# modelname = 'feasible-dust-380'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-01/13-05-50/wandb/run-20240501_130551-4rr2g0s4/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True\n",
    "    \n",
    "    \n",
    "# # # stilted-morning-381 | CNN + cond + scaled data + Cyl EncDec + lin energy encoded + CRBM + no freeze out\n",
    "# # run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-01/19-46-04/wandb/run-20240501_194605-4f6qr1dt/files/GumBoltAtlasPRBMCNN_atlas_default_latest.pth\"\n",
    "# # modelname = 'stilted-morning-381'\n",
    "# # datascaled = 'reduced'\n",
    "# # with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-01/19-46-04/wandb/run-20240501_194605-4f6qr1dt/files/config.yaml\", 'r') as file:\n",
    "# #     model_config = yaml.safe_load(file)\n",
    "# #     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "# #     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "# #     scaled=True\n",
    "    \n",
    "    \n",
    "# # fallen-disco-383 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-02/18-46-03/wandb/run-20240502_184604-opz17u3d/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# modelname = 'fallen-disco-383'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-02/18-46-03/wandb/run-20240502_184604-opz17u3d/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True\n",
    "    \n",
    "    \n",
    "# # # breezy-smoke-389 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition\n",
    "# # run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-06/21-43-41/wandb/run-20240506_214342-tyclqjw4/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# # modelname = 'breezy-smoke-389'\n",
    "# # datascaled = 'reduced'\n",
    "# # with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-06/21-43-41/wandb/run-20240506_214342-tyclqjw4/files/config.yaml\", 'r') as file:\n",
    "# #     model_config = yaml.safe_load(file)\n",
    "# #     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "# #     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "# #     scaled=True\n",
    "    \n",
    "\n",
    "# # # logical-dragon-394 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2\n",
    "# # run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-08/18-58-30/wandb/run-20240508_185831-yxmk5x30/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# # modelname = 'logical-dragon-394'\n",
    "# # datascaled = 'reduced'\n",
    "# # with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-08/18-58-30/wandb/run-20240508_185831-yxmk5x30/files/config.yaml\", 'r') as file:\n",
    "# #     model_config = yaml.safe_load(file)\n",
    "# #     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "# #     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "# #     scaled=True\n",
    "\n",
    "# # copper-vortex-404 is very similar to previous. Larger FCN at the end. Behaves very similar to previous model\n",
    "\n",
    "# # northern-sunset-406 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-10/10-55-05/wandb/run-20240510_105506-8txbu380/files/AtlasConditionalQVAE_atlas_default_100.pth\"\n",
    "# modelname = 'northern-sunset-406'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-10/10-55-05/wandb/run-20240510_105506-8txbu380/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True\n",
    "    \n",
    "    \n",
    "# # misunderstood-frost-410 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-12/16-24-06/wandb/run-20240512_162407-tz6u5opn/files/AtlasConditionalQVAE_atlas_default_120.pth\"\n",
    "# modelname = 'misunderstood-frost-410'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-12/16-24-06/wandb/run-20240512_162407-tz6u5opn/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True\n",
    "\n",
    "\n",
    "# # # flowing-grass-411 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2\n",
    "# # run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-13/13-18-33/wandb/run-20240513_131834-5saza00m/files/AtlasConditionalQVAE_atlas_default_best.pth\"\n",
    "# # modelname = 'flowing-grass-411'\n",
    "# # datascaled = 'reduced'\n",
    "# # with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-13/13-18-33/wandb/run-20240513_131834-5saza00m/files/config.yaml\", 'r') as file:\n",
    "# #     model_config = yaml.safe_load(file)\n",
    "# #     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "# #     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "# #     scaled=True\n",
    "\n",
    "\n",
    "# # dry-silence-412 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-15/14-28-01/wandb/run-20240515_142802-3la2tybf/files/AtlasConditionalQVAE_atlas_default_100.pth\"\n",
    "# modelname = 'dry-silence-412'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-15/14-28-01/wandb/run-20240515_142802-3la2tybf/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True\n",
    "    \n",
    "    \n",
    "# # # young-wildflower-413 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2\n",
    "# # run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-16/15-20-10/wandb/run-20240516_152011-cyeoc1or/files/AtlasConditionalQVAE_atlas_default_best.pth\"\n",
    "# # modelname = 'young-wildflower-412'\n",
    "# # datascaled = 'reduced'\n",
    "# # with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-16/15-20-10/wandb/run-20240516_152011-cyeoc1or/files/config.yaml\", 'r') as file:\n",
    "# #     model_config = yaml.safe_load(file)\n",
    "# #     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "# #     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "# #     scaled=True\n",
    "    \n",
    "    \n",
    "# # astral-terrain-415 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-16/19-47-55/wandb/run-20240516_194756-dt99yb97/files/AtlasConditionalQVAE_atlas_default_50.pth\"\n",
    "# modelname = 'astral-terrain-415'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-16/19-47-55/wandb/run-20240516_194756-dt99yb97/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True\n",
    "    \n",
    "    \n",
    "# # morning-breeze-420 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-18/15-22-04/wandb/run-20240518_152205-pi1sujcx/files/AtlasConditionalQVAE_atlas_default_150.pth\"\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-18/15-22-04/wandb/run-20240524_194939-pi1sujcx/files/AtlasConditionalQVAE_atlas_default_230.pth\"\n",
    "# modelname = 'morning-breeze-420'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-18/15-22-04/wandb/run-20240524_194939-pi1sujcx/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True\n",
    "    \n",
    "    \n",
    "# # gallant-capybara-418 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 + Z\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-18/15-20-30/wandb/run-20240518_152031-zhvzuxif/files/AtlasConditionalQVAE_atlas_default_150.pth\"\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-18/15-20-30/wandb/run-20240524_194447-zhvzuxif/files/AtlasConditionalQVAE_atlas_default_250.pth\"\n",
    "# modelname = 'gallant-capybara-418'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-18/15-20-30/wandb/run-20240518_152031-zhvzuxif/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True\n",
    "    \n",
    "    \n",
    "# # royal-plant-447 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-29/14-07-25/wandb/run-20240529_140726-f9sdv5v2/files/AtlasConditionalQVAE_atlas_default_10.pth\"\n",
    "# modelname = 'royal-plant-447'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-29/14-07-25/wandb/run-20240529_140726-f9sdv5v2/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=False   \n",
    "    \n",
    "# # brisk-bird-447 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-30/11-00-37/wandb/run-20240530_110038-oyw5vuog/files/AtlasConditionalQVAE_atlas_default_20.pth\"\n",
    "# modelname = 'brisk-bird-447'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-30/11-00-37/wandb/run-20240530_110038-oyw5vuog/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=False  \n",
    "    \n",
    "    \n",
    "# # #toasty-pond-448 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "# # run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-30/16-39-43/wandb/run-20240530_163944-g59w6j0e/files/AtlasConditionalQVAE_atlas_default_140.pth\"\n",
    "# # modelname = 'toasty-pond-448'\n",
    "# # datascaled = 'reduced'\n",
    "# # with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-30/16-39-43/wandb/run-20240530_163944-g59w6j0e/files/config.yaml\", 'r') as file:\n",
    "# #     model_config = yaml.safe_load(file)\n",
    "# #     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "# #     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "# #     scaled=False\n",
    "    \n",
    "    \n",
    "# # # solar-cloud-449 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "# # run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-30/19-04-18/wandb/run-20240530_190419-42l10ppy/files/AtlasConditionalQVAE_atlas_default_20.pth\"\n",
    "# # modelname = 'solar-cloud-449'\n",
    "# # datascaled = 'reduced'\n",
    "# # with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-30/19-04-18/wandb/run-20240530_190419-42l10ppy/files/config.yaml\", 'r') as file:\n",
    "# #     model_config = yaml.safe_load(file)\n",
    "# #     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "# #     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "# #     scaled=False \n",
    "\n",
    "\n",
    "# # twilight-river-450 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-31/19-11-05/wandb/run-20240531_191106-4dsnfwl4/files/GumBoltAtlasPRBMCNN_atlas_default_150.pth\"\n",
    "# modelname = 'twilight-river-450'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-31/19-11-05/wandb/run-20240531_191106-4dsnfwl4/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=False \n",
    "\n",
    "\n",
    "# #helpful-star-450 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-06-03/00-59-55/wandb/run-20240603_005956-nwgtxcyj/files/AtlasConditionalQVAE_atlas_default_120.pth\"\n",
    "# modelname = 'helpful-star-450'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-06-03/00-59-55/wandb/run-20240603_005956-nwgtxcyj/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=False\n",
    "    \n",
    "    \n",
    "# #glowing-meadow-453 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-06-03/23-59-58/wandb/run-20240603_235959-1txgiuch/files/AtlasConditionalQVAE_atlas_default_100.pth\"\n",
    "# modelname = 'glowing-meadow-453'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-06-03/23-59-58/wandb/run-20240603_235959-1txgiuch/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=False\n",
    "\n",
    "\n",
    "# #honest-hill-454 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-06-04/19-27-16/wandb/run-20240604_192717-n57xkuzr/files/AtlasConditionalQVAE_atlas_default_150.pth\"\n",
    "# modelname = 'honest-hill-454'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-06-04/19-27-16/wandb/run-20240604_192717-n57xkuzr/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=False\n",
    "    \n",
    "    \n",
    "# #pretty-shape-455 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-06-05/03-07-35/wandb/run-20240605_030736-20kaac85/files/AtlasConditionalQVAE_atlas_default_150.pth\"\n",
    "# modelname = 'pretty-shape-455'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-06-05/03-07-35/wandb/run-20240605_030736-20kaac85/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=False\n",
    "\n",
    "\n",
    "\n",
    "# #wobbly-aardvark-456 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-06-06/12-49-34/wandb/run-20240606_124935-30h7h1uj/files/AtlasConditionalQVAE_atlas_default_100.pth\"\n",
    "# modelname = 'wobbly-aardvark-456'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-06-06/12-49-34/wandb/run-20240606_124935-30h7h1uj/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=False\n",
    "\n",
    "# run_path = \"/fast_scratch_1/caloqvae/luian1/wandb/run-20240620_223442-7ggy3s19/files/AtlasConditionalQVAEv2_atlas_default_best.pth\"\n",
    "# # run_path = \"/fast_scratch_1/caloqvae/luian1/wandb/run-20240620_223442-7ggy3s19/files/AtlasConditionalQVAEv2_atlas_default_150.pth\"\n",
    "# modelname = 'dutiful-silence-108'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/fast_scratch_1/caloqvae/luian1/wandb/run-20240620_223442-7ggy3s19/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=False\n",
    "\n",
    "# jumping-wave-204 no Hierarchical Decoders - 3D Convolutions on 0.01 on Zephyr Topology\n",
    "run_path = \"/fast_scratch_1/caloqvae/luian1/wandb/run-20240713_101327-d3gqz2n9/files/AtlasConditionalQVAEv2_atlas_default_best.pth\"\n",
    "\n",
    "modelname = 'worthy-vortex-203'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/fast_scratch_1/caloqvae/luian1/wandb/run-20240713_101327-d3gqz2n9/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=False\n",
    "\n",
    "    \n",
    "arch = config['model']['model_type']\n",
    "part = config['data']['particle_type']\n",
    "print(arch)\n",
    "print(part)\n",
    "print(scaled, reducedata)\n",
    "\n",
    "\n",
    "# load_state(model, run_path, 'cuda:{0}'.format(cfg.gpu_list[0]))\n",
    "# load_state(model, run_path, dev)\n",
    "modelCreator.load_state(run_path, dev)\n",
    "engine.model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bdf532b-c6e6-447d-9f60-00d2067f9320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lnZais = engine.model.stater.AIS(30).detach().cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53462efd-8ab0-4020-8286-ebd9d5950c82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2740.80322265625 2740.698486328125\n"
     ]
    }
   ],
   "source": [
    "lnZrais = engine.model.stater.RAIS(20).detach().cpu().item()\n",
    "print(lnZais, lnZrais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fda41d50-7c3c-40a0-b4fe-babe8c48b94b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1586.5263671875 1587.450927734375\n"
     ]
    }
   ],
   "source": [
    "lnZais_rdm = engine_2.model.stater.AIS(30).detach().cpu().item()\n",
    "lnZrais_rdm = engine_2.model.stater.RAIS(20).detach().cpu().item()\n",
    "print(lnZais_rdm, lnZrais_rdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "272b86ae-9014-4914-b327-3b5502fc3ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object ParameterDict.items.<locals>.<genexpr> at 0x7f4a25d87060>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# engine.model.prior.bias_dict     # weight_dict['01']\n",
    "engine.model.prior.weight_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8f1fa1f-6a4f-4b6d-9b01-f40f4a1f4499",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously create file (unable to open file: name = '/home/javier/RBM_weights.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/javier/RBM_weights.hdf5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m hdf_file:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mprior\u001b[38;5;241m.\u001b[39mweight_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;66;03m# Each key-value pair in the dictionary becomes a dataset in the HDF5 file\u001b[39;00m\n\u001b[1;32m      5\u001b[0m         hdf_file\u001b[38;5;241m.\u001b[39mcreate_dataset(key, data\u001b[38;5;241m=\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu())\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py:241\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    239\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mcreate(name, h5f\u001b[38;5;241m.\u001b[39mACC_EXCL, fapl\u001b[38;5;241m=\u001b[39mfapl, fcpl\u001b[38;5;241m=\u001b[39mfcpl)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 241\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mACC_TRUNC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfcpl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# Open in append mode (read/write).\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# If that fails, create a new file only if it won't clobber an\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# existing one (ACC_EXCL)\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:122\u001b[0m, in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously create file (unable to open file: name = '/home/javier/RBM_weights.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File(\"/home/javier/RBM_weights.hdf5\", 'w') as hdf_file:\n",
    "    for key, value in engine.model.prior.weight_dict.items():\n",
    "        # Each key-value pair in the dictionary becomes a dataset in the HDF5 file\n",
    "        hdf_file.create_dataset(key, data=value.detach().cpu())\n",
    "        \n",
    "with h5py.File(\"/home/javier/RBM_biases.hdf5\", 'w') as hdf_file:\n",
    "    for key, value in engine.model.prior.bias_dict.items():\n",
    "        # Each key-value pair in the dictionary becomes a dataset in the HDF5 file\n",
    "        hdf_file.create_dataset(key, data=value.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2398a58b-a699-4ea7-96c8-5460ab6cc530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hfont = {'fontname':'Helvetica'}\n",
    "ds = {'electron-ds2':'Dataset 2', 'pion1':'Dataset 1: π'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4202c39e-ea8e-4ac7-ad48-dbc9717a05a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xx = next(iter(test_loader))\n",
    "in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1]) # input , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20931d8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 6480])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f49dc279d20>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 413,
       "width": 552
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(in_data.shape)\n",
    "plt.plot(in_data.cpu().numpy()[3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5c32576",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "unflatten: Provided sizes [1208, 1, 1, 1] don't multiply up to the size of dim 1 (3020) in the input tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m: \u001b[38;5;66;03m#reducedata:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     in_data \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39m_reduce(in_data, true_energy)\n\u001b[0;32m----> 5\u001b[0m fwd_output \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_energy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m engine\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39m_batch_size \u001b[38;5;241m=\u001b[39m true_energy\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m sample_energies, sample_data \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mgenerate_samples_cond(num_samples\u001b[38;5;241m=\u001b[39mtrue_energy\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], true_energy\u001b[38;5;241m=\u001b[39mtrue_energy)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/CaloQVAE/models/autoencoders/gumboltAtlasCRBMCNN.py:209\u001b[0m, in \u001b[0;36mGumBoltAtlasCRBMCNN.forward\u001b[0;34m(self, xx, is_training, beta_smoothing_fct, act_fct_slope)\u001b[0m\n\u001b[1;32m    206\u001b[0m         post_samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(out\u001b[38;5;241m.\u001b[39mpost_samples, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m#         post_samples = torch.cat([post_samples, x[1]], dim=1)\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m         output_hits, output_activations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpost_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;66;03m# labels = self.classifier(output_hits)\u001b[39;00m\n\u001b[1;32m    212\u001b[0m         out\u001b[38;5;241m.\u001b[39moutput_hits \u001b[38;5;241m=\u001b[39m output_hits\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/CaloQVAE/models/networks/DecoderCond.py:328\u001b[0m, in \u001b[0;36mDecoderCNNPB3Dv1.forward\u001b[0;34m(self, x, x0)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, x0):\n\u001b[0;32m--> 328\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m     x0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrans_energy(x0)\n\u001b[1;32m    330\u001b[0m     xx0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x, x0\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,torch\u001b[38;5;241m.\u001b[39mtensor(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m.\u001b[39mitem(),torch\u001b[38;5;241m.\u001b[39mtensor(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mitem(), torch\u001b[38;5;241m.\u001b[39mtensor(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:])\u001b[38;5;241m.\u001b[39mitem())), \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/flatten.py:141\u001b[0m, in \u001b[0;36mUnflatten.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflattened_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:1316\u001b[0m, in \u001b[0;36mTensor.unflatten\u001b[0;34m(self, dim, sizes)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39munflatten(dim, sizes, names)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msizes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: unflatten: Provided sizes [1208, 1, 1, 1] don't multiply up to the size of dim 1 (3020) in the input tensor"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "    if True: #reducedata:\n",
    "        in_data = engine._reduce(in_data, true_energy)\n",
    "    fwd_output = engine.model((in_data, true_energy), True)\n",
    "    engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "    sample_energies, sample_data = engine._model.generate_samples_cond(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "    # sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "    engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "idx = 0\n",
    "plt.plot(in_data.cpu().numpy()[idx,:])\n",
    "plt.plot(fwd_output.output_activations.detach().cpu().numpy()[idx,:], alpha=0.5)\n",
    "plt.plot(sample_data.detach().cpu().numpy()[idx,:], alpha=0.5)\n",
    "plt.legend([\"gt\",\"recon\",\"samp\"])\n",
    "plt.xlabel(\"voxel index\")\n",
    "plt.ylabel(\"energy per voxel in new variable\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(engine._reduceinv(in_data,true_energy).cpu().numpy()[idx,:])\n",
    "plt.plot(engine._reduceinv(fwd_output.output_activations,true_energy).detach().cpu().numpy()[idx,:], alpha=0.5)\n",
    "plt.plot(engine._reduceinv(sample_data, true_energy).detach().cpu().numpy()[idx,:], alpha=0.5)\n",
    "plt.legend([\"gt\",\"recon\",\"samp\"])\n",
    "plt.xlabel(\"voxel index\")\n",
    "plt.ylabel(\"energy per voxel\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(engine._reduceinv(in_data,true_energy).cpu().numpy()[idx,:]/true_energy.cpu().numpy()[idx,0])\n",
    "plt.plot(engine._reduceinv(fwd_output.output_activations,true_energy).detach().cpu().numpy()[idx,:]/true_energy.cpu().numpy()[idx,0], alpha=0.5)\n",
    "plt.plot(engine._reduceinv(sample_data, true_energy).detach().cpu().numpy()[idx,:]/true_energy.cpu().numpy()[idx,0], alpha=0.5)\n",
    "plt.legend([\"gt\",\"recon\",\"samp\"])\n",
    "plt.xlabel(\"voxel index\")\n",
    "plt.ylabel(\"energy per voxel\")\n",
    "plt.show()\n",
    "print(true_energy[idx,:], engine._reduceinv(in_data, true_energy)[idx,:].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89ceb31-4f25-47f2-82cd-40875b6615a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "directory_path = f'/home/luian1/CaloQVAE/figs/{modelname}'\n",
    "if not os.path.isdir(directory_path):\n",
    "    os.mkdir(directory_path) \n",
    "    print(modelname)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a53ea-746b-40d3-bc72-6335da7d4288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beta, beta_list, rbm_energy_list, dwave_energy_list, thrsh_met = engine.model.find_beta(num_reads=256, beta_init=4.41, lr=0.01, num_epochs = 30, delta = 4.0, method = 2, TOL=True, const = 1.0, adaptive = True)\n",
    "beta0 = beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8601f5c8-a90e-43da-985e-93e24a7a579a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(range(len(beta_list)), beta_list, linewidth=2.5, color=\"b\" )\n",
    "plt.plot(range(len(beta_list)), beta_list, linewidth=1.5, color=\"b\" )\n",
    "plt.xlabel(\"Iterations\", fontsize=15)\n",
    "plt.ylabel(\"Estimated $β_{QA}$\", fontsize=15)\n",
    "plt.legend([f'Chip {engine.model._qpu_sampler.properties[\"chip_id\"]}'], fontsize=15)\n",
    "# plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/luian1/CaloQVAE/figs/{modelname}/beta_QA_{engine.model._qpu_sampler.properties[\"chip_id\"]}_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f432056-c6b8-4b3e-b394-9943a4be5c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "QA = \"$β_{QA}$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb58c0ee-87f8-448c-bf47-ed08a4e7b2a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Hoffset = -(sum([engine.model.prior.bias_dict[key].sum().detach().cpu().item() for key in engine.model.prior.bias_dict.keys()])/2 \n",
    "            + sum([engine.model.prior.weight_dict[key].sum().detach().cpu().item() for key in engine.model.prior.weight_dict.keys()])/4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97096694-96ab-4b00-b16f-399e2f0f8f64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(rbm_energy_list[-1] + Hoffset, density=True, color=\"orange\", alpha=0.7)\n",
    "plt.hist(dwave_energy_list[-1] + Hoffset, density=True, color=\"m\", alpha=0.7)\n",
    "plt.xlabel(\"RBM Energy\", fontsize=15)\n",
    "plt.ylabel(\"PDF\", fontsize=15)\n",
    "plt.legend([\"Classical samples\", \"QPU samples\"], fontsize=17)\n",
    "# plt.title(f'ln(Z)[AIS] = {np.round(Zais)}, ln(Z)[RAIS] = {np.round(Zrais)}')\n",
    "plt.figtext(0.7, 0.6, f'Est. {QA} = {np.round(beta0, 2)}', ha='center', va='top', fontsize=17, bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=1'))\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/luian1/CaloQVAE/figs/{modelname}/Ising_energy_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n",
    "print(len(rbm_energy_list[-1]))\n",
    "print(len(dwave_energy_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0816824-e31e-41f3-a861-4e336c27cb40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "partition_size=config.model.n_latent_nodes_per_p\n",
    "energy_encoded_data = []\n",
    "\n",
    "engine.model.eval()\n",
    "with torch.no_grad():\n",
    "    for xx in val_loader:\n",
    "        in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "        if reducedata:\n",
    "            in_data = engine._reduce(in_data, true_energy, R=R)\n",
    "        # enIn = torch.cat((in_data, true_energy), dim=1)\n",
    "        # beta, post_logits, post_samples = engine.model.encoder(enIn, False)\n",
    "        beta, post_logits, post_samples = engine.model.encoder(in_data, true_energy, False)\n",
    "        post_samples = torch.cat(post_samples, 1)\n",
    "        post_samples_energy = engine.model.stater.energy_samples(post_samples[:,0:partition_size], post_samples[:,partition_size:2*partition_size], \n",
    "                                                 post_samples[:,2*partition_size:3*partition_size], post_samples[:,3*partition_size:4*partition_size], 1.0 )\n",
    "        energy_encoded_data.append(post_samples_energy.detach().cpu())\n",
    "\n",
    "energy_encoded_data = torch.cat(energy_encoded_data, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f5516-82f0-4819-aedc-927383707408",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# engine.model.prior_samples[:,0:512], engine.model.prior_samples[:,512:1024], engine.model.prior_samples[:,1024:1536], engine.model.prior_samples[:,1536:2048]\n",
    "energy_dwave = engine.model.stater.energy_samples(engine.model.prior_samples[1000:,0:512], engine.model.prior_samples[1000:,512:1024], \n",
    "                                                  engine.model.prior_samples[1000:,1024:1536], engine.model.prior_samples[1000:,1536:2048], 1.0)\n",
    "# _energy_rbm = engine.model.stater.energy_samples(rbm_data[-250:,0:512], rbm_data[-250:,512:1024], rbm_data[-250:,1024:1536], rbm_data[-250:,1536:2048], 1.0)\n",
    "# (rbm_data[-250:,0:512] == engine.model.prior_samples[:,0:512]).prod()\n",
    "engine.model.prior_samples.shape\n",
    "energy_dwave.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd80367-2140-4ffb-8134-77e7f71fa207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(engine.model.prior_samples[1000:,:512] == rbm_data[:,:512]).prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7a257e-ff86-4d2c-a124-c736bf9efb64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(energy_dwave.detach().cpu()+ Hoffset/2, density=True)\n",
    "plt.hist(energy_rbm_data.detach().cpu(), alpha=0.5, density=True)\n",
    "print(rbm_data.shape, energy_rbm_data.detach().cpu().mean() - energy_dwave.detach().cpu().mean(),\n",
    "     energy_rbm_data.shape, energy_dwave.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a51d69a-76fe-4f52-bc1e-b76993213854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "partition_size=config.model.n_latent_nodes_per_p\n",
    "encoded_data = []\n",
    "energy_encoded_data = []\n",
    "n_samples4_qpu = 200\n",
    "\n",
    "# encoded_data_rdm = []\n",
    "# energy_encoded_data_rdm = []\n",
    "engine.model.eval()\n",
    "# engine_2.model.eval()\n",
    "with torch.no_grad():\n",
    "    for xx in val_loader:\n",
    "    # for xx in train_loader:\n",
    "        in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "        #################################################\n",
    "        # true_energy = true_energy[:n_samples4_qpu,:]\n",
    "        # in_data = in_data[:n_samples4_qpu,:]\n",
    "        #################################################\n",
    "        if reducedata:\n",
    "            in_data = engine._reduce(in_data, true_energy, R=R)\n",
    "        # enIn = torch.cat((in_data, true_energy), dim=1)\n",
    "        # beta, post_logits, post_samples = engine.model.encoder(enIn, False)\n",
    "        beta, post_logits, post_samples = engine.model.encoder(in_data, true_energy, False)\n",
    "        post_samples = torch.cat(post_samples, 1)\n",
    "        post_samples_energy = engine.model.stater.energy_samples(post_samples[:,0:partition_size], post_samples[:,partition_size:2*partition_size], \n",
    "                                                 post_samples[:,2*partition_size:3*partition_size], post_samples[:,3*partition_size:4*partition_size], 1.0 )\n",
    "        encoded_data.append(post_samples.detach().cpu())\n",
    "        energy_encoded_data.append(post_samples_energy.detach().cpu())\n",
    "        \n",
    "        # #Rdm model\n",
    "        # # enIn = torch.cat((in_data, true_energy), dim=1)\n",
    "        # # beta, post_logits, post_samples = engine.model.encoder(enIn, False)\n",
    "        # beta, post_logits, post_samples = engine_2.model.encoder(in_data, true_energy, False)\n",
    "        # post_samples = torch.cat(post_samples, 1)\n",
    "        # post_samples_energy = engine_2.model.stater.energy_samples(post_samples[:,0:partition_size], post_samples[:,partition_size:2*partition_size], \n",
    "        #                                          post_samples[:,2*partition_size:3*partition_size], post_samples[:,3*partition_size:4*partition_size], 1.0 )\n",
    "        # encoded_data_rdm.append(post_samples.detach().cpu())\n",
    "        # energy_encoded_data_rdm.append(post_samples_energy.detach().cpu())\n",
    "\n",
    "encoded_data = torch.cat(encoded_data, dim=0)\n",
    "energy_encoded_data = torch.cat(energy_encoded_data, dim=0)\n",
    "        \n",
    "# encoded_data_rdm = torch.cat(encoded_data_rdm, dim=0)\n",
    "# energy_encoded_data_rdm = torch.cat(energy_encoded_data_rdm, dim=0)\n",
    "\n",
    "p1,p2,p3,p4 = post_samples[:,0:partition_size], post_samples[:,partition_size:2*partition_size], \\\n",
    "                                                 post_samples[:,2*partition_size:3*partition_size], post_samples[:,3*partition_size:4*partition_size]\n",
    "\n",
    "energy_rbm_data = []\n",
    "rbm_data = []\n",
    "# energy_rbm_rdm_data = []\n",
    "with torch.no_grad():\n",
    "    # for i in range(10):\n",
    "    for xx in val_loader:\n",
    "        in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "        ##################################################\n",
    "        # true_energy = true_energy[:n_samples4_qpu,:]\n",
    "        # in_data = in_data[:n_samples4_qpu,:]\n",
    "        ##################################################\n",
    "        # if i == 0:\n",
    "            # p1, p2, p3, p4 = engine.model.stater.block_gibbs_sampling_ais(1.0)\n",
    "        # else:\n",
    "            # p1, p2, p3, p4 = engine.model.stater.block_gibbs_sampling_ais(1.0, p1, p2, p3, p4)\n",
    "        engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "        if True:\n",
    "            u = engine.model.encoder.binary_energy(true_energy).to(dtype=torch.float32)\n",
    "            p1, p2, p3, p4 = engine.model.sampler.block_gibbs_sampling_cond(u)\n",
    "        else:\n",
    "            p1, p2, p3, p4 = engine.model.sampler.block_gibbs_sampling()\n",
    "        rbm_data.append(torch.cat((p1,p2,p3,p4),1))\n",
    "        rbm_samples_energy = engine.model.stater.energy_samples(p1, p2, p3, p4, 1.0)\n",
    "        energy_rbm_data.append(rbm_samples_energy.detach().cpu())\n",
    "        engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "        \n",
    "        # if i == 0:\n",
    "        #     p1_r, p2_r, p3_r, p4_r = engine_2.model.stater.block_gibbs_sampling_ais(1.0)\n",
    "        # else:\n",
    "        #     p1_r, p2_r, p3_r, p4_r = engine_2.model.stater.block_gibbs_sampling_ais(1.0, p1_r, p2_r, p3_r, p4_r)\n",
    "        # rbm_rdm_samples_energy = engine_2.model.stater.energy_samples(p1_r, p2_r, p3_r, p4_r, 1.0)\n",
    "        # energy_rbm_rdm_data.append(rbm_rdm_samples_energy.detach().cpu())\n",
    "    \n",
    "energy_rbm_data = torch.cat(energy_rbm_data, dim=0)\n",
    "rbm_data = torch.cat(rbm_data,0)\n",
    "# energy_rbm_rdm_data = torch.cat(energy_rbm_rdm_data, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59faa9fc-3dfc-4032-b66f-3287f7accb93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(energy_encoded_data.numpy(), bins=70, linewidth=2.5, color=\"b\", density=True, log=True)\n",
    "plt.hist(energy_rbm_data.numpy(), bins=20, color=\"orange\", density=True, fc=(1, 0, 1, 0.5), histtype='step', linewidth=1.5)\n",
    "plt.hist(energy_rbm_rdm_data.numpy(), bins=20, linewidth=2.5, color=\"cyan\", density=True, fc=(0.5, 1.0, 0.5, 0.8))\n",
    "plt.hist(energy_encoded_data_rdm.numpy(), bins=70, linewidth=2.5, color=\"r\", density=True)\n",
    "\n",
    "plt.xlabel(\"RBM Energy\", fontsize=15)\n",
    "plt.ylabel(\"PDF\", fontsize=15)\n",
    "plt.legend([\"Trained RBM w/ Encoded Data\", \"Trained RBM w/ Gibbs sampled data\", \"Random RBM w/ Gibbs sampled data\", \"Random RBM w/ Init Encoded Data\"], fontsize=17)\n",
    "# plt.title(f'ln(Z)[AIS] = {np.round(Zais)}, ln(Z)[RAIS] = {np.round(Zrais)}')\n",
    "# plt.title(f'LL(trained) = {np.round(-energy_encoded_data.mean() - lnZais)}, LL(Rdm) = {np.round(-energy_encoded_data_rdm.mean() - lnZrais_rdm)} \\n \\\n",
    "        # LL(trained RBM data) = {np.round(-energy_rbm_data.mean() - lnZais)}, LL(Rdm RBM data) = {np.round(-energy_rbm_rdm_data.mean() - lnZrais_rdm)}')\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/luian1/CaloQVAE/figs/{modelname}/RBM_energy_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d301b8da-fcc0-4df7-9a1d-e1426e2379f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f6f54-5170-4ce1-98be-b42bc4f73b29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minVal, maxVal = min(energy_encoded_data.numpy()), max(energy_encoded_data.numpy())\n",
    "# minVal, maxVal = min(energy_dwave.detach().cpu().numpy()+ Hoffset/2), max(energy_dwave.detach().cpu().numpy()+ Hoffset/2)\n",
    "binwidth = (maxVal-minVal)/30\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(energy_encoded_data.numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), linewidth=2.5, color=\"b\", density=True, log=True, label=\"Encoded data\", alpha=0.7)\n",
    "plt.hist(energy_rbm_data.numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), color=\"orange\", density=True, fc=(1, 0, 1, 0.5), log=True, histtype='step', linewidth=2.5, label=\"MC\")\n",
    "# plt.hist(energy_dwave.detach().cpu().numpy() + Hoffset/2, bins=np.arange(minVal, maxVal + binwidth, binwidth), color=\"m\", density=True, fc=(1, 0, 1, 0.5), log=True, histtype='step', linewidth=2.5, label=\"QPU\")\n",
    "\n",
    "# plt.hist(energy_rbm_rdm_data.numpy(), bins=20, linewidth=2.5, color=\"cyan\", density=True, fc=(0.5, 1.0, 0.5, 0.8))\n",
    "# plt.hist(energy_encoded_data_rdm.numpy(), bins=70, linewidth=2.5, color=\"r\", density=True)\n",
    "\n",
    "plt.xlabel(\"RBM Energy\", fontsize=15)\n",
    "plt.ylabel(\"PDF\", fontsize=15)\n",
    "# plt.legend([\"Encoded data\", \"Gibbs sampled data\", \"QA sampled data\"], fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "# plt.title(f'ln(Z)[AIS] = {np.round(Zais)}, ln(Z)[RAIS] = {np.round(Zrais)}')\n",
    "# plt.title(f'LL(trained) = {np.round(-energy_encoded_data.mean() - lnZais)}, LL(Rdm) = {np.round(-energy_encoded_data_rdm.mean() - lnZrais_rdm)} \\n \\\n",
    "        # LL(trained RBM data) = {np.round(-energy_rbm_data.mean() - lnZais)}, LL(Rdm RBM data) = {np.round(-energy_rbm_rdm_data.mean() - lnZrais_rdm)}')\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/luian1/CaloQVAE/figs/{modelname}/RBM_energy_2_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d984e56a-4104-4a57-83cc-bc21e28732d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sparsity and Energy\n",
    "# beta\n",
    "# _just_act_cool(in_data, true_energy)\n",
    "# _shift_energy(in_data, true_energy)\n",
    "sample_data_qpu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f45d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# en_labels = []\n",
    "\n",
    "xtarget_samples = []\n",
    "xrecon_samples = []\n",
    "xgen_samples = []\n",
    "xgen_samples_qpu = []\n",
    "n_samples4_qpu = 200\n",
    "\n",
    "# xrecon_samples_2 = []\n",
    "\n",
    "# labelstarget_samples = []\n",
    "# labelsrecon_samples = []\n",
    "entarget_samples = []\n",
    "with torch.no_grad():\n",
    "    for xx in val_loader:\n",
    "    # for xx in train_loader:\n",
    "        in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "        ###############################################\n",
    "        # true_energy = true_energy[:n_samples4_qpu,:]\n",
    "        # in_data = in_data[:n_samples4_qpu,:]\n",
    "        ##############################################\n",
    "        # print(in_data.shape)\n",
    "        if reducedata:\n",
    "            in_data = engine._reduce(in_data, true_energy, R=R)\n",
    "        fwd_output = engine.model((in_data, true_energy), False)\n",
    "        if reducedata:\n",
    "            in_data = engine._reduceinv(in_data, true_energy, R=R)\n",
    "            recon_data = engine._reduceinv(fwd_output.output_activations, true_energy, R=R)\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            if True:\n",
    "                sample_energies, sample_data = engine._model.generate_samples_cond(num_samples=true_energy.shape[0], true_energy=true_energy, measure_time=True)\n",
    "                # sample_energies_qpu, sample_data_qpu = engine.model.generate_samples_qpu_cond(true_energy=true_energy, num_samples=1, thrsh=30, beta=1/beta0)\n",
    "            else:\n",
    "                sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy, measure_time=True)\n",
    "                # sample_energies_qpu, sample_data_qpu = engine._model.generate_samples_qpu(num_samples=true_energy.shape[0], true_energy=true_energy, measure_time=True, beta=1/beta0)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = engine._reduceinv(sample_data, sample_energies, R=R)\n",
    "            # sample_data_qpu = engine._reduceinv(sample_data_qpu, sample_energies_qpu, R=R)\n",
    "        elif scaled:\n",
    "            in_data = torch.tensor(engine._data_mgr.inv_transform(in_data.detach().cpu().numpy()))\n",
    "            recon_data = torch.tensor(engine._data_mgr.inv_transform(fwd_output.output_activations.detach().cpu().numpy()))\n",
    "            # recon_data_2 = torch.tensor(engine._data_mgr.inv_transform(fwd_just_act.detach().cpu().numpy()))\n",
    "            # recon_data_2 = torch.tensor(engine._data_mgr.inv_transform(fwd_energy_shift.detach().cpu().numpy()))\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            \n",
    "            if True:\n",
    "                sample_energies, sample_data = engine._model.generate_samples_cond(num_samples=true_energy.shape[0], true_energy=true_energy, measure_time=True)\n",
    "                # sample_energies_qpu, sample_data_qpu = engine.model.generate_samples_qpu_cond(true_energy=true_energy[:100,:], num_samples=1, thrsh=30, beta=1/beta0)\n",
    "            else:\n",
    "                sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy, measure_time=True)\n",
    "                # sample_energies_qpu, sample_data_qpu = engine._model.generate_samples_qpu(num_samples=true_energy.shape[0], true_energy=true_energy, measure_time=True, beta=1/beta0)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = torch.tensor(engine._data_mgr.inv_transform(sample_data.detach().cpu().numpy()))\n",
    "            # sample_data_qpu = torch.tensor(engine._data_mgr.inv_transform(sample_data_qpu.detach().cpu().numpy()))\n",
    "        else:\n",
    "            in_data = in_data.detach().cpu()*1000\n",
    "            recon_data = fwd_output.output_activations.detach().cpu()*1000\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            # sample_energies, sample_data = engine._model.generate_samples(num_samples=2048)\n",
    "            sample_data = sample_data.detach().cpu()*1000\n",
    "\n",
    "\n",
    "        xtarget_samples.append(in_data.detach().cpu())\n",
    "        xrecon_samples.append( recon_data.detach().cpu())\n",
    "        xgen_samples.append( sample_data.detach().cpu())\n",
    "        # xgen_samples_qpu.append( sample_data_qpu.detach().cpu())\n",
    "        entarget_samples.append(true_energy.detach().cpu())\n",
    "\n",
    "        # xrecon_samples_2.append( recon_data_2.detach().cpu())\n",
    "    \n",
    "    \n",
    "xtarget_samples = torch.cat(xtarget_samples, dim=0)\n",
    "xrecon_samples = torch.cat(xrecon_samples, dim=0)\n",
    "xgen_samples = torch.cat(xgen_samples, dim=0)\n",
    "# xgen_samples_qpu = torch.cat(xgen_samples_qpu, dim=0)\n",
    "entarget_samples = torch.cat(entarget_samples, dim=0)\n",
    "\n",
    "# xrecon_samples_2 = torch.cat(xrecon_samples_2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64833670-8ed1-4bea-ba5d-43743c1b12e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(xgen_samples.sum(dim=0) == 0).sum()\n",
    "(xrecon_samples.sum(dim=0) == 0).sum()\n",
    "# (xtarget_samples.sum(dim=0) == 0).sum()\n",
    "# print((xgen_samples.sum(dim=0) == 0).nonzero(as_tuple=True))\n",
    "# print((xrecon_samples.sum(dim=0) == 0).nonzero(as_tuple=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed1e4d-decf-4049-9d2e-8d42ac30ce0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random RBM\n",
    "# engine.model.sampler._prbm._bias_dict = load_RBM_state(f'/home/javier/Projects/CaloQVAE/outputs/2023-11-21/13-09-06/wandb/latest-run/files/RBM/RBM_1_9_biases.pth', dev)\n",
    "# engine.model.sampler._prbm._weight_dict = load_RBM_state(f'/home/javier/Projects/CaloQVAE/outputs/2023-11-21/13-09-06/wandb/latest-run/files/RBM/RBM_1_9_weights.pth', dev)\n",
    "engine.model.sampler._prbm._bias_dict = engine_2.model.sampler._prbm._bias_dict\n",
    "engine.model.sampler._prbm._weight_dict = engine_2.model.sampler._prbm._weight_dict\n",
    "# en_labels = []\n",
    "\n",
    "xtarget_samples = []\n",
    "xrecon_samples = []\n",
    "xgen_samples = []\n",
    "xgen_samples_qpu = []\n",
    "\n",
    "# labelstarget_samples = []\n",
    "# labelsrecon_samples = []\n",
    "entarget_samples = []\n",
    "with torch.no_grad():\n",
    "    for xx in val_loader:\n",
    "    # for xx in train_loader:\n",
    "        in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "        if reducedata:\n",
    "            in_data = engine._reduce(in_data, true_energy, R=R)\n",
    "        fwd_output = engine.model((in_data, true_energy), False)\n",
    "        if reducedata:\n",
    "            in_data = engine._reduceinv(in_data, true_energy, R=R)\n",
    "            recon_data = engine._reduceinv(fwd_output.output_activations, true_energy, R=R)\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = engine._reduceinv(sample_data, sample_energies, R=R)\n",
    "        elif scaled:\n",
    "            in_data = torch.tensor(engine._data_mgr.inv_transform(in_data.detach().cpu().numpy()))\n",
    "            recon_data = torch.tensor(engine._data_mgr.inv_transform(fwd_output.output_activations.detach().cpu().numpy()))\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy, measure_time=True)\n",
    "            # sample_energies_qpu, sample_data_qpu = engine._model.generate_samples_qpu(num_samples=true_energy.shape[0], true_energy=true_energy, measure_time=True, beta=1/beta)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = torch.tensor(engine._data_mgr.inv_transform(sample_data.detach().cpu().numpy()))\n",
    "            # sample_data_qpu = torch.tensor(engine._data_mgr.inv_transform(sample_data_qpu.detach().cpu().numpy()))\n",
    "        else:\n",
    "            in_data = in_data.detach().cpu()*1000\n",
    "            recon_data = fwd_output.output_activations.detach().cpu()*1000\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            # sample_energies, sample_data = engine._model.generate_samples(num_samples=2048)\n",
    "            sample_data = sample_data.detach().cpu()*1000\n",
    "\n",
    "        # xrecon_samples.append( torch.tensor(engine._data_mgr.inv_transform(fwd_output.output_activations.detach().cpu().numpy())) )\n",
    "    #     if engine._config.engine.cl_lambda:\n",
    "    #         labelsrecon_samples.append(fwd_output.labels.detach().cpu())\n",
    "    #         labelstarget_samples.append( nn.functional.one_hot(true_energy.divide(256).log2().to(torch.int64), num_classes=15).squeeze(1).to(torch.float).detach().cpu() )\n",
    "\n",
    "    #         en_labels.append(true_energy.detach().cpu())\n",
    "\n",
    "        xtarget_samples.append(in_data.detach().cpu())\n",
    "        xrecon_samples.append( recon_data.detach().cpu())\n",
    "        xgen_samples.append( sample_data.detach().cpu())\n",
    "        # xgen_samples_qpu.append( sample_data_qpu.detach().cpu())\n",
    "        entarget_samples.append(true_energy.detach().cpu())\n",
    "\n",
    "        # xtarget_samples.append( torch.tensor(engine._data_mgr.inv_transform(xx[0][0].detach().cpu().numpy())) )\n",
    "    \n",
    "    \n",
    "xtarget_samples = torch.cat(xtarget_samples, dim=0)\n",
    "xrecon_samples = torch.cat(xrecon_samples, dim=0)\n",
    "xgen_samples = torch.cat(xgen_samples, dim=0)\n",
    "# xgen_samples_qpu = torch.cat(xgen_samples_qpu, dim=0)\n",
    "entarget_samples = torch.cat(entarget_samples, dim=0)\n",
    "\n",
    "# if engine._config.engine.cl_lambda:\n",
    "#     labelstarget_samples = torch.cat(labelstarget_samples, dim=0)\n",
    "#     labelsrecon_samples = torch.cat(labelsrecon_samples, dim=0)\n",
    "#     en_labels = torch.cat(en_labels, dim=0)\n",
    "\n",
    "#     lhat = torch.argmax(nn.Sigmoid()(labelsrecon_samples), dim=1).numpy()\n",
    "#     l = torch.argmax(labelstarget_samples, dim=1).numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b91f5b9-5cad-4674-9726-a6f0e95641c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"mean qpu time\", np.mean([engine._model.sampling_time_qpu[i][0] for i in range(9)]), np.std([engine._model.sampling_time_qpu[i][0] for i in range(9)]))\n",
    "print(\"mean gpu time\", np.mean([engine._model.sampling_time_gpu[i][0] for i in range(9)]), np.std([engine._model.sampling_time_gpu[i][0] for i in range(9)]))\n",
    "print(\"mean gpu time/mean qpu time\", np.mean([engine._model.sampling_time_gpu[i][0] for i in range(9)])/np.mean([engine._model.sampling_time_qpu[i][0] for i in range(9)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123e80bd-b119-448e-8221-5c1e9c01946c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"mean qpu time\", np.mean([engine._model.sampling_time_qpu[i][0] for i in range(9)]), np.std([engine._model.sampling_time_qpu[i][0] for i in range(9)]))\n",
    "print(\"mean gpu time\", np.mean([engine._model.sampling_time_gpu[i][0] for i in range(9)]), np.std([engine._model.sampling_time_gpu[i][0] for i in range(9)]))\n",
    "print(\"mean gpu time/mean qpu time\", np.mean([engine._model.sampling_time_gpu[i][0] for i in range(9)])/np.mean([engine._model.sampling_time_qpu[i][0] for i in range(9)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87764fc8-c3db-4d13-bd0d-c4c8ccb4561a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minVal, maxVal = min(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy()), max(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy())\n",
    "binwidth = (maxVal-minVal)/50\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7, label=\"GT\")\n",
    "plt.hist(((xrecon_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"c\", label=\"Recon\")\n",
    "plt.hist(((xgen_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=3.5, color=\"orange\", linestyle=\"dashdot\", label=\"MC\")\n",
    "# plt.hist(((xgen_samples_qpu == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=3.5, color=\"brown\", linestyle=\"dashed\", label=\"QPU\")\n",
    "plt.xlabel(\"Sparsity Index\", fontsize=15)\n",
    "plt.ylabel(\"Histogram\", fontsize=15)\n",
    "# plt.legend([\"GT\", \"Recon\", \"Samples\", \"Sample /w QPU\"], fontsize=17)\n",
    "plt.legend( fontsize=17)\n",
    "# plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/luian1/CaloQVAE/figs/{modelname}/sparsity_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10455e-bd04-453f-8d01-cfa5255e122b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=20, log=True, histtype='step', linewidth=2.5, color=\"b\")\n",
    "plt.hist(((xrecon_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=20, log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "plt.hist(((xgen_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=20, log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashed\")\n",
    "# plt.hist(((xgen_samples_qpu == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=20, log=True, histtype='step', linewidth=2.5, color=\"green\", linestyle=\"dashed\")\n",
    "plt.xlabel(\"Sparsity Index\")\n",
    "plt.ylabel(\"Histogram\")\n",
    "plt.legend([\"GT\", \"Recon\", \"Samples\", \"Sample /w QPU\"])\n",
    "plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/luian1/CaloQVAE/figs/{modelname}/sparsity_RDM_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd9cc71-7a5c-43e8-88e2-9a4d8ad7d5bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HLF_1_electron.relevantLayers = [0,5,10,15,20,25,30,35,40,45]\n",
    "plt.figure(figsize=(8,6))\n",
    "# Create a grid of subplots\n",
    "fig, axes = plt.subplots(3,3, figsize=(12, 12), sharey=True, sharex=True, tight_layout=True)\n",
    "fig.text(0.5, -0.01, 'Sparsity Index', ha='center', fontsize=15)\n",
    "fig.text(-0.01, 0.5, 'Histogram', va='center', rotation='vertical', fontsize=15)\n",
    "\n",
    "# Iterate through the columns of X and plot histograms\n",
    "for i,_ in enumerate(HLF_1_electron.relevantLayers[:-1]):\n",
    "    row_index = i // 3  # Determine the row index\n",
    "    col_index = i % 3   # Determine the column index\n",
    "    \n",
    "    ax = axes[row_index, col_index]  # Get the current subplot\n",
    "    \n",
    "    # Plot histogram for the current column\n",
    "    idx = HLF_1_electron.relevantLayers[i+1]*9*16\n",
    "    idxPrev = (HLF_1_electron.relevantLayers[i])*9*16\n",
    "    l = idx - idxPrev\n",
    "    minVal, maxVal = min(((xtarget_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy()), max(((xtarget_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy())\n",
    "    binwidth = (maxVal-minVal)/50\n",
    "    ax.hist(((xtarget_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy(),  bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7, label=\"GT\")\n",
    "    ax.hist(((xrecon_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"c\", label=\"Recon\")\n",
    "    ax.hist(((xgen_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashdot\", label=\"MC\")\n",
    "    # ax.hist(((xgen_samples_qpu[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashed\", label=\"QPU\")\n",
    "    if i == 0:\n",
    "        # ax.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], fontsize=14)\n",
    "        ax.legend(fontsize=14)\n",
    "    ax.grid(\"True\")\n",
    "    \n",
    "    # Set labels and title for the subplot\n",
    "    # ax.set_xlabel(f'Column {i + 1}')\n",
    "    # ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Layers {HLF_1_electron.relevantLayers[i]} to {HLF_1_electron.relevantLayers[i+1]-1}', fontsize=12)\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'/home/luian1/CaloQVAE/figs/{modelname}/sparsity_per_layer_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9746360-eded-4c05-9be7-8ee72ee64e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), ((xrecon_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(),  marker='.', alpha=.5, color=\"b\")\n",
    "plt.scatter(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), ((xgen_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(),  marker='.', alpha=.5, color=\"orange\")\n",
    "# plt.scatter(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), ((xgen_samples_qpu == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(),  marker='.', alpha=.5, color=\"c\")\n",
    "plt.plot([0,1],[0,1], c='red', lw=2.5)\n",
    "plt.xlabel('GT Sparsity Index', fontsize=15)\n",
    "plt.ylabel('Reconstruction Sparsity Index', fontsize=15)\n",
    "plt.legend([\"Recon\", \"MC\", \"QPU\"], fontsize=17)\n",
    "# plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/luian1/CaloQVAE/figs/{modelname}/sparsity_scatter_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574bbfe2-32fe-4d50-a1a4-63ac22ae488c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "E_right = 100000\n",
    "E_left = 3000\n",
    "tmp = (entarget_samples < E_right) * (entarget_samples > E_left)\n",
    "idxEnFilter = (tmp == True).nonzero(as_tuple=True)[0]\n",
    "len(idxEnFilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aee82f-c2dc-4abf-a5ea-240786dd3999",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minVal, maxVal = min((xtarget_samples[idxEnFilter,:].sum(dim=1)/entarget_samples[idxEnFilter].view(-1)).numpy()), max((xtarget_samples[idxEnFilter,:].sum(dim=1)/entarget_samples[idxEnFilter].view(-1)).numpy())\n",
    "binwidth = (maxVal-minVal)/50\n",
    "plt.hist((xtarget_samples[idxEnFilter,:].sum(dim=1)/entarget_samples[idxEnFilter].view(-1)).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7, density=True, label=\"GT\")\n",
    "plt.hist((xrecon_samples[idxEnFilter,:].sum(dim=1).numpy()/entarget_samples[idxEnFilter].view(-1)).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"c\", density=True, label=\"Recon\")\n",
    "plt.hist((xgen_samples[idxEnFilter,:].sum(dim=1).numpy()/entarget_samples[idxEnFilter].view(-1)).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashdot\", density=True, label=\"MC\")\n",
    "# plt.hist((xgen_samples_qpu[idxEnFilter,:].sum(dim=1)/entarget_samples[idxEnFilter].view(-1)).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashed\", density=True, label=\"QPU\")\n",
    "\n",
    "# plt.hist((xtarget_samples.sum(dim=1)/entarget_samples.view(-1)).numpy(), bins=30, log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7, density=True)\n",
    "# plt.hist((xrecon_samples.sum(dim=1).numpy()/entarget_samples.view(-1)).numpy(), bins=30, log=True, histtype='step', linewidth=2.5, color=\"c\", density=True)\n",
    "# plt.hist((xgen_samples.sum(dim=1).numpy()/entarget_samples.view(-1)).numpy(), bins=30, log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashdot\", density=True)\n",
    "# plt.hist((xgen_samples_qpu[idxEnFilter,:].sum(dim=1)/entarget_samples[idxEnFilter].view(-1)).numpy(), bins=30, log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashed\", density=True)\n",
    "\n",
    "\n",
    "plt.xlabel(\"Energy ratio\", fontsize=15)\n",
    "# plt.xscale('log')\n",
    "\n",
    "plt.ylabel(\"Histogram\", fontsize=15)\n",
    "# plt.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "# plt.title(f'{ds[part]} \\n {E_left/1000}<E_inc<{E_right/1000} (GeV)')\n",
    "plt.savefig(f'/home/luian1/CaloQVAE/figs/{modelname}/energy_ration_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23327d69-c91d-4674-90e8-6065cecfc3a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minVal, maxVal = min(xtarget_samples[idxEnFilter,:].sum(dim=1).numpy()/1000), max(xtarget_samples[idxEnFilter,:].sum(dim=1).numpy()/1000)\n",
    "binwidth = (maxVal-minVal)/50\n",
    "plt.hist(xtarget_samples[idxEnFilter,:].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7, density=True, label=\"GT\")\n",
    "plt.hist(xrecon_samples[idxEnFilter,:].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"c\", density=True, label=\"Recon\")\n",
    "plt.hist(xgen_samples[idxEnFilter,:].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashdot\", density=True, label=\"MC\")\n",
    "# plt.hist(xgen_samples_qpu[idxEnFilter,:].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashed\", density=True, label=\"QPU\")\n",
    "\n",
    "plt.xlabel(\"energy per event (GeV)\", fontsize=15)\n",
    "# plt.xscale('log')\n",
    "\n",
    "plt.ylabel(\"Histogram\", fontsize=15)\n",
    "# plt.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"])\n",
    "plt.legend(fontsize=18)\n",
    "# plt.title(f'{ds[part]} \\n {E_left/1000}<E_inc<{E_right/1000} (GeV)')\n",
    "plt.savefig(f'/home/luian1/CaloQVAE/figs/{modelname}/energy_slice_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfafa50-5e03-46d1-bacb-9f8b3c80b965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HLF_1_electron.relevantLayers = [0,5,10,15,20,25,30,35,40,45]\n",
    "plt.figure(figsize=(8,6))\n",
    "# Create a grid of subplots\n",
    "fig, axes = plt.subplots(3,3, figsize=(12, 12), sharey=True, sharex=False, tight_layout=True)\n",
    "fig.text(0.5, 0.0, 'Energy per event (GeV)', ha='center', fontsize=15)\n",
    "fig.text(0.0, 0.5, 'Histogram', va='center', rotation='vertical', fontsize=15)\n",
    "\n",
    "# Iterate through the columns of X and plot histograms\n",
    "for i,_ in enumerate(HLF_1_electron.relevantLayers[:-1]):\n",
    "    row_index = i // 3  # Determine the row index\n",
    "    col_index = i % 3   # Determine the column index\n",
    "    \n",
    "    ax = axes[row_index, col_index]  # Get the current subplot\n",
    "    \n",
    "    # Plot histogram for the current column\n",
    "    idx = HLF_1_electron.relevantLayers[i+1]*9*16\n",
    "    idxPrev = (HLF_1_electron.relevantLayers[i])*9*16\n",
    "    l = idx - idxPrev\n",
    "    minVal, maxVal = min(xtarget_samples[idxEnFilter, idxPrev:idx].sum(dim=1).numpy()/1000), max(xtarget_samples[idxEnFilter, idxPrev:idx].sum(dim=1).numpy()/1000)\n",
    "    binwidth = (maxVal-minVal)/50\n",
    "    ax.hist(xtarget_samples[idxEnFilter, idxPrev:idx].sum(dim=1).numpy()/1000,  bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7, label=\"GT\")\n",
    "    ax.hist(xrecon_samples[idxEnFilter, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"c\", label=\"Recon\")\n",
    "    # ax.hist(xrecon_samples_2[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=20, log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashdot\", label=\"MC\")\n",
    "    ax.hist(xgen_samples[idxEnFilter, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashdot\", label=\"MC\")\n",
    "    # ax.hist(xgen_samples_qpu[idxEnFilter, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashed\", label=\"QPU\")\n",
    "    if i == 0:\n",
    "        # ax.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], title=f'{ds[part]}')\n",
    "        ax.legend(fontsize=15)\n",
    "    ax.grid(\"True\")\n",
    "    \n",
    "    # Set labels and title for the subplot\n",
    "    # ax.set_xlabel(f'Column {i + 1}')\n",
    "    # ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Layers {HLF_1_electron.relevantLayers[i]} to {HLF_1_electron.relevantLayers[i+1]-1}')\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_per_layer_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a20645a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minVal, maxVal = min(xtarget_samples.sum(dim=1).numpy()/1000), max(xtarget_samples.sum(dim=1).numpy()/1000)\n",
    "binwidth = (maxVal-minVal)/50\n",
    "plt.hist(xtarget_samples.sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7, label=\"GT\")\n",
    "plt.hist(xrecon_samples.sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"c\", label=\"Recon\")\n",
    "plt.hist(xgen_samples.sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"orange\", linestyle=\"dashdot\", label=\"MC\")\n",
    "# plt.hist(xgen_samples_qpu.sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"brown\", linestyle=\"dashed\", label=\"QPU\")\n",
    "# plt.hist(xtarget_samples.sum(dim=1).numpy()/1000, bins=np.arange(0, 100 + 1,2), log=True, histtype='step', linewidth=2.5, color=\"b\")\n",
    "# plt.hist(xrecon_samples.sum(dim=1).numpy()/1000, bins=np.arange(0, 100 + 1,2), log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "# plt.hist(xgen_samples.sum(dim=1).numpy()/1000, bins=np.arange(0, 100 + 1,2), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashed\")\n",
    "# plt.hist(xtarget_samples.sum(dim=1).numpy()/1000, bins=np.arange(100+1, 1000 + 1,10), log=True, histtype='step')\n",
    "# plt.hist(xrecon_samples.sum(dim=1).numpy()/1000, bins=np.arange(100+1, 1000 + 1,10), log=True, histtype='step')\n",
    "# plt.hist(xgen_samples.sum(dim=1).numpy()/1000, bins=np.arange(100+1, 1000 + 1,10), log=True, histtype='step')\n",
    "plt.xlabel(\"Energy per event (GeV)\", fontsize=15)\n",
    "# plt.xscale('log')\n",
    "\n",
    "plt.ylabel(\"Histogram\", fontsize=15)\n",
    "# plt.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], fontsize=18)\n",
    "plt.legend( fontsize=18)\n",
    "# plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/luian1/CaloQVAE/figs/{modelname}/energy_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n",
    "print(xgen_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a488ff-3187-41f2-a534-8f066030a145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(xtarget_samples.sum(dim=1).numpy()/1000, bins=30, log=True, histtype='step', linewidth=2.5, color=\"b\")\n",
    "plt.hist(xrecon_samples.sum(dim=1).numpy()/1000, bins=30, log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "plt.hist(xgen_samples.sum(dim=1).numpy()/1000, bins=30, log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"orange\", linestyle=\"dashed\")\n",
    "# plt.hist(xgen_samples_qpu.sum(dim=1).numpy()/1000, bins=30, log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"green\", linestyle=\"dashed\")\n",
    "# plt.hist(xtarget_samples.sum(dim=1).numpy()/1000, bins=np.arange(0, 100 + 1,2), log=True, histtype='step', linewidth=2.5, color=\"b\")\n",
    "# plt.hist(xrecon_samples.sum(dim=1).numpy()/1000, bins=np.arange(0, 100 + 1,2), log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "# plt.hist(xgen_samples.sum(dim=1).numpy()/1000, bins=np.arange(0, 100 + 1,2), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashed\")\n",
    "# plt.hist(xtarget_samples.sum(dim=1).numpy()/1000, bins=np.arange(100+1, 1000 + 1,10), log=True, histtype='step')\n",
    "# plt.hist(xrecon_samples.sum(dim=1).numpy()/1000, bins=np.arange(100+1, 1000 + 1,10), log=True, histtype='step')\n",
    "# plt.hist(xgen_samples.sum(dim=1).numpy()/1000, bins=np.arange(100+1, 1000 + 1,10), log=True, histtype='step')\n",
    "plt.xlabel(\"energy per event (GeV)\")\n",
    "# plt.xscale('log')\n",
    "\n",
    "plt.ylabel(\"Histogram\")\n",
    "plt.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"])\n",
    "plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/luian1/CaloQVAE/figs/{modelname}/energy_RDM_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n",
    "print(xgen_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d1b7fa-9e21-476c-9fac-8e518f3f178a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(xtarget_samples.sum(dim=1).numpy()/1000, xrecon_samples.sum(dim=1).numpy()/1000, marker='.', alpha=.5, color=\"b\")\n",
    "plt.scatter(xtarget_samples.sum(dim=1).numpy()/1000, xgen_samples.sum(dim=1).numpy()/1000, marker='.', alpha=.5, color=\"orange\")\n",
    "# plt.scatter(xtarget_samples.sum(dim=1).numpy()/1000, xgen_samples_qpu.sum(dim=1).numpy()/1000, marker='.', alpha=.5, color=\"cyan\")\n",
    "plt.plot([0,800],[0,800], c='red', lw=2.5, label='y=x')\n",
    "# plt.plot([0,20],[0,20], c='red', lw=2)\n",
    "# axes[0,1].set_xlabel(\"GT energy per event (GeV)\")\n",
    "plt.legend([\"Recon\", \"MC\", \"QPU\", \"y=x\"], fontsize=17)\n",
    "plt.grid(\"True\")\n",
    "plt.xlabel(\"GT energy per event (GeV)\", fontsize=15)\n",
    "plt.ylabel(\"Model output energy per \\n event (GeV)\", fontsize=15)\n",
    "plt.savefig(f'/home/luian1/CaloQVAE/figs/{modelname}/energy_scatter_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a106b8-2a7b-47ef-812e-fce4e0f45450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(xtarget_samples.sum(dim=1).numpy()/1000, (xtarget_samples.sum(dim=1).numpy() - xrecon_samples.sum(dim=1).numpy())/1000, marker='o', alpha=0.7, color=\"b\")\n",
    "plt.scatter(xtarget_samples.sum(dim=1).numpy()/1000, (xtarget_samples.sum(dim=1).numpy() - xgen_samples.sum(dim=1).numpy())/1000, marker='o', alpha=0.4, color=\"orange\")\n",
    "# plt.scatter(xtarget_samples.sum(dim=1).numpy()/1000, (xtarget_samples.sum(dim=1).numpy() - xgen_samples_qpu.sum(dim=1).numpy())/1000, marker='o', alpha=0.2, color=\"m\")\n",
    "# plt.plot([0,20],[0,20], c='red', lw=2)\n",
    "plt.xlabel(\"GT energy per event (GeV)\", fontsize=15)\n",
    "plt.ylabel(\"Abs error (GeV)\", fontsize=15)\n",
    "plt.ylim([-40,40])\n",
    "plt.legend([\"Recon\", \"Sample\", \"Sample w/ QPU\"], fontsize=15)\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/luian1/CaloQVAE/CaloQVAE/figs/{modelname}/energy_scatter_AbsError_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee0ff6b-28ac-4bf8-8d33-b813f6b4deb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(1/(xtarget_samples.sum(dim=1).numpy()/1000), np.abs(xtarget_samples.sum(dim=1).numpy() - xrecon_samples.sum(dim=1).numpy())/(xtarget_samples.sum(dim=1).numpy()+1e-3), marker='o', alpha=.7, color=\"blue\")\n",
    "plt.scatter(1/(xtarget_samples.sum(dim=1).numpy()/1000), np.abs(xtarget_samples.sum(dim=1).numpy() - xgen_samples.sum(dim=1).numpy())/(xtarget_samples.sum(dim=1).numpy()+1e-3), marker='o', alpha=.3, color=\"orange\")\n",
    "# plt.scatter(1/(xtarget_samples.sum(dim=1).numpy()/1000), np.abs(xtarget_samples.sum(dim=1).numpy() - xgen_samples_qpu.sum(dim=1).numpy())/(xtarget_samples.sum(dim=1).numpy()+1e-3), marker='o', alpha=.1, color=\"m\")\n",
    "plt.plot([1e-3,1e1],np.sqrt([1e-3,1e1])*np.power(2,0.5), c='r', lw=2.5, label='y=sqrt(x)')\n",
    "# axes[1,1].plot([1e-9,1e-6],np.linspace(1e-9,1e-6)*np.power(10,3.5), c='c', lw=2.5, label='y=x', linestyle=\"dashed\")\n",
    "plt.grid(\"True\")\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.ylim([1e-5,1e1])\n",
    "plt.yticks([1e-5,1e-4,1e-3,1e-2,1e-1,1e0,1e1])\n",
    "plt.legend([\"Recon\", \"Sample\", \"Sample w/ QPU\", \"y=sqrt(x)\"], fontsize=15)\n",
    "plt.ylabel(\"Relative Error\", fontsize=15)\n",
    "plt.xlabel('1/(GT energy per event) (GeV)$^{-1}$', fontsize=15)\n",
    "plt.savefig(f'/home/luian1/CaloQVAE/CaloQVAE/figs/{modelname}/energy_scatter_RelError_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8100cf5f-23aa-4c7d-93d4-8ee0bc2d0ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,2, figsize=(8,8), tight_layout=True)\n",
    "fig.text(0.5, 0.0, 'GT energy per event (GeV)', ha='center')\n",
    "# fig.text(0.5, 1.0, f'{ds[part]}', ha='center', fontsize=12)\n",
    "\n",
    "axes[0,0].scatter(xtarget_samples.sum(dim=1).numpy()/1000, xrecon_samples.sum(dim=1).numpy()/1000, marker='.', alpha=.5, color=\"b\")\n",
    "axes[0,0].scatter(xtarget_samples.sum(dim=1).numpy()/1000, xgen_samples.sum(dim=1).numpy()/1000, marker='.', alpha=.5, color=\"orange\")\n",
    "axes[0,0].plot([0,800],[0,800], c='red', lw=2.5, label='y=x')\n",
    "# axes[0,0].plot([0,3800],[0,3800], c='red', lw=2.5, label='y=x')\n",
    "axes[0,0].set_ylabel(\"Recon energy per event (GeV)\")\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(\"True\")\n",
    "axes[0,0].set_yscale('log')\n",
    "axes[0,0].set_xscale('log')\n",
    "\n",
    "axes[0,1].scatter(xtarget_samples.sum(dim=1).numpy()/1000, (xtarget_samples.sum(dim=1).numpy() - xrecon_samples.sum(dim=1).numpy())/1000, marker='.', alpha=0.6, color=\"b\")\n",
    "axes[0,1].scatter(xtarget_samples.sum(dim=1).numpy()/1000, (xtarget_samples.sum(dim=1).numpy() - xgen_samples.sum(dim=1).numpy())/1000, marker='.', alpha=0.2, color=\"orange\")\n",
    "# axes[0,1].scatter(xtarget_samples.sum(dim=1).numpy()/1000, (xtarget_samples.sum(dim=1).numpy() - xgen_samples_qpu.sum(dim=1).numpy())/1000, marker='.', alpha=0.1, color=\"m\")\n",
    "# plt.plot([0,20],[0,20], c='red', lw=2)\n",
    "# axes[0,1].set_xlabel(\"GT energy per event (GeV)\")\n",
    "axes[0,1].set_ylabel(\"Abs error (GeV)\")\n",
    "axes[0,1].set_ylim([-40,40])\n",
    "# axes[0,1].legend()\n",
    "# axes[0,1].set_yscale('log')\n",
    "axes[0,1].grid(\"True\")\n",
    "\n",
    "# axes[1,0].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy() - xtarget_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.5, color=\"blue\", label=\"Simulation\")\n",
    "# axes[1,0].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy() - xrecon_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.05, color=\"red\", label=\"Model\")\n",
    "axes[1,0].scatter(1/(entarget_samples.numpy()/1000), np.abs(entarget_samples.reshape(-1).numpy() - xtarget_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.5, color=\"blue\", label=\"Simulation\")\n",
    "axes[1,0].scatter(1/(entarget_samples.numpy()/1000), np.abs(entarget_samples.reshape(-1).numpy() - xrecon_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.05, color=\"red\", label=\"Model\")\n",
    "axes[1,0].plot([1e-3,1e0],np.power([1e-3,1e0],0.25)*np.power(10,2.0), c='orange', lw=2.5, label='slope=0.25', linestyle=\"dashdot\")\n",
    "axes[1,0].grid(\"True\")\n",
    "axes[1,0].set_yscale('log')\n",
    "axes[1,0].set_xscale('log')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].set_ylabel(\"Relative Error\")\n",
    "\n",
    "# axes[1,1].scatter(xtarget_samples.sum(dim=1).numpy()/1000, np.abs(xtarget_samples.sum(dim=1).numpy()/1000 - xrecon_samples.sum(dim=1).numpy()/1000), marker='.', alpha=.5, color=\"blue\")\n",
    "axes[1,1].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy()/1000 - xtarget_samples.sum(dim=1).numpy()/1000), marker='.', alpha=1, color=\"blue\", label=\"Simulation\")\n",
    "axes[1,1].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy()/1000 - xrecon_samples.sum(dim=1).numpy()/1000), marker='.', alpha=.2, color=\"red\", label=\"Model\")\n",
    "axes[1,1].plot([1,800],np.sqrt([1,800]), c='orange', lw=2.5, label='y=sqrt(x)', linestyle=\"dashdot\")\n",
    "axes[1,1].plot([1,800],[1,800], c='c', lw=2.5, label='y=x', linestyle=\"dashed\")\n",
    "# axes[1,1].set_title(f'{ds[part]}')\n",
    "axes[1,1].grid(\"True\")\n",
    "axes[1,1].set_yscale('log')\n",
    "axes[1,1].set_xscale('log')\n",
    "axes[1,1].set_ylabel(\"Absolute Error\")\n",
    "axes[1,1].legend()\n",
    "\n",
    "\n",
    "# Merge the first row's axes\n",
    "gs = axes[2, 0].get_gridspec()\n",
    "for ax in axes[2, :]:\n",
    "    ax.remove()\n",
    "ax_big = fig.add_subplot(gs[2, :])\n",
    "ax_big.scatter(1/(xtarget_samples.sum(dim=1).numpy()/1000), np.abs(xtarget_samples.sum(dim=1).numpy() - xrecon_samples.sum(dim=1).numpy())/(xtarget_samples.sum(dim=1).numpy()+1e-3), marker='.', alpha=.5, color=\"blue\")\n",
    "ax_big.scatter(1/(xtarget_samples.sum(dim=1).numpy()/1000), np.abs(xtarget_samples.sum(dim=1).numpy() - xgen_samples.sum(dim=1).numpy())/(xtarget_samples.sum(dim=1).numpy()+1e-3), marker='.', alpha=.5, color=\"orange\")\n",
    "# axes[1,0].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy() - xtarget_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.5, color=\"blue\", label=\"Simulation\")\n",
    "# axes[1,0].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy() - xrecon_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.05, color=\"red\", label=\"Model\")\n",
    "# axes[1,0].set_title(f'{ds[part]}')\n",
    "ax_big.plot([1e-3,1e1],np.sqrt([1e-3,1e1])*np.power(1,3.5), c='r', lw=2.5, label='y=sqrt(x)', linestyle=\"dashdot\")\n",
    "# axes[1,1].plot([1e-9,1e-6],np.linspace(1e-9,1e-6)*np.power(10,3.5), c='c', lw=2.5, label='y=x', linestyle=\"dashed\")\n",
    "ax_big.grid(\"True\")\n",
    "ax_big.set_yscale('log')\n",
    "ax_big.set_xscale('log')\n",
    "ax_big.legend()\n",
    "ax_big.set_ylim([1e-5,1e1])\n",
    "ax_big.set_yticks([1e-5,1e-4,1e-3,1e-2,1e-1,1e0,1e1])\n",
    "ax_big.set_ylabel(\"Relative Recon Error\")\n",
    "plt.savefig(f'/home/luian1/CaloQVAE/figs/{modelname}/energy_scatter_4panels_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104498b6-af53-464f-b6eb-b7924634d099",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HLF_1_electron.relevantLayers = [0,5,10,15,20,25,30,35,40,45]\n",
    "plt.figure(figsize=(8,6))\n",
    "# Create a grid of subplots\n",
    "fig, axes = plt.subplots(3,3, figsize=(12, 12), sharey=True, sharex=False, tight_layout=True)\n",
    "fig.text(0.5, 0.0, 'Energy per event (GeV)', ha='center', fontsize=15)\n",
    "fig.text(0.0, 0.5, 'Histogram', va='center', rotation='vertical', fontsize=15)\n",
    "\n",
    "# Iterate through the columns of X and plot histograms\n",
    "for i,_ in enumerate(HLF_1_electron.relevantLayers[:-1]):\n",
    "    row_index = i // 3  # Determine the row index\n",
    "    col_index = i % 3   # Determine the column index\n",
    "    \n",
    "    ax = axes[row_index, col_index]  # Get the current subplot\n",
    "    \n",
    "    # Plot histogram for the current column\n",
    "    idx = HLF_1_electron.relevantLayers[i+1]*9*16\n",
    "    idxPrev = (HLF_1_electron.relevantLayers[i])*9*16\n",
    "    l = idx - idxPrev\n",
    "    minVal, maxVal = min(xtarget_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000), max(xtarget_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000)\n",
    "    binwidth = (maxVal-minVal)/50\n",
    "    ax.hist(xtarget_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000,  bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7)\n",
    "    ax.hist(xrecon_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"c\")\n",
    "    # ax.hist(xrecon_samples_2[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=20, log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "    ax.hist(xgen_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashdot\")\n",
    "    # ax.hist(xgen_samples_qpu[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashed\")\n",
    "    if i == 0:\n",
    "        # ax.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], title=f'{ds[part]}')\n",
    "        ax.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], fontsize=15)\n",
    "    ax.grid(\"True\")\n",
    "    \n",
    "    # Set labels and title for the subplot\n",
    "    # ax.set_xlabel(f'Column {i + 1}')\n",
    "    # ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Layers {HLF_1_electron.relevantLayers[i]} to {HLF_1_electron.relevantLayers[i+1]-1}')\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'/home/luian1/CaloQVAE/figs/{modelname}/energy_per_layer_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a163100f-ac31-41d9-9b14-e10ef0a4996f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgen_samples2 = []\n",
    "en_input = [1,2,3,5,10,20,30,50,100,200,300,500,1000,2000,3000,5000,10000,20000]\n",
    "ll = len(en_input)\n",
    "gen_bs = 2048 #true_energy.shape[0]\n",
    "with torch.no_grad():\n",
    "    for i in en_input:\n",
    "        if reducedata:\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = engine._reduceinv(sample_data, sample_energies, R=R)\n",
    "        elif scaled:\n",
    "            engine._model.sampler._batch_size = gen_bs # true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=1000*i, measure_time=True)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = torch.tensor(engine._data_mgr.inv_transform(sample_data.detach().cpu().numpy()))\n",
    "        else:\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = sample_data.detach().cpu()*1000\n",
    "\n",
    "        xgen_samples2.append( sample_data.detach().cpu())\n",
    "\n",
    "xgen_samples2 = torch.cat(xgen_samples2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e450b-6dd3-4553-a82a-a0d17ed6ec92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "energy_gen = xgen_samples2.sum(dim=1)\n",
    "m_energy_gen = [energy_gen[i*gen_bs:gen_bs*(i+1)].sum().item()/1000 for i in range(ll)]\n",
    "sd_energy_gen = [energy_gen[i*gen_bs:gen_bs*(i+1)].std().item()/1000 for i in range(ll)]\n",
    "lin_inter = np.power(m_energy_gen,1/2) * (1 - np.array(m_energy_gen)/np.array(m_energy_gen).max()) \\\n",
    "    + np.power(m_energy_gen,1) * np.array(m_energy_gen)/np.array(m_energy_gen).max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed8495-167b-4a42-9524-63bb2abfe429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(np.array(m_energy_gen)/1000, sd_energy_gen, c='orange', lw=3.5, label='event mean energy')\n",
    "plt.plot((np.array(en_input)), sd_energy_gen, c='blue', lw=3.5, label='inc energy', linestyle=\"dashed\")\n",
    "plt.grid(\"True\")\n",
    "# plt.plot([1,10], np.sqrt([1,10])*np.power(10, -0.8))\n",
    "plt.plot(np.array(m_energy_gen)/1000, lin_inter*np.power(10, -1.8), c='red', lw=3.5, label='linear interpolation b/w sqrt and lin')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axvline(x=1000, c='black', lw=2.5, label='max energy trained on', linestyle=\"dashdot\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"E (GeV)\")\n",
    "plt.ylabel(\"σₑ\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca60851a-cddc-4ac2-8bc0-2ce382388ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# post_samples = torch.cat(post_samples,1)\n",
    "M = post_samples.shape[1]\n",
    "post_samples_cpu = post_samples.clone().detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaf98d6-57c1-4c09-b4f1-6830b957f7eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "pres = [(torch.arange(0,M).multiply(i*np.pi/M).cos() * post_samples_cpu + torch.arange(0,M).multiply(i*np.pi/M).sin() *(1 - post_samples_cpu).abs()).divide(np.sqrt(M)).unsqueeze(2) for i in np.arange(1,M-1,1)]\n",
    "# pres = [(torch.arange(0,M).multiply(i*np.pi/M).cos()).divide(np.sqrt(M)) for i in np.arange(1,M-1,1)]\n",
    "pos_enc = torch.cat(pres,2).transpose(1,2);\n",
    "res = pos_enc.sum([1,2])/(M-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c126cc5b-2bb6-44d0-aa82-391fd5539abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.plot(pres[0][0,:,0])\n",
    "# plt.plot(pres[1][0,:,0])\n",
    "# plt.plot(pres[10][0,:,0])\n",
    "plt.xlabel(\"partition index\")\n",
    "plt.plot(pos_enc.sum([1,2]))\n",
    "# plt.plot(torch.arange(0,M).multiply(np.pi/M).cos())\n",
    "# pos_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9e11f7-db79-46e2-9887-174a6dcc8dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "post_samples.sum(dim=1).unique().shape\n",
    "pos_enc.sum([1,2]).unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc2a73-1916-4026-b8d3-87d2cad2ff0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "engine.model.encoder.binary_energy(true_energy);\n",
    "bin_en.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a6e2a2-ec4b-45fb-ba67-6c5b80f5d4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bin_en = torch.tensor([[np.random.randint(2)for i in range(M)] for j in range(50)])\n",
    "\n",
    "bin_en = engine.model.encoder.binary_energy(true_energy)\n",
    "M = bin_en.shape[1]\n",
    "\n",
    "pres = [(torch.arange(0,M).multiply(np.pi/M).cos().to(bin_en.device) * bin_en + torch.arange(0,M).multiply(np.pi/M).sin().to(bin_en.device) *(1 - bin_en).abs()).divide(np.sqrt(M)).unsqueeze(2) for i in np.arange(1,M-1,1)]\n",
    "pos_enc = torch.cat(pres,2).transpose(1,2);\n",
    "res = pos_enc.sum([1,2])/(M-1)\n",
    "res.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ef30d6-b473-4cf1-9a23-5c603fc80d96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(range(128), pos_enc.sum([1,2]).detach().cpu()/(M-1))\n",
    "# pos_enc.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbda6ee0-7c2d-4527-b8d5-b3ed43b643e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###########Create Synth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ebc743-f3c7-457c-b084-aa0fd0c4ce74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "engen_samples2 = []\n",
    "xgen_samples2 = []\n",
    "with torch.no_grad():\n",
    "    for i,xx in enumerate(train_loader):\n",
    "        in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "        if reducedata:\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples_cond(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = engine._reduceinv(sample_data, sample_energies, R=R)\n",
    "        elif scaled:\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy, measure_time=True)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = torch.tensor(engine._data_mgr.inv_transform(sample_data.detach().cpu().numpy()))\n",
    "        else:\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = sample_data.detach().cpu()*1000\n",
    "\n",
    "        xgen_samples2.append( sample_data.detach().cpu())\n",
    "        engen_samples2.append(true_energy.detach().cpu())\n",
    "        \n",
    "        # if i > 30:\n",
    "        #     break\n",
    "\n",
    "xgen_samples2 = torch.cat(xgen_samples2, dim=0)\n",
    "engen_samples2 = torch.cat(engen_samples2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaae5da-a4ff-4f5e-a37c-57e54fe12c09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "import h5py\n",
    "\n",
    "# Convert tensors to numpy arrays as h5py does not support PyTorch tensors directly\n",
    "tensor1_np = xgen_samples2[:100000,:].numpy()\n",
    "tensor2_np = engen_samples2[:100000,:].numpy()\n",
    "\n",
    "# Create a new HDF5 file\n",
    "with h5py.File(f'/raid/javier/Datasets/CaloVAE/data/synData/dataset2_synthetic_{modelname}.hdf5', 'w') as f:\n",
    "    # Create datasets for your tensors\n",
    "    f.create_dataset('showers', data=tensor1_np)\n",
    "    f.create_dataset('incidence energy', data=tensor2_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3de6a5-fd05-4b65-a64e-79ab7d6c65b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = engine.model.prior.weight_dict['01'].sign().abs().sum(dim=1).detach().cpu().numpy()\n",
    "binwidth = 1.0\n",
    "data = {}\n",
    "for key in engine.model.prior.weight_dict.keys():\n",
    "    # data[key] = engine.model.prior.weight_dict[key].sign().abs().sum(dim=0).detach().cpu().numpy()\n",
    "    data[key] = engine.model.prior._weight_mask_dict[key].abs().sum(dim=0).detach().cpu().numpy()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f636e63-4c15-4fca-bc49-f867dce3fb21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create 2x2 grid of subplots\n",
    "fig, axs = plt.subplots(2, 3, figsize=(10, 7), sharey=True, sharex=True, tight_layout=True)  # 2x2 grid, figure size 10x10\n",
    "fig.text(0.5, 0.0, 'Couplings', ha='center', fontsize=15)\n",
    "fig.text(0.0, 0.4, 'Histogram', rotation=90, ha='center', fontsize=15)\n",
    "\n",
    "# Plot data on each subplot\n",
    "labels, counts = np.unique(data['01'], return_counts=True)\n",
    "axs[0,0].bar(labels, counts, align='center', color=\"b\", alpha=0.8)\n",
    "# axs[0, 0].hist(data['01'], bins=np.arange(min(data['01']), max(data['01']) + binwidth, binwidth), histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7, align='center')\n",
    "axs[0,0].grid(\"True\")\n",
    "axs[0,0].legend([\"v to h\"], fontsize=18)\n",
    "\n",
    "labels, counts = np.unique(data['02'], return_counts=True)\n",
    "axs[0,1].bar(labels, counts, align='center', color=\"b\", alpha=0.9)\n",
    "axs[0,1].grid(\"True\")\n",
    "axs[0,1].legend([\"v to s\"], fontsize=18)\n",
    "\n",
    "labels, counts = np.unique(data['03'], return_counts=True)\n",
    "axs[0,2].bar(labels, counts, align='center', color=\"b\", alpha=0.9)\n",
    "axs[0,2].grid(\"True\")\n",
    "axs[0,2].legend([\"v to t\"], fontsize=18)\n",
    "\n",
    "labels, counts = np.unique(data['12'], return_counts=True)\n",
    "axs[1,0].bar(labels, counts, align='center', color=\"b\", alpha=0.9)\n",
    "axs[1,0].grid(\"True\")\n",
    "axs[1,0].legend([\"h to s\"], fontsize=18)\n",
    "\n",
    "labels, counts = np.unique(data['13'], return_counts=True)\n",
    "axs[1,1].bar(labels, counts, align='center', color=\"b\", alpha=0.9)\n",
    "axs[1,1].grid(\"True\")\n",
    "axs[1,1].legend([\"h to t\"], fontsize=18)\n",
    "\n",
    "labels, counts = np.unique(data['12'], return_counts=True)\n",
    "axs[1,2].bar(labels, counts, align='center', color=\"b\", alpha=0.9)\n",
    "axs[1,2].grid(\"True\")\n",
    "axs[1,2].legend([\"s to t\"], fontsize=18)\n",
    "\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/weights_plot_zephyr.png', bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1172e4-75b8-4278-811f-6b9e7a34f385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.unique(HLF_1_pions.bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b83db1c-811d-480c-a945-0da83738bdef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xx = next(iter(val_loader))\n",
    "xx = next(iter(train_loader))\n",
    "in_data_pre, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1]) # input , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5c23ec-4e9c-4ff5-92c2-e7693bdf7dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if reducedata:\n",
    "    in_data = engine._reduce(in_data, true_energy, R=R)\n",
    "fwd_output = engine.model((in_data_pre, true_energy), False)\n",
    "if reducedata:\n",
    "    in_data = engine._reduceinv(in_data, true_energy, R=R)\n",
    "    recon_data = engine._reduceinv(fwd_output.output_activations, true_energy, R=R)\n",
    "    engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "    sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "    engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "    sample_data = engine._reduceinv(sample_data, sample_energies, R=R)\n",
    "elif scaled:\n",
    "    in_data = torch.tensor(engine._data_mgr.inv_transform(in_data_pre.detach().cpu().numpy()))\n",
    "    recon_data = torch.tensor(engine._data_mgr.inv_transform(fwd_output.output_activations.detach().cpu().numpy()))\n",
    "    engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "    # try:\n",
    "    sample_energies, sample_data = engine._model.generate_samples_cond(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "    # except:\n",
    "        # pass\n",
    "    engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "    # sample_energies, sample_data = engine._model.generate_samples(num_samples=2048)\n",
    "    sample_data = torch.tensor(engine._data_mgr.inv_transform(sample_data.detach().cpu().numpy()))\n",
    "else:\n",
    "    in_data = in_data.detach().cpu()*1000\n",
    "    recon_data = fwd_output.output_activations.detach().cpu()*1000\n",
    "    engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "    sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "    engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "    # sample_energies, sample_data = engine._model.generate_samples(num_samples=2048)\n",
    "    sample_data = sample_data.detach().cpu()*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a82abb-dce4-4c4a-ad86-aa92b696ae0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(20000/6)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90b672e-3725-4a6c-b3c4-7e4fbbcec853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "THRSH=7\n",
    "recon_data = recon_data * (recon_data > THRSH)\n",
    "sample_data = sample_data * (sample_data > THRSH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b9a4c-e9d7-42c7-9a9a-7bffabb94f01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HLF_1_pions.relevantLayers = [1,2,3,4,5,6,7]\n",
    "# np.unique(HLF_1_pions.bin_edges)\n",
    "# true_energy/1000\n",
    "# HLF_1_electron.relevantLayers\n",
    "true_energy[idx]/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547dae52-5624-4a8f-9476-ac538c899359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HLF_1_electron.relevantLayers = [0,5,10,15,20,25,30,35,40,44] #[i for i in range(0,5)] #[0,5,10,15,20,25,30,35,40,47,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb76334-d387-42a1-84f1-3564ca7f0e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (((in_data[:,0:108] - recon_data[:,0:108])/(in_data[:,0:108]))**2).sum(dim=1).argsort()[:20]\n",
    "# (((in_data - recon_data)/(in_data+1e-5))**2).sum(dim=1).argsort()[-200:-1]\n",
    "# (((in_data - recon_data))**2).sum(dim=1).argsort()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be370dc3-8afb-46d8-abfe-cbef70b47b74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xtarget_samples\n",
    "print(HLF_1_electron.DrawSingleShower(xtarget_samples[idx,:].detach().cpu().numpy(), vmax=1e+4, vmin=1e+0, cmap='rainbow', filename=None ) )\n",
    "print(HLF_1_electron.DrawSingleShower(xrecon_samples[idx,:].detach().cpu().numpy(), vmax=1e+4, vmin=1e+0, cmap='rainbow', filename=None ) )\n",
    "print(HLF_1_electron.DrawSingleShower(xgen_samples[idx,:].detach().cpu().numpy(), vmax=1e+4, vmin=1e+0, cmap='rainbow', filename=None ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10535ec8-4171-4e0f-a502-cd3f0627ec09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 45*16*9\n",
    "# probe = torch.zeros(6480)\n",
    "# probe[0] = 0.01\n",
    "# probe[1] = 0.1\n",
    "# probe[2:9] = torch.tensor([0.01*i for i in range(2,9)])\n",
    "# probe[9] = 1\n",
    "# HLF_1_electron.DrawSingleShower(probe.numpy()*1000, vmax=1e+4, vmin=1e+0, cmap='rainbow', filename=None ) \n",
    "in_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ada102-361a-48b1-9d04-ecea3d50b391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx=21\n",
    "# HLF_1_pions.DrawSingleShower(in_data[idx,:].detach().cpu().numpy(), filename=None)\n",
    "# HLF_1_pions.DrawSingleShower(in_data[idx,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/target_{idx}_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "\n",
    "HLF_1_electron.DrawSingleShower(in_data[idx,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/target_a_{idx}_{modelname}_{arch}_{datascaled}_{part}.png', vmax=1e+3, vmin=1e+0, cmap='rainbow')\n",
    "HLF_1_electron.DrawSingleShower(in_data[idx,:].detach().cpu().numpy(), vmax=1e+4, vmin=1e+0, cmap='rainbow', filename=None ) \n",
    "\n",
    "HLF_1_electron.DrawAverageShower(in_data[:,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/target_a_{idx}_{modelname}_{arch}_{datascaled}_{part}_avg.png')\n",
    "HLF_1_electron.DrawAverageShower(in_data[:,:].detach().cpu().numpy(),   vmax=1e+2, vmin=1e-2, cmap='rainbow', filename=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9706a637-40a7-4ffd-8daf-0721d37402d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HLF_1_pions.DrawSingleShower(recon_data[idx,:].detach().cpu().numpy(), filename=None)\n",
    "# HLF_1_pions.DrawSingleShower(recon_data[idx,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/recon_{idx}_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "\n",
    "HLF_1_electron.DrawSingleShower(recon_data[idx,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/recon_a_{idx}_{modelname}_{arch}_{datascaled}_{part}.png', vmax=1e+3, vmin=1e+0, cmap='rainbow')\n",
    "HLF_1_electron.DrawSingleShower(recon_data[idx,:].detach().cpu().numpy(), filename=None, vmax=1e+4, vmin=1e+0, cmap='rainbow')\n",
    "\n",
    "HLF_1_electron.DrawAverageShower(recon_data[:,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/recon_{idx}_{modelname}_{arch}_{datascaled}_{part}_avg.png')\n",
    "HLF_1_electron.DrawAverageShower(recon_data[:,:].detach().cpu().numpy(),  vmax=1e+2, vmin=1e-2, cmap='rainbow', filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad4061e-5ca2-4e00-9a8a-39286d219431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HLF_1_pions.DrawSingleShower(sample_data[idx,:].detach().cpu().numpy(), filename=None)\n",
    "# HLF_1_pions.DrawSingleShower(sample_data[1,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sample_{idx}_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "\n",
    "HLF_1_electron.DrawSingleShower(sample_data[idx,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sample_a_{idx}_{modelname}_{arch}_{datascaled}_{part}.png', vmax=1e+3, vmin=1e+0, cmap='rainbow')\n",
    "HLF_1_electron.DrawSingleShower(sample_data[idx,:].detach().cpu().numpy(), filename=None, vmax=1e+4, vmin=1e+0, cmap='rainbow')\n",
    "\n",
    "HLF_1_electron.DrawAverageShower(sample_data[:,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sample_a_{idx}_{modelname}_{arch}_{datascaled}_{part}_avg.png')\n",
    "HLF_1_electron.DrawAverageShower(sample_data[:,:].detach().cpu().numpy(),  vmax=1e+2, vmin=1e-2, cmap='rainbow', filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d80a8-d382-4c81-ada2-202e240d0d07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HLF_1_electron.DrawSingleShower(sample_data_qpu[idx,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sample_QPU_a_{idx}_{modelname}_{arch}_{datascaled}_{part}.png', vmax=1e+3, vmin=1e+0, cmap='rainbow')\n",
    "HLF_1_electron.DrawSingleShower(sample_data_qpu[idx,:].detach().cpu().numpy(), filename=None, vmax=1e+4, vmin=1e+0, cmap='rainbow')\n",
    "\n",
    "HLF_1_electron.DrawAverageShower(sample_data_qpu[:,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sample_QPU_a_{idx}_{modelname}_{arch}_{datascaled}_{part}_avg.png')\n",
    "HLF_1_electron.DrawAverageShower(sample_data_qpu[:,:].detach().cpu().numpy(),  vmax=1e+2, vmin=1e-2, cmap='rainbow', filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711e42a-09b3-41a2-9823-84b35975df5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samps = 50\n",
    "minVal, maxVal = min(xtarget_samples[:samps,:].view(-1)), max(xtarget_samples[:samps,:].view(-1))\n",
    "binwidth = (maxVal-minVal)/30\n",
    "\n",
    "plt.hist(xtarget_samples[:samps,:].view(-1), bins=np.arange(minVal, maxVal + binwidth, binwidth), density=True, log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7)\n",
    "plt.hist(xrecon_samples[:samps,:].view(-1), bins=np.arange(minVal, maxVal + binwidth, binwidth), density=True, log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"c\")\n",
    "plt.hist(xgen_samples[:samps,:].view(-1), bins=np.arange(minVal, maxVal + binwidth, binwidth), density=True, log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"orange\", linestyle=\"dashdot\")\n",
    "plt.xlabel(\"Energy per voxel (MeV)\", fontsize=15)\n",
    "\n",
    "plt.ylabel(\"Histogram\", fontsize=15)\n",
    "plt.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], fontsize=18)\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_per_voxel_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n",
    "print(xtarget_samples.view(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16347be-d694-4902-a175-e472106f60f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_qpu_time_to_train = [_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[0] for i in [128,256,512,1024]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c3a17-c141-4068-b123-4b328418ba2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %config InlineBackend.figure_format = 'retina'\n",
    "np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933cd57-fbd8-47ec-9d82-358e397c701f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[3] for i in [128,256,512,1024]],  marker='.', markersize=15, linewidth=2.5)\n",
    "# plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[3] for i in [128,256,512,1024]],  marker='o', markersize=15, linewidth=2.5)\n",
    "# plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[3] for i in [128,256,512,1024]],  marker='+', markersize=15, linewidth=2.5)\n",
    "# plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[3] for i in [128,256,512,1024]],  marker='.', markersize=15, linewidth=2.5)\n",
    "# plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[3] for i in [128,256,512,1024]],  marker='o', markersize=15, linewidth=2.5)\n",
    "# plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[3] for i in [128,256,512,1024]],  marker='+', markersize=15, linewidth=2.5)\n",
    "\n",
    "plt.plot([128,256,512,1024], np.array([_gpu_timing(temp_steps=3, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[3] for i in [128,256,512,1024]]),  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], np.array([_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[3] for i in [128,256,512,1024]]),  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], np.array([_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[3] for i in [128,256,512,1024]]),  marker='+', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], np.array([_gpu_timing(temp_steps=3, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[3] for i in [128,256,512,1024]]),  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], np.array([_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[3] for i in [128,256,512,1024]]),  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], np.array([_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[3] for i in [128,256,512,1024]]),  marker='+', markersize=15, linewidth=2.5)\n",
    "plt.xscale(\"log\")\n",
    "plt.axhline(y=1.5, color='black', linestyle='--')\n",
    "\n",
    "# plt.title(\"Milestone 4\")\n",
    "plt.xlabel(\"Training batch size\")\n",
    "plt.ylabel(\"Hours per 100 epochs\")\n",
    "plt.legend([\"steps=3, bs=256\",\"steps=5, bs=256\",\"steps=10, bs=256\", \"steps=3, bs=128\",\"steps=5, bs=128\",\"steps=10, bs=128\", \"1.5 hrs\"], title=\"βeff steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac426ba-3426-4d26-9783-34ac10878610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[2] for i in [128,256,512,1024]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[2] for i in [128,256,512,1024]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[2] for i in [128,256,512,1024]],  marker='+', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[2] for i in [128,256,512,1024]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[2] for i in [128,256,512,1024]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[2] for i in [128,256,512,1024]],  marker='+', markersize=15, linewidth=2.5)\n",
    "\n",
    "plt.title(\"Milestone 3\")\n",
    "plt.xlabel(\"Training batch size\")\n",
    "plt.ylabel(\"Hours per 100 epochs\")\n",
    "plt.legend([\"steps=5, bs=256\",\"steps=10, bs=256\",\"steps=15, bs=256\", \"steps=5, bs=128\",\"steps=10, bs=128\",\"steps=15, bs=128\"], title=\"βeff steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4073c-f2e7-4b71-bc77-c33807e4e992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[1] for i in [128,256,512,1024]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[1] for i in [128,256,512,1024]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[1] for i in [128,256,512,1024]],  marker='+', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[1] for i in [128,256,512,1024]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[1] for i in [128,256,512,1024]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[1] for i in [128,256,512,1024]],  marker='+', markersize=15, linewidth=2.5)\n",
    "\n",
    "plt.title(\"Milestone 2\")\n",
    "plt.xlabel(\"Training batch size\")\n",
    "plt.ylabel(\"Minutes per epoch\")\n",
    "plt.legend([\"steps=5, bs=256\",\"steps=10, bs=256\",\"steps=15, bs=256\", \"steps=5, bs=128\",\"steps=10, bs=128\",\"steps=15, bs=128\"], title=\"βeff steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eb90f5-1652-4875-8ff2-ba1271dc5038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ae3491-fb6a-49cb-9566-d20800ab0d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 256)[0] for i in [1024,2048]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 256)[0] for i in [1024,2048]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 256)[0] for i in [1024,2048]],  marker='+', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 128)[0] for i in [1024,2048]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 128)[0] for i in [1024,2048]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 128)[0] for i in [1024,2048]],  marker='+', markersize=15, linewidth=2.5)\n",
    "\n",
    "plt.title(\"Milestone 1\")\n",
    "plt.xlabel(\"Validation batch size\")\n",
    "plt.ylabel(\"Minutes per 100-epochs\")\n",
    "plt.legend([\"steps=5, bs=256\",\"steps=10, bs=256\",\"steps=15, bs=256\", \"steps=5, bs=128\",\"steps=10, bs=128\",\"steps=15, bs=128\"], title=\"βeff steps\")\n",
    "# plt.legend([\"steps=10, bs=256\",\"steps=15, bs=256\", \"steps=10, bs=128\",\"steps=15, bs=128\"], title=\"βeff steps\")\n",
    "plt.grid(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6add3d14-331e-4c98-a160-95d639799065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 256)[4] for i in [1024,2048]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 256)[4] for i in [1024,2048]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 256)[4] for i in [1024,2048]],  marker='+', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 128)[4] for i in [1024,2048]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 128)[4] for i in [1024,2048]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 128)[4] for i in [1024,2048]],  marker='+', markersize=15, linewidth=2.5)\n",
    "\n",
    "plt.title(\"Milestone 1\")\n",
    "plt.xlabel(\"Validation batch size\")\n",
    "plt.ylabel(\"Minutes per 100-epochs\")\n",
    "plt.legend([\"steps=5, bs=256\",\"steps=10, bs=256\",\"steps=15, bs=256\", \"steps=5, bs=128\",\"steps=10, bs=128\",\"steps=15, bs=128\"], title=\"βeff steps\")\n",
    "# plt.legend([\"steps=10, bs=256\",\"steps=15, bs=256\", \"steps=10, bs=128\",\"steps=15, bs=128\"], title=\"βeff steps\")\n",
    "plt.grid(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4112bb13-2ff3-4cad-aac7-d6cdec2c5f77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot([1024,2048], [_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 256)[4] for i in [1024,2048]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 256)[4] for i in [1024,2048]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [_gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 256)[4] for i in [1024,2048]],  marker='+', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 128)[4] for i in [1024,2048]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 128)[4] for i in [1024,2048]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [_gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 128)[4] for i in [1024,2048]],  marker='+', markersize=15, linewidth=2.5)\n",
    "\n",
    "plt.title(\"Milestone 1\")\n",
    "plt.xlabel(\"Validation batch size\")\n",
    "plt.ylabel(\"Seconds per epochs\")\n",
    "plt.legend([\"steps=5, bs=256\",\"steps=10, bs=256\",\"steps=15, bs=256\", \"steps=5, bs=128\",\"steps=10, bs=128\",\"steps=15, bs=128\"], title=\"βeff steps\")\n",
    "# plt.legend([\"steps=10, bs=256\",\"steps=15, bs=256\", \"steps=10, bs=128\",\"steps=15, bs=128\"], title=\"βeff steps\")\n",
    "plt.grid(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b1c46-6b18-4bfc-9830-356a5ebcc269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def float32_to_binary(num):\n",
    "    # Check if the number is negative\n",
    "    # if num < 0:\n",
    "        # raise ValueError(\"Number must be positive\")\n",
    "\n",
    "    # Convert the float number to 32-bit binary format\n",
    "    packed = struct.pack('f', num)\n",
    "    \n",
    "    # Convert the bytes to an integer\n",
    "    i = int.from_bytes(packed, byteorder='little', signed=False)\n",
    "    \n",
    "    # Format the integer to its binary representation and pad with zeros to 32 bits\n",
    "    return format(i, '032b')\n",
    "\n",
    "# Example usage\n",
    "num = 123.456\n",
    "binary_representation = float32_to_binary(num)\n",
    "print(\"Binary representation of\", num, \":\", binary_representation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d4359-ab77-4232-b458-24c338ddfdc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num = -0.456\n",
    "binary_representation = float32_to_binary(num)\n",
    "print(\"Binary representation of\", num, \":\", binary_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60226d69-df40-4d51-87e9-25bf656c0bed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### QPU ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db30ef13-6104-4a65-94c4-ac1871a97b04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beta_KL, beta_list_KL, rbm_energy_list_KL, dwave_energies_list_KL = engine.model.find_beta(7.0, 0.01, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041124ec-bbfc-4d21-8362-3f3dd0147813",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(beta_list_KL, linewidth=2.5, color=\"b\" )\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"β QA\")\n",
    "plt.legend([f'Chip {engine.model._qpu_sampler.properties[\"chip_id\"]}'])\n",
    "# plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/beta_QA_{engine.model._qpu_sampler.properties[\"chip_id\"]}_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca5a08b-6fee-454f-922d-1be7a5478fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 1:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a90c7-395e-4001-a502-0c163bb54e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beta_Hao, beta_list_Hao, rbm_energy_list_Hao, dwave_energies_list_Hao = engine.model.find_beta(4.0, 0.01, 20, 10.0, 'Hao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4076ce2-4fa3-483c-b265-4173f298df3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(beta_list_Hao, linewidth=2.5, color=\"b\" )\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"β QA\")\n",
    "plt.legend([f'Chip {engine.model._qpu_sampler.properties[\"chip_id\"]}'])\n",
    "# plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/beta_QA_{engine.model._qpu_sampler.properties[\"chip_id\"]}_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d3f64-df35-45a0-add1-50f27e84a4a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.plot(beta_list_Hao, linewidth=2.5, color=\"b\" )\n",
    "p0_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f861eb7f-e4e7-43d2-8219-584806b8802a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beta_init = 1.8\n",
    "# lr = 0.01\n",
    "num_epochs = 20\n",
    "Δbeta = 0.2\n",
    "beta = beta_init\n",
    "beta_list = []\n",
    "rbm_energy_list = []\n",
    "dwave_energies_list = []\n",
    "mean_rbm_energy_list = []\n",
    "mean_dwave_energy_list = []\n",
    "var_rbm_energy_list = []\n",
    "var_dwave_energy_list = []\n",
    "training_results = {}\n",
    "\n",
    "for epoch in range(num_epochs+1):\n",
    "    _,_,_,_, dwave_weights_rbm, dwave_bias_rbm = engine.model.ising_model(1.0)\n",
    "    # _,_,_,_, dwave_weights_rbm, dwave_bias_rbm = engine.model.ising_model(1.0)\n",
    "    h, J, qubit_idxs, idx_dict, dwave_weights, dwave_bias = engine.model.ising_model(1.0 / beta)\n",
    "    # if epoch == 0:\n",
    "    # prbm_sampler = PGBS(self.prior, 512, 3000)\n",
    "    p0_state, p1_state, p2_state, p3_state = engine.model.sampler.block_gibbs_sampling()\n",
    "    p0_ising = p0_state * 2 - 1\n",
    "    p1_ising = p1_state * 2 - 1\n",
    "    p2_ising = p2_state * 2 - 1\n",
    "    p3_ising = p3_state * 2 - 1\n",
    "    rbm_energies = engine.model.ising_energy(p0_ising, p1_ising, p2_ising, p3_ising, dwave_weights_rbm, dwave_bias_rbm)\n",
    "    rbm_energies = rbm_energies.detach().cpu().numpy()\n",
    "\n",
    "    response = engine.model._qpu_sampler.sample_ising(h, J, num_reads=256, auto_scale=False)\n",
    "    dwave_samples, dwave_energies, origSamples = engine.model.batch_dwave_samples(response, qubit_idxs)\n",
    "    # dwave_samples, dwave_energies = self.batch_dwave_samples(response, qubit_idxs)\n",
    "    nonpl = len(idx_dict['0'])\n",
    "    dwave_1, dwave_2, dwave_3, dwave_4 = dwave_samples[:,0:nonpl], dwave_samples[:,nonpl:2*nonpl], dwave_samples[:,2*nonpl:3*nonpl], dwave_samples[:,3*nonpl:4*nonpl]\n",
    "    dwave_1_t = torch.tensor(dwave_1).to(p0_ising.device).float()\n",
    "    dwave_2_t = torch.tensor(dwave_2).to(p0_ising.device).float()\n",
    "    dwave_3_t = torch.tensor(dwave_3).to(p0_ising.device).float()\n",
    "    dwave_4_t = torch.tensor(dwave_4).to(p0_ising.device).float()\n",
    "    dwave_energies = engine.model.ising_energy(dwave_1_t, dwave_2_t, dwave_3_t, dwave_4_t, dwave_weights_rbm, dwave_bias_rbm)\n",
    "    dwave_energies = dwave_energies.detach().cpu().numpy()\n",
    "    mean_rbm_energy = np.mean(rbm_energies)\n",
    "    mean_dwave_energy = np.mean(dwave_energies)\n",
    "    var_rbm_energy = np.var(rbm_energies)\n",
    "    var_dwave_energy = np.var(dwave_energies)\n",
    "\n",
    "    rbm_energy_list.append(rbm_energies)\n",
    "    dwave_energies_list.append(dwave_energies)\n",
    "    mean_rbm_energy_list.append(mean_rbm_energy)\n",
    "    mean_dwave_energy_list.append(mean_dwave_energy)\n",
    "    var_rbm_energy_list.append(var_rbm_energy)\n",
    "    var_dwave_energy_list.append(var_dwave_energy)\n",
    "    beta_list.append(beta)\n",
    "    print (f'Epoch {epoch}: beta = {beta}, DW/RBM = {mean_dwave_energy/mean_rbm_energy}')\n",
    "    beta = beta + Δbeta #lr * (mean_dwave_energy - mean_rbm_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e94b9-9c68-4508-a35a-99e6b397acb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.plot( rbmrbm_energy_list\n",
    "plt.plot( beta_list , np.array(mean_dwave_energy_list) / np.array(mean_rbm_energy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6790ca8-2502-411e-84aa-9a0698d5c95c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "\n",
    "plt.plot(beta_list, 1 + np.array([np.var(dwave_energies_list[i]) for i in range(len(dwave_energies_list))])/mean_rbm_energy_list, marker='o', markersize=15, linewidth=2.5, c='blue' )\n",
    "plt.plot(beta_list, 1 + 2 * np.array([np.var(dwave_energies_list[i]) for i in range(len(dwave_energies_list))])/mean_dwave_energy_list, marker='.', markersize=15, linewidth=2.5, c='orange' )\n",
    "plt.plot(beta_list, 1 + 10 * np.array([np.var(dwave_energies_list[i]) for i in range(len(dwave_energies_list))])/mean_dwave_energy_list, marker='+', markersize=15, linewidth=2.5, c='red')\n",
    "plt.legend([\"1\",\"2\",\"5\"], title=\"δ\", fontsize=15)\n",
    "plt.xlabel(\"β\", fontsize=15)\n",
    "# plt.axvspan(9, 9.5, color='purple', alpha=0.3)\n",
    "# label_x = (18.5) / 2\n",
    "# label_y = 0.2  # For example, 80% of the way up the y-axis\n",
    "# plt.text(label_x, label_y, 'Fixed point', horizontalalignment='center', verticalalignment='center', rotation=90, fontsize=15)\n",
    "\n",
    "# plt.ylabel(\"δ σ**2/<H>\")\n",
    "plt.ylabel(\"f(βQA)\", fontsize=18)\n",
    "plt.grid(\"True\")\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/stability_analysis_meth2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a55d95-a992-4aad-861b-3476d73958b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(beta_list, beta_list)\n",
    "plt.plot(beta_list, beta_list * np.array(mean_dwave_energy_list)/np.array(mean_rbm_energy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3b07fe-dfac-4fda-9476-00374d26313c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax1 = plt.subplots() \n",
    "# fig.figure(figsize=(7,5), dpi=100)\n",
    "ax1.plot(beta_list, np.abs(1 + np.array([np.var(dwave_energies_list[i]) for i in range(len(dwave_energies_list))])/mean_rbm_energy_list), marker='o', markersize=15, linewidth=2.5, c='blue' )\n",
    "ax1.plot(beta_list, np.abs(1 + 2 * np.array([np.var(dwave_energies_list[i]) for i in range(len(dwave_energies_list))])/mean_dwave_energy_list), marker='.', markersize=15, linewidth=2.5, c='orange' )\n",
    "ax1.plot(beta_list, np.abs(1 + 4 * np.array([np.var(dwave_energies_list[i]) for i in range(len(dwave_energies_list))])/mean_dwave_energy_list), marker='^', markersize=15, linewidth=2.5, c='red')\n",
    "ax1.legend([\"1\",\"2\",\"4\"], title=\"δ\", fontsize=15)\n",
    "ax1.set_xlabel(\"β\", fontsize=15)\n",
    "ax1.set_ylabel(\"λ(δ)\", fontsize=18)\n",
    "ax1.grid(\"True\")\n",
    "# ax1.axhline([1], color='black', linestyle='dashed', linewidth=1)\n",
    "ax1.axhspan(0, 1, facecolor='b', alpha=0.1)\n",
    "\n",
    "# # Adding Twin Axes to plot using dataset_2\n",
    "ax2 = ax1.twinx() \n",
    "\n",
    "color = 'm' #'tab:green'\n",
    "# ax2.set_ylabel('Y2-axis', color = color) \n",
    "# ax2.plot(x, dataset_2, color = color) \n",
    "ax2.plot( beta_list , np.array(mean_dwave_energy_list) / np.array(mean_rbm_energy_list), marker='p', markersize=7, linewidth=1.5, color = color)\n",
    "ax2.tick_params(axis ='y', labelcolor = color) \n",
    "ax2.set_ylabel(\"Ratio between QA and Classical Avg Energy\", fontsize=10, color = color)\n",
    "# ax2.set_yticks([1, 0.92])\n",
    "# ax2.grid(\"True\", color='black', linestyle='dashed', linewidth=1)\n",
    "ax2.axhline([1], color='black', linestyle='dashed', linewidth=1)\n",
    "plt.subplots_adjust(left=0.1, right=0.8, bottom=0.1, top=0.9)\n",
    "\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/stability_analysis_meth2.png')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b100fe0-3ba6-46c4-8281-5a798480d3df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.scatter(np.array([[1,2],[3,4]]).reshape(-1), np.array([[1,2],[3,4]]).reshape(-1))\n",
    "\n",
    "CM1 = torch.rand(1000).numpy()\n",
    "CMsn = torch.rand(1000).numpy()\n",
    "\n",
    "np.sqrt(np.power(CM1 - CMsn, 2).sum()/np.power(CM1, 2).sum())\n",
    "hlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f47c60d-9c8f-418f-8630-baf988798e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede5526-4a50-4c81-90fa-c273148a5512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(entarget_samples/1000, (xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1])\n",
    "plt.xlabel(\"incidence energy\")\n",
    "plt.ylabel(\"sparsity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c72414-d7ce-416d-b3ad-212c57a4b033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(entarget_samples.divide(1000).multiply(-0.004).exp(), (xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1])\n",
    "plt.xlabel(\"f(incidence energy)\")\n",
    "plt.ylabel(\"sparsity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee9f3f4-134b-4d7a-b074-67ab60f7b12d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Synth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad7e0f9-5453-48ba-a141-314e47b29a51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "# import torch\n",
    "\n",
    "# Replace 'your_file.h5' with the path to your HDF5 file\n",
    "file_path = '/raid/javier/Datasets/CaloVAE/data/atlas_dataset2and3/dataset_2_2.hdf5'\n",
    "data_dict = {}\n",
    "# Open the HDF5 file\n",
    "with h5py.File(file_path, 'r') as file:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % file.keys())\n",
    "    for key in file.keys():\n",
    "        data_dict[key] = torch.tensor(file[key][:])\n",
    "        \n",
    "        \n",
    "file_path = '/raid/javier/Datasets/CaloVAE/data/atlas_dataset2and3/dataset_2_1.hdf5'\n",
    "data_dict_tr = {}\n",
    "# Open the HDF5 file\n",
    "with h5py.File(file_path, 'r') as file:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % file.keys())\n",
    "    for key in file.keys():\n",
    "        data_dict_tr[key] = torch.tensor(file[key][:])\n",
    "        \n",
    "\n",
    "\n",
    "file_path = '/raid/javier/Datasets/CaloVAE/data/synData/dataset2_synthetic_honest-hill-454.hdf5'\n",
    "data_dict_syn = {}\n",
    "# Open the HDF5 file\n",
    "with h5py.File(file_path, 'r') as file:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % file.keys())\n",
    "    for key in file.keys():\n",
    "        data_dict_syn[key] = torch.tensor(file[key][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d51c252-fb10-48b1-8975-47ff7fcda769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xtarget_samples = data_dict['showers']\n",
    "xrecon_samples = data_dict_tr['showers']\n",
    "xgen_samples = data_dict_syn['showers']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee3fb7e-2580-4474-a35b-052f9a9dc0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HLF_1_electron.relevantLayers = [0,5,10,15,20,25,30,35,40,45]\n",
    "plt.figure(figsize=(8,6))\n",
    "# Create a grid of subplots\n",
    "fig, axes = plt.subplots(3,3, figsize=(12, 12), sharey=True, sharex=False, tight_layout=True)\n",
    "fig.text(0.5, 0.0, 'Energy per event (GeV)', ha='center', fontsize=15)\n",
    "fig.text(0.0, 0.5, 'Histogram', va='center', rotation='vertical', fontsize=15)\n",
    "\n",
    "# Iterate through the columns of X and plot histograms\n",
    "for i,_ in enumerate(HLF_1_electron.relevantLayers[:-1]):\n",
    "    row_index = i // 3  # Determine the row index\n",
    "    col_index = i % 3   # Determine the column index\n",
    "    \n",
    "    ax = axes[row_index, col_index]  # Get the current subplot\n",
    "    \n",
    "    # Plot histogram for the current column\n",
    "    idx = HLF_1_electron.relevantLayers[i+1]*9*16\n",
    "    idxPrev = (HLF_1_electron.relevantLayers[i])*9*16\n",
    "    l = idx - idxPrev\n",
    "    minVal, maxVal = min(xtarget_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000), max(xtarget_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000)\n",
    "    binwidth = (maxVal-minVal)/50\n",
    "    ax.hist(xtarget_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000,  bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7)\n",
    "    ax.hist(xrecon_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"c\")\n",
    "    # ax.hist(xrecon_samples_2[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=20, log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "    ax.hist(xgen_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashdot\")\n",
    "    # ax.hist(xgen_samples_qpu[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashed\")\n",
    "    if i == 0:\n",
    "        # ax.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], title=f'{ds[part]}')\n",
    "        ax.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], fontsize=15)\n",
    "    ax.grid(\"True\")\n",
    "    \n",
    "    # Set labels and title for the subplot\n",
    "    # ax.set_xlabel(f'Column {i + 1}')\n",
    "    # ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Layers {HLF_1_electron.relevantLayers[i]} to {HLF_1_electron.relevantLayers[i+1]-1}')\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_per_layer_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411251ba-57e5-4c23-b6ee-3ead4e4fcbe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

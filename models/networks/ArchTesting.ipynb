{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fcc5d86-50b8-4a16-a936-edeefd7daa98",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetworks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasicCoders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BasicDecoderV3\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPeriodicConvTranspose2d\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_channels, out_channels, kernel_size, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, dilation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from models.networks.basicCoders import BasicDecoderV3\n",
    "\n",
    "class PeriodicConvTranspose2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
    "        super(PeriodicConvTranspose2d, self).__init__()\n",
    "        self.padding = padding\n",
    "        self.conv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=0, dilation=dilation, groups=groups, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pad input tensor with periodic boundary conditions\n",
    "        x = F.pad(x, (self.padding, self.padding, self.padding, self.padding), mode='circular')\n",
    "        # Apply convolution\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class sequentialMultiInput(nn.Sequential):\n",
    "    def forward(self, *inputs):\n",
    "        for module in self._modules.values():\n",
    "            if type(inputs) == tuple:\n",
    "                inputs = module(*inputs)\n",
    "            else:\n",
    "                inputs = module(inputs)\n",
    "        return inputs\n",
    "\n",
    "class DecoderCNNPBv4_HEMOD(BasicDecoderV3):\n",
    "    def __init__(self, num_input_nodes, num_output_nodes, output_activation_fct=nn.Identity(), **kwargs):\n",
    "        super(DecoderCNNPBv4_HEMOD, self).__init__(**kwargs)\n",
    "        self._output_activation_fct = output_activation_fct\n",
    "        self.num_input_nodes = num_input_nodes\n",
    "        self.z = 45\n",
    "        self.r = 9\n",
    "        self.phi = 16\n",
    "        self.hierarchal_outputs = num_output_nodes\n",
    "        self.output_layers = int(self.hierarchal_outputs / 144)\n",
    "        \n",
    "        # self._node_sequence = [(2049, 800), (800, 700), (700, 600), (600, 550), (550, 500), (500, 6480)]\n",
    "        self._layers =  nn.Sequential(\n",
    "                   # nn.Unflatten(1, (self._node_sequence[0][0]-1, 1,1)),\n",
    "                   nn.Unflatten(1, (self.num_input_nodes, 1,1)),\n",
    "\n",
    "                   PeriodicConvTranspose2d(self.num_input_nodes, 1024, (3,5), 2, 0),\n",
    "                   nn.BatchNorm2d(1024),\n",
    "                   nn.PReLU(1024, 0.02),\n",
    "                   \n",
    "\n",
    "                   PeriodicConvTranspose2d(1024, 512, (3,5), 1, 0),\n",
    "                   nn.BatchNorm2d(512),\n",
    "                   nn.PReLU(512, 0.02),\n",
    "                                   )\n",
    "        \n",
    "        self._layers2 = nn.Sequential(\n",
    "                   PeriodicConvTranspose2d(513, 128, (3,5), 1, 0),\n",
    "                   nn.BatchNorm2d(128),\n",
    "                   nn.PReLU(128, 0.02),\n",
    "\n",
    "                   PeriodicConvTranspose2d(128, self.output_layers, (3,4), 1, 0),\n",
    "                   # nn.BatchNorm2d(45),\n",
    "                   nn.PReLU(self.output_layers, 1.0),\n",
    "                                   )\n",
    "        \n",
    "        self._layers3 = nn.Sequential(\n",
    "                   PeriodicConvTranspose2d(513, 128, (3,5), 1, 0),\n",
    "                   nn.BatchNorm2d(128),\n",
    "                   nn.PReLU(128, 0.02),\n",
    "\n",
    "                   PeriodicConvTranspose2d(128, self.output_layers, (3,4), 1, 0),\n",
    "                   # nn.BatchNorm2d(45),\n",
    "                   nn.PReLU(self.output_layers, 0.02),\n",
    "                                   )\n",
    "        \n",
    "    def forward(self, x, x0):\n",
    "        print(\"t1: \", x.shape)\n",
    "        x = self._layers(x)\n",
    "        print(\"t2: \", x.shape)\n",
    "        x0 = self.trans_energy(x0)\n",
    "        xx0 = torch.cat((x, x0.unsqueeze(2).unsqueeze(3).repeat(1,1,torch.tensor(x.shape[-2:-1]).item(), torch.tensor(x.shape[-1:]).item())), 1)\n",
    "        x1 = self._layers2(xx0)\n",
    "        x2 = self._layers3(xx0)\n",
    "        # need channels * height * width = self.hierarchal_outputs = 1620\n",
    "        return x1.reshape(x1.shape[0], self.hierarchal_outputs), x2.reshape(x1.shape[0], self.hierarchal_outputs)\n",
    "    \n",
    "    def trans_energy(self, x0, log_e_max=14.0, log_e_min=6.0, s_map = 15 * 1.2812657528661318):\n",
    "        # s_map = max(scaled voxel energy u_i) * (incidence energy / slope of total energy in shower) of the dataset\n",
    "        return ((torch.log(x0) - log_e_min)/(log_e_max - log_e_min)) * s_map\n",
    "\n",
    "class DecoderCNNPB_HEv1(BasicDecoderV3):\n",
    "    def __init__(self, encArch = 'Large', **kwargs):\n",
    "        self.encArch = encArch\n",
    "        super(DecoderCNNPB_HEv1, self).__init__(**kwargs)\n",
    "\n",
    "    def _create_hierarchy_network(self, level: int = 0):\n",
    "        self.latent_nodes = 2048\n",
    "        self.layer_step = 11*144\n",
    "        self.hierarchiel_lvls = 4\n",
    "\n",
    "        inp_layers = [self.latent_nodes + i * self.layer_step for i in range(self.hierarchiel_lvls)] \n",
    "        out_layers = 4 * [self.layer_step]\n",
    "        out_layers[3] += (6480 - 4 * self.layer_step)\n",
    "\n",
    "        self.moduleLayers = nn.ModuleList([])\n",
    "        for i in range(len(inp_layers)):\n",
    "            self.moduleLayers.append(DecoderCNNPBv4_HEMOD(inp_layers[i], out_layers[i]))\n",
    "            \n",
    "        sequential = sequentialMultiInput(*self.moduleLayers)\n",
    "        return sequential\n",
    "    \n",
    "    def forward(self, x, x0):\n",
    "        self._create_hierarchy_network()\n",
    "        self.sub_values = []\n",
    "        x1, x2 = torch.tensor([]), torch.tensor([])\n",
    "        for lvl in range(self.hierarchiel_lvls):\n",
    "            cur_net = self.moduleLayers[lvl]\n",
    "            hits, acts = cur_net(x, x0)\n",
    "            beta = torch.tensor(self._config.model.output_smoothing_fct, dtype=torch.float, device=output_hits.device, requires_grad=False)\n",
    "            out.output_activations = self._energy_activation_fct(output_activations) * self._hit_smoothing_dist_mod(output_hits, beta, is_training)\n",
    "            z = out.output_activations\n",
    "            self.sub_values.append([hits, acts])\n",
    "            if lvl == self.hierarchiel_lvls - 1:\n",
    "                for vals in self.sub_values:\n",
    "                    x1 = torch.cat((x1, vals[0]), dim=1)\n",
    "                    x2 = torch.cat((x2, vals[1]), dim=1)\n",
    "            else:\n",
    "                x = torch.cat((x, z), dim=1)\n",
    "        return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c69ca-1c4e-4e23-a19a-c0340999d2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1669d94-b856-4cf7-9a9d-d4ffbcb75423",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeriodicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
    "        super(PeriodicConv2d, self).__init__()\n",
    "        self.padding = padding\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=0, dilation=dilation, groups=groups, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pad input tensor with periodic boundary conditions\n",
    "        x = F.pad(x, (self.padding, self.padding, 0, 0), mode='circular')\n",
    "        # Apply convolution\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a59cbe1a-58a0-4c3b-8109-adeeea0ceac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeriodicConv3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
    "        super(PeriodicConv3d, self).__init__()\n",
    "        self.padding = padding\n",
    "        # try 3x3x3 cubic convolution\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=0, dilation=dilation, groups=groups, bias=bias)\n",
    "    def forward(self, x):\n",
    "        # Pad input tensor with periodic boundary and circle-center conditions\n",
    "        if self.padding == 1:\n",
    "            mid = x.shape[-1] // 2\n",
    "            shift = torch.cat((x[..., [-1], mid:], x[..., [-1], :mid]), -1)\n",
    "            x = torch.cat((x, shift), dim=-2)\n",
    "        x = F.pad(x, (self.padding, self.padding, 0, 0, 0, 0), mode='circular')\n",
    "        # Apply convolution\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c534c9e6-31c4-4dd2-8398-7aadacedb03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeriodicConv3d_v2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
    "        super(PeriodicConv3d_v2, self).__init__()\n",
    "        self.padding = padding\n",
    "        # try 3x3x3 cubic convolution\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=0, dilation=dilation, groups=groups, bias=bias)\n",
    "    def forward(self, x):\n",
    "        # Pad input tensor with periodic boundary and circle-center conditions\n",
    "        if self.padding == 1:\n",
    "            mid = x.shape[-2] // 2\n",
    "            shift = torch.cat((x[..., mid:, [0]], x[..., :mid, [0]]), -2)\n",
    "            x = torch.cat((shift,x), dim=-1)\n",
    "        x = F.pad(x, (0, 0, self.padding, self.padding, 0, 0), mode='circular')\n",
    "        # Apply convolution\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9f2a949-6d7d-4595-b8f8-e22d997b0c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 45, 9, 16])\n"
     ]
    }
   ],
   "source": [
    "data = torch.rand([32, 1, 45, 9, 16])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "48f2ead4-6f42-49c8-95fd-0d76c611e0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): PeriodicConv3d(\n",
      "    (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(2, 1, 1))\n",
      "  )\n",
      "  (1): PeriodicConv3d(\n",
      "    (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 1, 1))\n",
      "  )\n",
      "  (2): PeriodicConv3d(\n",
      "    (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 2))\n",
      "  )\n",
      "  (3): PeriodicConv3d(\n",
      "    (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 1, 2))\n",
      "  )\n",
      "  (4): PeriodicConv3d(\n",
      "    (conv): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  )\n",
      ")\n",
      "Input Shape:  torch.Size([32, 1, 45, 9, 16])\n",
      "Cur Shape:  torch.Size([32, 32, 22, 8, 16])\n",
      "Size:  90112\n",
      "Cur Shape:  torch.Size([32, 64, 10, 7, 16])\n",
      "Size:  71680\n",
      "Cur Shape:  torch.Size([32, 128, 8, 5, 7])\n",
      "Size:  35840\n",
      "Cur Shape:  torch.Size([32, 256, 3, 3, 3])\n",
      "Size:  6912\n",
      "Cur Shape:  torch.Size([32, 512, 1, 1, 1])\n",
      "Size:  512\n"
     ]
    }
   ],
   "source": [
    "# Encoder Conv Testing \n",
    "conv1 = nn.Sequential(\n",
    "    PeriodicConv3d(1, 32, (3,3,3), (2,1,1), 1),\n",
    "    PeriodicConv3d(32, 64, (3,3,3), (2,1,1), 1),\n",
    "    # nn.BatchNorm3d(64),\n",
    "    # nn.PReLU(64, 0.02),\n",
    "    PeriodicConv3d(64, 128, (3,3,3), (1,1,2), 0),\n",
    "    PeriodicConv3d(128, 256, (3,3,3), (2,1,2), 0),\n",
    "    PeriodicConv3d(256, 512, (3,3,3), (1,1,1), 0),\n",
    ")\n",
    "# conv2 = PeriodicConv3d(16, 32, 3, 1, 1)\n",
    "# conv3 = PeriodicConv3d(32, 64, 3, 1, 1)\n",
    "# xt = conv1(data)\n",
    "xt = data\n",
    "\n",
    "print(conv1)\n",
    "print(\"Input Shape: \", xt.shape)\n",
    "for layer in conv1:\n",
    "    xt = layer(xt)\n",
    "    print(\"Cur Shape: \", xt.shape)\n",
    "    print(\"Size: \", xt.shape[1] * xt.shape[2] * xt.shape[3] * xt.shape[4])\n",
    "\n",
    "# xt = conv3(conv2(conv1(data)))\n",
    "# shape of 3d data (batch_sizes, depth, height, width) \n",
    "# width gets padded so 3, 3, 5 in this example\n",
    "# print(xt.shape)\n",
    "#torch.Size([32, 128, 29, 1, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0dcfc60f-a444-4532-ab4d-c07d193310e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeriodicConvTranspose3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, dilation=1, groups=1, bias=True):\n",
    "        super(PeriodicConvTranspose3d, self).__init__()\n",
    "        self.padding = padding\n",
    "        self.conv = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=0, dilation=dilation, groups=groups, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pad input tensor with periodic boundary conditions\n",
    "        if self.padding == 1:\n",
    "            mid = x.shape[-1] // 2\n",
    "            shift = torch.cat((x[..., [-1], mid:], x[..., [-1], :mid]), -1)\n",
    "            x = torch.cat((x, shift), dim=-2)\n",
    "        x = F.pad(x, (self.padding, self.padding, 0, 0, 0, 0), mode='circular')\n",
    "        # Apply convolution\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f7c3fdd1-49e0-4bd8-9800-791e9d0dfe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class PeriodicConv3d_v2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "                 dilation=1, groups=1, bias=True):\n",
    "        super(PeriodicConv3d_v2, self).__init__()\n",
    "        self.padding = padding\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, \n",
    "                              padding=0, dilation=dilation, groups=groups, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pad input tensor with periodic boundary conditions\n",
    "        if self.padding == 1:\n",
    "            mid = x.shape[-2] // 2\n",
    "            shift = torch.cat((x[..., mid:, :1], x[..., :mid, :1]), -2)\n",
    "            x = torch.cat((shift, x), dim=-1)\n",
    "        x = F.pad(x, (0, 0, self.padding, self.padding, 0, 0), mode='circular')\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class PeriodicConvTranspose3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "                 output_padding=0, groups=1, bias=True, dilation=1):\n",
    "        super(PeriodicConvTranspose3d, self).__init__()\n",
    "        self.padding = padding\n",
    "        self.conv_transpose = nn.ConvTranspose3d(\n",
    "            in_channels, out_channels, kernel_size, stride=stride, padding=0,\n",
    "            output_padding=0, groups=groups, bias=bias, dilation=dilation\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pad input tensor with periodic boundary conditions\n",
    "        if self.padding == 1:\n",
    "            mid = x.shape[-2] // 2\n",
    "            shift = torch.cat((x[..., mid:, :1], x[..., :mid, :1]), -2)\n",
    "            x = torch.cat((shift, x), dim=-1)\n",
    "        x = F.pad(x, (0, 0, self.padding, self.padding, 0, 0), mode='circular')\n",
    "        x = self.conv_transpose(x)\n",
    "        return x\n",
    "\n",
    "class UNetPBH3Dv3(nn.Module):\n",
    "    def __init__(self, num_input_nodes, n_latent_nodes=952):\n",
    "        super(UNetPBH3Dv3, self).__init__()\n",
    "        self.num_input_nodes = num_input_nodes\n",
    "        self.n_latent_nodes = n_latent_nodes\n",
    "        self.z = 45\n",
    "        self.phi = 9\n",
    "        self.r = 16\n",
    "\n",
    "        # Encoder\n",
    "        self.enc_conv1 = nn.Sequential(\n",
    "            PeriodicConv3d_v2(1, 32, (3,3,3), stride=(2,1,1), padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.PReLU(32, 0.02)\n",
    "        )\n",
    "\n",
    "        self.enc_conv2 = nn.Sequential(\n",
    "            PeriodicConv3d_v2(32, 64, (3,3,3), stride=(2,1,1), padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.PReLU(64, 0.02)\n",
    "        )\n",
    "\n",
    "        self.enc_conv3 = nn.Sequential(\n",
    "            PeriodicConv3d_v2(64, 128, (3,3,3), stride=(1,2,1), padding=1),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.PReLU(128, 0.02)\n",
    "        )\n",
    "\n",
    "        # Incorporate x0 (energy) into the feature map\n",
    "        self.enc_conv4 = nn.Sequential(\n",
    "            PeriodicConv3d_v2(129, 256, (3,3,3), stride=(2,2,1), padding=0),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.PReLU(256, 0.02)\n",
    "        )\n",
    "\n",
    "        self.enc_conv5 = nn.Sequential(\n",
    "            PeriodicConv3d_v2(256, self.n_latent_nodes, (3,3,3), stride=(1,2,2), padding=0),\n",
    "            nn.PReLU(self.n_latent_nodes, 1.0)\n",
    "        )\n",
    "\n",
    "        # Decoder with specified transpose convolutions and skip connections\n",
    "        # Include a convolution after concatenation to adjust channel sizes\n",
    "        self.dec_conv1 = nn.Sequential(\n",
    "            # Adjust channels after concatenation\n",
    "            PeriodicConv3d_v2(self.n_latent_nodes + 256, 1208, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm3d(1208),\n",
    "            nn.PReLU(1208, 0.02),\n",
    "            # Transpose convolution\n",
    "            PeriodicConvTranspose3d(1208, 512, (3,3,3), stride=(1,1,1), padding=0),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.PReLU(512, 0.02)\n",
    "        )\n",
    "\n",
    "        self.dec_conv2 = nn.Sequential(\n",
    "            # Adjust channels after concatenation\n",
    "            PeriodicConv3d_v2(512 + 128, 512, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.PReLU(512, 0.02),\n",
    "            # Transpose convolution\n",
    "            PeriodicConvTranspose3d(512, 128, (4,3,3), stride=(2,1,2), padding=0),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.PReLU(128, 0.02)\n",
    "        )\n",
    "\n",
    "        self.dec_conv3 = nn.Sequential(\n",
    "            # Adjust channels after concatenation\n",
    "            PeriodicConv3d_v2(128 + 64, 128, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.PReLU(128, 0.02),\n",
    "            # Transpose convolution\n",
    "            PeriodicConvTranspose3d(128, 64, (3,3,3), stride=(1,1,2), padding=0),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.PReLU(64, 0.02)\n",
    "        )\n",
    "\n",
    "        self.dec_conv4 = nn.Sequential(\n",
    "            # Adjust channels after concatenation\n",
    "            PeriodicConv3d_v2(64 + 32, 64, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.PReLU(64, 0.02),\n",
    "            # Transpose convolution\n",
    "            PeriodicConvTranspose3d(64, 32, (4,3,2), stride=(2,1,1), padding=0),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.PReLU(32, 0.02)\n",
    "        )\n",
    "\n",
    "        self.dec_conv5 = nn.Sequential(\n",
    "            PeriodicConvTranspose3d(32, 1, (3,1,1), stride=(2,1,1), padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, x0):\n",
    "        # Reshape and position encoding\n",
    "        x = x.reshape(x.shape[0], 1, self.z, self.phi, self.r)\n",
    "\n",
    "        # Encoder path\n",
    "        x1 = self.enc_conv1(x)  # [batch, 32, z1, phi1, r1]\n",
    "        x2 = self.enc_conv2(x1) # [batch, 64, z2, phi2, r2]\n",
    "        x3 = self.enc_conv3(x2) # [batch, 128, z3, phi3, r3]\n",
    "\n",
    "        # Process x0 and concatenate\n",
    "        x0_trans = self.trans_energy(x0)\n",
    "        x0_trans = x0_trans.unsqueeze(1).unsqueeze(2).unsqueeze(3).unsqueeze(4)\n",
    "        x0_trans = x0_trans.expand(-1, -1, x3.shape[2], x3.shape[3], x3.shape[4])\n",
    "        x3_cat = torch.cat((x3, x0_trans), dim=1)  # [batch, 129, z3, phi3, r3]\n",
    "\n",
    "        x4 = self.enc_conv4(x3_cat)  # [batch, 256, z4, phi4, r4]\n",
    "        x5 = self.enc_conv5(x4)      # [batch, n_latent_nodes, z5, phi5, r5]\n",
    "\n",
    "        # Decoder path with skip connections and convolution after concatenation\n",
    "        # First decoder layer\n",
    "        x = torch.cat((x5, x4), dim=1)  # [batch, n_latent_nodes + 256, ...]\n",
    "        x = self.dec_conv1(x)           # [batch, 512, ...]\n",
    "\n",
    "        # Second decoder layer\n",
    "        x = torch.cat((x, x3), dim=1)   # [batch, 512 + 128, ...]\n",
    "        x = self.dec_conv2(x)           # [batch, 128, ...]\n",
    "\n",
    "        # Third decoder layer\n",
    "        x = torch.cat((x, x2), dim=1)   # [batch, 128 + 64, ...]\n",
    "        x = self.dec_conv3(x)           # [batch, 64, ...]\n",
    "\n",
    "        # Fourth decoder layer\n",
    "        x = torch.cat((x, x1), dim=1)   # [batch, 64 + 32, ...]\n",
    "        x = self.dec_conv4(x)           # [batch, 32, ...]\n",
    "\n",
    "        # Output layer\n",
    "        x = self.dec_conv5(x)           # [batch, 1, ...]\n",
    "\n",
    "        return x\n",
    "\n",
    "    def trans_energy(self, x0, log_e_max=14.0, log_e_min=6.0, s_map=1.0):\n",
    "        return ((torch.log(x0) - log_e_min) / (log_e_max - log_e_min)) * s_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4ea3dca1-6e78-43ee-88d4-7bdfeaf1c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock3DUNETv1(nn.Module):\n",
    "    def __init__(self, num_input_nodes, n_latent_nodes):\n",
    "        super(EncoderBlock3DUNETv1, self).__init__()\n",
    "        self.num_input_nodes = num_input_nodes\n",
    "        self.n_latent_nodes = 4 * n_latent_nodes\n",
    "        self.z = 45\n",
    "        self.r = 9\n",
    "        self.phi = 16\n",
    "        \n",
    "        self.seq1 = nn.Sequential(\n",
    "                   # nn.Linear(self.num_input_nodes, 24*24),\n",
    "                   # nn.Unflatten(1, (1,24, 24)),\n",
    "    \n",
    "                   PeriodicConv3d(1, 32, (3,3,3), (2,1,1), 1),\n",
    "                   nn.BatchNorm3d(32),\n",
    "                   nn.PReLU(32, 0.02),\n",
    "    \n",
    "                   PeriodicConv3d(32, 64, (3,3,3), (2,1,1), 1),\n",
    "                   nn.BatchNorm3d(64),\n",
    "                   nn.PReLU(64, 0.02),\n",
    "\n",
    "                   PeriodicConv3d(64, 128, (3,3,3), (1,1,2), 0),\n",
    "                   nn.BatchNorm3d(128),\n",
    "                   nn.PReLU(128, 0.02),\n",
    "                )\n",
    "\n",
    "        self.seq2 = nn.Sequential(\n",
    "                           PeriodicConv3d(129, 512, (3,3,3), (2,1,2), 0),\n",
    "                           nn.BatchNorm3d(512),\n",
    "                           nn.PReLU(512, 0.02),\n",
    "\n",
    "                           PeriodicConv3d(512, self.n_latent_nodes, (3,3,3), (1,2,1), 0),\n",
    "                           nn.PReLU(self.n_latent_nodes, 1.0),\n",
    "                           nn.Flatten(),\n",
    "                        )\n",
    "        \n",
    "\n",
    "    def forward(self, x, x0):\n",
    "        # list for skip connections\n",
    "        skip_connections = []\n",
    "        \n",
    "        # 1 channel of a 3d object / shower\n",
    "        x = x.reshape(x.shape[0], 1, self.z, self.r,self.phi) \n",
    "        for layer in self.seq1:\n",
    "            x = layer(x)\n",
    "            if isinstance(layer, nn.PReLU):  # store output after prelu act\n",
    "                skip_connections.append(x)\n",
    "\n",
    "        x0 = self.trans_energy(x0)\n",
    "        x = torch.cat((x, x0.unsqueeze(2).unsqueeze(3).unsqueeze(4).repeat(1,1,torch.tensor(x.shape[-3:-2]).item(),torch.tensor(x.shape[-2:-1]).item(), torch.tensor(x.shape[-1:]).item())), 1)\n",
    " \n",
    "        for layer in self.seq2:\n",
    "            x = layer(x)\n",
    "            \n",
    "            if isinstance(layer, nn.PReLU):  # Store output after each PReLU activation or final Flatten layer\n",
    "                # print(\"seq 2 if: \", x, x.shape)\n",
    "                skip_connections.append(x)\n",
    "\n",
    "        return x, skip_connections\n",
    "        \n",
    "    def trans_energy(self, x0, log_e_max=14.0, log_e_min=6.0, s_map = 1):\n",
    "        # s_map = max(scaled voxel energy u_i) * (incidence energy / slope of total energy in shower) of the dataset\n",
    "        return ((torch.log(x0) - log_e_min)/(log_e_max - log_e_min)) * s_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f38d0d33-fd6d-4dd0-a9b4-012d1af50a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 45, 9, 16])\n",
      "torch.Size([32, 32, 22, 8, 16])\n",
      "torch.Size([32, 32, 22, 8, 16])\n",
      "torch.Size([32, 32, 22, 8, 16])\n",
      "torch.Size([32, 64, 10, 7, 16])\n",
      "torch.Size([32, 64, 10, 7, 16])\n",
      "torch.Size([32, 64, 10, 7, 16])\n",
      "torch.Size([32, 128, 8, 5, 7])\n",
      "torch.Size([32, 128, 8, 5, 7])\n",
      "torch.Size([32, 1208])\n",
      "torch.Size([32, 32, 22, 8, 16])\n",
      "torch.Size([32, 64, 10, 7, 16])\n",
      "torch.Size([32, 128, 8, 5, 7])\n",
      "torch.Size([32, 512, 3, 3, 3])\n",
      "torch.Size([32, 1208, 1, 1, 1])\n",
      "skips:  torch.Size([32, 32, 22, 8, 16])\n",
      "skips:  torch.Size([32, 64, 10, 7, 16])\n",
      "skips:  torch.Size([32, 128, 8, 5, 7])\n",
      "skips:  torch.Size([32, 512, 3, 3, 3])\n",
      "skips:  torch.Size([32, 1208, 1, 1, 1])\n",
      "torch.Size([32, 32, 22, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "model = EncoderBlock3DUNETv1(num_input_nodes=10, n_latent_nodes=302)\n",
    "\n",
    "# Random input tensor\n",
    "x = torch.randn(32, 1, 45, 9, 16)  # Batch size of 2, input size of 10\n",
    "x0 = torch.randn(32, 1)  # Secondary input\n",
    "x0 = x0 - 2* min(x0)\n",
    "\n",
    "# Run the model\n",
    "output, skip_connections = model(x, x0)\n",
    "for skips in skip_connections: print(\"skips: \", skips.shape)\n",
    "\n",
    "print(skip_connections[0].shape)\n",
    "# print(skip_connections[3], (skip_connections[3]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "59de5376-109e-4508-a3b7-a062e2e2081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderCNNPB3DUNETv1(nn.Module):\n",
    "    def __init__(self, output_activation_fct=nn.Identity(),num_output_nodes=368, **kwargs):\n",
    "        super(DecoderCNNPB3DUNETv1, self).__init__(**kwargs)\n",
    "        self._output_activation_fct=output_activation_fct\n",
    "        self.num_output_nodes = num_output_nodes\n",
    "        self.z = 45\n",
    "        self.r = 9\n",
    "        self.phi = 16\n",
    "\n",
    "        # self.n_latent_nodes = self._config.model.n_latent_nodes\n",
    "        self.n_latent_nodes = 302* 4\n",
    "\n",
    "        # dropout for regularization\n",
    "        # self.dropout = nn.Dropout3d(self._config.model.dropout_prob)\n",
    "        \n",
    "        # self._node_sequence = [(2049, 800), (800, 700), (700, 600), (600, 550), (550, 500), (500, 6480)]\n",
    "        self.dec_conv1 = nn.Sequential(\n",
    "            # Adjust channels after concatenation\n",
    "            PeriodicConv3d_v2(self.n_latent_nodes, 1208, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm3d(1208),\n",
    "            nn.PReLU(1208, 0.02),\n",
    "            # Transpose convolution\n",
    "            PeriodicConvTranspose3d(1208, 512, (3,3,3), stride=(1,1,1), padding=0),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.PReLU(512, 0.02)\n",
    "        )\n",
    "\n",
    "        self.dec_conv2 = nn.Sequential(\n",
    "            # Adjust channels after concatenation\n",
    "            PeriodicConv3d_v2(512 + 512, 512, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.PReLU(512, 0.02),\n",
    "            # Transpose convolution\n",
    "            PeriodicConvTranspose3d(512, 128, (4,3,3), stride=(2,1,2), padding=0),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.PReLU(128, 0.02)\n",
    "        )\n",
    "\n",
    "        self.dec_conv3r1 = nn.Sequential(\n",
    "            # Adjust channels after concatenation\n",
    "            PeriodicConv3d_v2(129 + 128, 128, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.PReLU(128, 0.02),\n",
    "            # Transpose convolution\n",
    "            PeriodicConvTranspose3d(128, 64, (3,3,4), stride=(1,1,2), padding=0),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.PReLU(64, 0.02)\n",
    "        )\n",
    "\n",
    "        self.dec_conv4r1 = nn.Sequential(\n",
    "            # Adjust channels after concatenation\n",
    "            PeriodicConv3d_v2(64 + 64, 64, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.PReLU(64, 0.02),\n",
    "            # Transpose convolution\n",
    "            PeriodicConvTranspose3d(64, 32, (4,2,1), stride=(2,1,1), padding=0),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.PReLU(32, 1.0)\n",
    "        )\n",
    "\n",
    "        self.dec_conv5r1 = nn.Sequential(\n",
    "            PeriodicConvTranspose3d(32+32, 1, (3,2,1), stride=(2,1,1), padding=0),\n",
    "            nn.PReLU(1, 1.0)\n",
    "        )\n",
    "\n",
    "        self.dec_conv3r2 = nn.Sequential(\n",
    "            # Adjust channels after concatenation\n",
    "            PeriodicConv3d_v2(129 + 128, 128, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.PReLU(128, 0.02),\n",
    "            # Transpose convolution\n",
    "            PeriodicConvTranspose3d(128, 64, (3,3,4), stride=(1,1,2), padding=0),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.PReLU(64, 0.02)\n",
    "        )\n",
    "\n",
    "        self.dec_conv4r2 = nn.Sequential(\n",
    "            # Adjust channels after concatenation\n",
    "            PeriodicConv3d_v2(64 + 64, 64, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.PReLU(64, 0.02),\n",
    "            # Transpose convolution\n",
    "            PeriodicConvTranspose3d(64, 32, (4,2,1), stride=(2,1,1), padding=0),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.PReLU(32, 0.02)\n",
    "        )\n",
    "\n",
    "        self.dec_conv5r2 = nn.Sequential(\n",
    "            PeriodicConvTranspose3d(32+32, 1, (3,2,1), stride=(2,1,1), padding=0),\n",
    "            nn.PReLU(1, 1.0)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x, x0, skip_connections):\n",
    "        x = self.dec_conv1(x)      \n",
    "        print(x.shape, (skip_connections[3]).shape)\n",
    "        x = torch.cat((x, skip_connections[3]), dim=1)  \n",
    "        print(x.shape, (skip_connections[3]).shape)\n",
    "        x = self.dec_conv2(x)  \n",
    "        xx0 = torch.cat((x, x0.unsqueeze(2).unsqueeze(3).unsqueeze(4).repeat(1,1,torch.tensor(x.shape[-3:-2]).item(),torch.tensor(x.shape[-2:-1]).item(), torch.tensor(x.shape[-1:]).item())), 1)\n",
    "        x1 = torch.cat((xx0, skip_connections[2]), dim=1)   \n",
    "        x1 = self.dec_conv3r1(x1)      \n",
    "        x1 = torch.cat((x1, skip_connections[1]), dim=1)  \n",
    "        x1 = self.dec_conv4r1(x1)         \n",
    "        x1 = torch.cat((x1, skip_connections[0]), dim=1)\n",
    "        x1 = self.dec_conv5r1(x1)         \n",
    "\n",
    "        x2 = torch.cat((xx0, skip_connections[2]), dim=1)   \n",
    "        x2 = self.dec_conv3r2(x2)         \n",
    "        x2 = torch.cat((x2, skip_connections[1]), dim=1)  \n",
    "        x2 = self.dec_conv4r2(x2)         \n",
    "        x2 = torch.cat((x2, skip_connections[0]), dim=1)\n",
    "        x2 = self.dec_conv5r2(x2)          \n",
    "        return x1.reshape(x1.shape[0],self.z*self.r*self.phi), x2.reshape(x1.shape[0],self.z*self.r*self.phi)\n",
    "\n",
    "    \n",
    "    def trans_energy(self, x0, log_e_max=14.0, log_e_min=6.0):\n",
    "        return (torch.log(x0) - log_e_min)/(log_e_max - log_e_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "dc078fce-ce1b-44fe-9d36-431592e98dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512, 3, 3, 3]) torch.Size([32, 512, 3, 3, 3])\n",
      "torch.Size([32, 1024, 3, 3, 3]) torch.Size([32, 512, 3, 3, 3])\n",
      "torch.Size([32, 6480])\n"
     ]
    }
   ],
   "source": [
    "model = DecoderCNNPB3DUNETv1()\n",
    "\n",
    "# Random input tensor\n",
    "x = torch.randn(32, 1208, 1, 1, 1)  # Batch size of 2, input size of 10\n",
    "x0 = torch.randn(32, 1)  # Secondary input\n",
    "\n",
    "# Run the model\n",
    "x1, x2 = model(x, x0, skip_connections)\n",
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2a56e490-feea-41e7-bb62-3c4f83d9f0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32, 22, 8, 16])\n",
      "torch.Size([32, 64, 10, 7, 16])\n",
      "torch.Size([32, 128, 8, 5, 7])\n",
      "torch.Size([32, 512, 3, 3, 3])\n",
      "torch.Size([32, 1208, 1, 1, 1])\n",
      "torch.Size([32, 512, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor_sizes = [\n",
    "    (32, 32, 22, 8, 16),\n",
    "    (32, 64, 10, 7, 16),\n",
    "    (32, 128, 8, 5, 7),\n",
    "    (32, 512, 3, 3, 3),\n",
    "    (32, 1208, 1, 1, 1)\n",
    "]\n",
    "\n",
    "random_tensors = [torch.randn(size) for size in tensor_sizes]\n",
    "for tensor in random_tensors: print(tensor.shape)\n",
    "\n",
    "print(random_tensors[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b2cdbee-a4ac-4971-b493-76875ba7b338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Unflatten(dim=1, unflattened_size=(1208, 1, 1, 1))\n",
      "  (1): PeriodicConvTranspose3d(\n",
      "    (conv): ConvTranspose3d(1208, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  )\n",
      "  (2): PeriodicConvTranspose3d(\n",
      "    (conv): ConvTranspose3d(512, 128, kernel_size=(4, 3, 3), stride=(2, 1, 2))\n",
      "  )\n",
      "  (3): PeriodicConvTranspose3d(\n",
      "    (conv): ConvTranspose3d(128, 64, kernel_size=(3, 2, 3), stride=(2, 1, 1))\n",
      "  )\n",
      "  (4): PeriodicConvTranspose3d(\n",
      "    (conv): ConvTranspose3d(64, 32, kernel_size=(5, 3, 3), stride=(2, 1, 2))\n",
      "  )\n",
      "  (5): PeriodicConvTranspose3d(\n",
      "    (conv): ConvTranspose3d(32, 1, kernel_size=(5, 3, 2), stride=(1, 1, 1))\n",
      "  )\n",
      "  (6): PeriodicConv3d(\n",
      "    (conv): Conv3d(1, 1, kernel_size=(41, 1, 1), stride=(1, 1, 1))\n",
      "  )\n",
      ")\n",
      "Input Shape:  torch.Size([32, 1208])\n",
      "Cur Shape:  torch.Size([32, 1208, 1, 1, 1])\n",
      "Cur Shape:  torch.Size([32, 512, 3, 3, 3])\n",
      "Cur Shape:  torch.Size([32, 128, 8, 5, 7])\n",
      "Cur Shape:  torch.Size([32, 64, 17, 6, 9])\n",
      "Cur Shape:  torch.Size([32, 32, 37, 8, 19])\n",
      "Cur Shape:  torch.Size([32, 1, 41, 10, 20])\n",
      "Cur Shape:  torch.Size([32, 1, 1, 10, 20])\n"
     ]
    }
   ],
   "source": [
    "convt = nn.Sequential(\n",
    "    # PeriodicConvTranspose3d(1, 64, (5,3,5), (2,1,1), 1),\n",
    "    # nn.BatchNorm3d(64),\n",
    "    # nn.PReLU(64, 0.02),\n",
    "    # PeriodicConvTrnaspose3d(64, 128, (5,3,3), (2,1,2), 1),\n",
    "    # PeriodicConvTranspose3d(128, 256, (5,3,3), (2,1,2), 0),\n",
    "    # PeriodicConvTranspose3d(256, 512, (3,3,3), (1,1,1), 0),\n",
    "\n",
    "    nn.Unflatten(1, (1208, 1, 1, 1)),\n",
    "\n",
    "    PeriodicConvTranspose3d(1208, 512, (3,3,3), (1,1,1), 0),\n",
    "   \n",
    "    PeriodicConvTranspose3d(512, 128, (4,3,3), (2,1,2), 0),\n",
    "\n",
    "    PeriodicConvTranspose3d(128, 64, (3,2,3), (2,1,1), 0),\n",
    "\n",
    "    PeriodicConvTranspose3d(64, 32, (5,3,3), (2,1,2), 0),\n",
    "\n",
    "    PeriodicConvTranspose3d(32, 1, (5,3,2), (1,1,1), 0),\n",
    "\n",
    "    PeriodicConv3d(1, 1, (45 - 5 + 1, 1, 1), (1,1,1), 0)\n",
    "    \n",
    ")\n",
    "\n",
    "# xx0 = torch.cat((x, x0.unsqueeze(2).unsqueeze(3).repeat(1,1,torch.tensor(x.shape[-2:-1]).item(), torch.tensor(x.shape[-1:]).item())), 1)\n",
    "xt = torch.rand([32, 1208])\n",
    "\n",
    "print(convt)\n",
    "print(\"Input Shape: \", xt.shape)\n",
    "for layer in convt:\n",
    "    xt = layer(xt)\n",
    "    print(\"Cur Shape: \", xt.shape)\n",
    "\n",
    "# xt = conv3(conv2(conv1(data)))\n",
    "# shape of 3d data (batch_size, depth, height, width) \n",
    "# width gets padded so 3, 3, 5 in this example\n",
    "# print(xt.shape)\n",
    "#torch.Size([32, 128, 29, 1, 8])\n",
    "\n",
    "# Input Shape:  torch.Size([32, 1, 45, 9, 16])\n",
    "# Cur Shape:  torch.Size([32, 32, 22, 8, 16])\n",
    "# Size:  90112\n",
    "# Cur Shape:  torch.Size([32, 64, 10, 7, 16])\n",
    "# Size:  71680\n",
    "# Cur Shape:  torch.Size([32, 128, 8, 5, 7])\n",
    "# Size:  35840\n",
    "# Cur Shape:  torch.Size([32, 256, 3, 3, 3])\n",
    "# Size:  6912\n",
    "# Cur Shape:  torch.Size([32, 512, 1, 1, 1])\n",
    "# Size:  512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "997a8427-1ae1-4613-b612-55c24a3bfe86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Unflatten(dim=1, unflattened_size=(1208, 1, 1, 1))\n",
      "  (1): PeriodicConvTranspose3d(\n",
      "    (conv_transpose): ConvTranspose3d(1208, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  )\n",
      "  (2): PeriodicConvTranspose3d(\n",
      "    (conv_transpose): ConvTranspose3d(512, 128, kernel_size=(4, 3, 3), stride=(2, 1, 2))\n",
      "  )\n",
      "  (3): PeriodicConvTranspose3d(\n",
      "    (conv_transpose): ConvTranspose3d(128, 64, kernel_size=(3, 3, 4), stride=(1, 1, 2))\n",
      "  )\n",
      "  (4): PeriodicConvTranspose3d(\n",
      "    (conv_transpose): ConvTranspose3d(64, 32, kernel_size=(4, 2, 1), stride=(2, 1, 1))\n",
      "  )\n",
      "  (5): PeriodicConvTranspose3d(\n",
      "    (conv_transpose): ConvTranspose3d(32, 1, kernel_size=(3, 2, 1), stride=(2, 1, 1))\n",
      "  )\n",
      ")\n",
      "Input Shape:  torch.Size([32, 1208])\n",
      "Cur Shape:  torch.Size([32, 1208, 1, 1, 1])\n",
      "Cur Shape:  torch.Size([32, 512, 3, 3, 3])\n",
      "Cur Shape:  torch.Size([32, 128, 8, 5, 7])\n",
      "Cur Shape:  torch.Size([32, 64, 10, 7, 16])\n",
      "Cur Shape:  torch.Size([32, 32, 22, 8, 16])\n",
      "Cur Shape:  torch.Size([32, 1, 45, 9, 16])\n"
     ]
    }
   ],
   "source": [
    "convt = nn.Sequential(\n",
    "    # PeriodicConvTranspose3d(1, 64, (5,3,5), (2,1,1), 1),\n",
    "    # nn.BatchNorm3d(64),\n",
    "    # nn.PReLU(64, 0.02),\n",
    "    # PeriodicConvTrnaspose3d(64, 128, (5,3,3), (2,1,2), 1),\n",
    "    # PeriodicConvTranspose3d(128, 256, (5,3,3), (2,1,2), 0),\n",
    "    # PeriodicConvTranspose3d(256, 512, (3,3,3), (1,1,1), 0),\n",
    "\n",
    "#     Sequential(\n",
    "#   (0): PeriodicConv3d(\n",
    "#     (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(2, 1, 1))\n",
    "#   )\n",
    "#   (1): PeriodicConv3d(\n",
    "#     (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 1, 1))\n",
    "#   )\n",
    "#   (2): PeriodicConv3d(\n",
    "#     (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 2))\n",
    "#   )\n",
    "#   (3): PeriodicConv3d(\n",
    "#     (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 1, 2))\n",
    "#   )\n",
    "#   (4): PeriodicConv3d(\n",
    "#     (conv): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
    "#   )\n",
    "# )\n",
    "\n",
    "    nn.Unflatten(1, (1208, 1, 1, 1)),\n",
    "\n",
    "    PeriodicConvTranspose3d(1208, 512, (3,3,3), (1,1,1), 0),\n",
    "   \n",
    "    PeriodicConvTranspose3d(512, 128, (4,3,3), (2,1,2), 0),\n",
    "\n",
    "    PeriodicConvTranspose3d(128, 64, (3,3,4), (1,1,2), 0),\n",
    "\n",
    "    PeriodicConvTranspose3d(64, 32, (4,2,1), (2,1,1), 0),\n",
    "\n",
    "    PeriodicConvTranspose3d(32, 1, (3,2,1), (2,1,1), 0),\n",
    "    \n",
    ")\n",
    "\n",
    "# xx0 = torch.cat((x, x0.unsqueeze(2).unsqueeze(3).repeat(1,1,torch.tensor(x.shape[-2:-1]).item(), torch.tensor(x.shape[-1:]).item())), 1)\n",
    "xt = torch.rand([32, 1208])\n",
    "\n",
    "print(convt)\n",
    "print(\"Input Shape: \", xt.shape)\n",
    "for layer in convt:\n",
    "    xt = layer(xt)\n",
    "    print(\"Cur Shape: \", xt.shape)\n",
    "\n",
    "# xt = conv3(conv2(conv1(data)))\n",
    "# shape of 3d data (batch_size, depth, height, width) \n",
    "# width gets padded so 3, 3, 5 in this example\n",
    "# print(xt.shape)\n",
    "#torch.Size([32, 128, 29, 1, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db96f674-97f4-477b-84fe-c62654864d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class PeriodicConv3d_v2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "                 dilation=1, groups=1, bias=True):\n",
    "        super(PeriodicConv3d_v2, self).__init__()\n",
    "        self.padding = padding\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, \n",
    "                              padding=0, dilation=dilation, groups=groups, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pad input tensor with periodic boundary conditions\n",
    "        if self.padding == 1:\n",
    "            mid = x.shape[-2] // 2\n",
    "            shift = torch.cat((x[..., mid:, :1], x[..., :mid, :1]), -2)\n",
    "            x = torch.cat((shift, x), dim=-1)\n",
    "        x = F.pad(x, (0, 0, self.padding, self.padding, 0, 0), mode='circular')\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class PeriodicConvTranspose3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "                 output_padding=0, groups=1, bias=True, dilation=1):\n",
    "        super(PeriodicConvTranspose3d, self).__init__()\n",
    "        self.padding = padding\n",
    "        self.conv_transpose = nn.ConvTranspose3d(\n",
    "            in_channels, out_channels, kernel_size, stride=stride, padding=0,\n",
    "            output_padding=0, groups=groups, bias=bias, dilation=dilation\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pad input tensor with periodic boundary conditions\n",
    "        if self.padding == 1:\n",
    "            mid = x.shape[-2] // 2\n",
    "            shift = torch.cat((x[..., mid:, :1], x[..., :mid, :1]), -2)\n",
    "            x = torch.cat((shift, x), dim=-1)\n",
    "        x = F.pad(x, (0, 0, self.padding, self.padding, 0, 0), mode='circular')\n",
    "        x = self.conv_transpose(x)\n",
    "        return x\n",
    "\n",
    "class UNetPBH3Dv3(nn.Module):\n",
    "    def __init__(self, num_input_nodes, n_latent_nodes):\n",
    "        super(UNetPBH3Dv3, self).__init__()\n",
    "        self.num_input_nodes = num_input_nodes\n",
    "        self.n_latent_nodes = n_latent_nodes\n",
    "        self.z = 45\n",
    "        self.phi = 9\n",
    "        self.r = 16\n",
    "\n",
    "        # Encoder\n",
    "        self.enc_conv1 = nn.Sequential(\n",
    "            PeriodicConv3d_v2(1, 32, (3,3,3), stride=(2,1,1), padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.PReLU(32, 0.02)\n",
    "        )\n",
    "\n",
    "        self.enc_conv2 = nn.Sequential(\n",
    "            PeriodicConv3d_v2(32, 64, (3,3,3), stride=(2,1,1), padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.PReLU(64, 0.02)\n",
    "        )\n",
    "\n",
    "        self.enc_conv3 = nn.Sequential(\n",
    "            PeriodicConv3d_v2(64, 128, (3,3,3), stride=(1,2,1), padding=1),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.PReLU(128, 0.02)\n",
    "        )\n",
    "\n",
    "        # Incorporate x0 (energy) into the feature map\n",
    "        self.enc_conv4 = nn.Sequential(\n",
    "            PeriodicConv3d_v2(129, 512, (3,3,3), stride=(2,2,1), padding=0),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.PReLU(256, 0.02)\n",
    "        )\n",
    "\n",
    "        self.enc_conv5 = nn.Sequential(\n",
    "            PeriodicConv3d_v2(512, self.n_latent_nodes, (3,3,3), stride=(1,2,2), padding=0),\n",
    "            nn.PReLU(self.n_latent_nodes, 1.0)\n",
    "        )\n",
    "\n",
    "        self.dec_conv1 = nn.Sequential(\n",
    "            PeriodicConvTranspose3d(self.n_latent_nodes, 512, (3,3,3), stride=(1,1,1), padding=0),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.PReLU(512, 0.02)\n",
    "        )\n",
    "\n",
    "        self.dec_conv2 = nn.Sequential(\n",
    "            PeriodicConvTranspose3d(512, 128, (4,3,3), stride=(2,1,2), padding=0),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.PReLU(128, 0.02)\n",
    "        )\n",
    "\n",
    "        self.dec_conv3 = nn.Sequential(\n",
    "            PeriodicConvTranspose3d(128, 64, (3,3,3), stride=(1,1,2), padding=0),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.PReLU(64, 0.02)\n",
    "        )\n",
    "\n",
    "        self.dec_conv4 = nn.Sequential(\n",
    "            PeriodicConvTranspose3d(64, 32, (4,3,2), stride=(2,1,1), padding=0),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.PReLU(32, 0.02)\n",
    "        )\n",
    "\n",
    "        self.dec_conv5 = nn.Sequential(\n",
    "            PeriodicConvTranspose3d(32, 1, (3,1,1), stride=(2,1,1), padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, x0, post_samples):\n",
    "        # Reshape and position encoding\n",
    "        x = x.reshape(x.shape[0], 1, self.z, self.phi, self.r)\n",
    "        pos_enc_samples = self._pos_enc(post_samples)\n",
    "        x = x + pos_enc_samples.unsqueeze(2).unsqueeze(3).unsqueeze(4)\n",
    "\n",
    "        # Encoder path\n",
    "        x1 = self.enc_conv1(x)  # [batch, 32, z1, phi1, r1]\n",
    "        x2 = self.enc_conv2(x1) # [batch, 64, z2, phi2, r2]\n",
    "        x3 = self.enc_conv3(x2) # [batch, 128, z3, phi3, r3]\n",
    "\n",
    "        # Process x0 and concatenate\n",
    "        x0_trans = self.trans_energy(x0)\n",
    "        x0_trans = x0_trans.unsqueeze(1).unsqueeze(2).unsqueeze(3).unsqueeze(4)\n",
    "        x0_trans = x0_trans.expand(-1, -1, x3.shape[2], x3.shape[3], x3.shape[4])\n",
    "        x3_cat = torch.cat((x3, x0_trans), dim=1)  # [batch, 129, z3, phi3, r3]\n",
    "\n",
    "        x4 = self.enc_conv4(x3_cat)  # [batch, 256, z4, phi4, r4]\n",
    "        x5 = self.enc_conv5(x4)      # [batch, latent_nodes, z5, phi5, r5]\n",
    "\n",
    "        # Decoder path with skip connections\n",
    "        # Concatenate x5 and x4 for the first decoder layer\n",
    "        x5_cat = torch.cat((x5, x4), dim=1)  # [batch, latent_nodes + 256, z4, phi4, r4]\n",
    "        x = self.dec_conv1(x5_cat)  # [batch, 512, z4, phi4, r4]\n",
    "\n",
    "        # Second decoder layer with skip connection from x3\n",
    "        x = self.dec_conv2(x)\n",
    "        x = torch.cat((x, x3), dim=1)  # Concatenate with x3\n",
    "        x = self.dec_conv3(x)          # [batch, 64, z3, phi3, r3]\n",
    "\n",
    "        # Third decoder layer with skip connection from x2\n",
    "        x = torch.cat((x, x2), dim=1)  # Concatenate with x2\n",
    "        x = self.dec_conv4(x)          # [batch, 32, z2, phi2, r2]\n",
    "\n",
    "        # Fourth decoder layer with skip connection from x1\n",
    "        x = torch.cat((x, x1), dim=1)  # Concatenate with x1\n",
    "        x = self.dec_conv5(x)          # [batch, 1, z, phi, r]\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _pos_enc(self, post_samples):\n",
    "        post_samples = torch.cat(post_samples, 1)\n",
    "        M = post_samples.shape[1]\n",
    "        device = post_samples.device\n",
    "\n",
    "        pres = []\n",
    "        for i in range(1, int(M / 4 - 1)):\n",
    "            angle = torch.arange(0, M, device=device).float() * np.pi / M\n",
    "            term = (angle.cos() * post_samples + angle.sin() * (1 - post_samples).abs()) / np.sqrt(M)\n",
    "            pres.append(term.unsqueeze(2))\n",
    "        pos_enc = torch.cat(pres, dim=2).transpose(1, 2)\n",
    "        res = pos_enc.sum(dim=[1, 2]) / (M - 1)\n",
    "        return res.unsqueeze(1)\n",
    "\n",
    "    def trans_energy(self, x0, log_e_max=14.0, log_e_min=6.0, s_map=1.0):\n",
    "        return ((torch.log(x0) - log_e_min) / (log_e_max - log_e_min)) * s_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5893449c-1be1-40be-afe2-4585ae5289b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "           [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]],\n",
      "\n",
      "          [[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "           [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]]]]) torch.Size([1, 1, 2, 2, 10])\n",
      "tensor([[[[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "           [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]],\n",
      "\n",
      "          [[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "           [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]]]]) torch.Size([1, 1, 2, 2, 10])\n",
      "tensor([[[[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "           [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]],\n",
      "\n",
      "          [[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "           [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]]]]) torch.Size([1, 1, 2, 2, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(([[[[[0,1,2,3,4,5,6,7,8,9], [10,11,12,13,14,15,16,17,18,19]], [[0,1,2,3,4,5,6,7,8,9], [10,11,12,13,14,15,16,17,18,19]]]]]))\n",
    "print(x, x.shape)\n",
    "# x = F.pad(x, (1, 1, 0, 0, 0, 0), mode='circular')\n",
    "print(x, x.shape)\n",
    "# x = F.pad(x, (1, 1, 0, 0, 0, 0), mode='circular')\n",
    "print(x, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c6471f4-617b-4153-9644-dc67074f1aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 9, 19],\n",
      "          [ 9, 19]]]])\n"
     ]
    }
   ],
   "source": [
    "print(x[...,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4caca961-2379-4ee4-9e93-ec44668e7f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "           [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]],\n",
      "\n",
      "          [[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "           [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]]]])\n",
      "10\n",
      "tensor([[[[[15, 16, 17, 18, 19, 10, 11, 12, 13, 14]],\n",
      "\n",
      "          [[15, 16, 17, 18, 19, 10, 11, 12, 13, 14]]]]])\n",
      "tensor([[[[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "           [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
      "           [15, 16, 17, 18, 19, 10, 11, 12, 13, 14]],\n",
      "\n",
      "          [[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "           [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
      "           [15, 16, 17, 18, 19, 10, 11, 12, 13, 14]]]]])\n",
      "tensor([[[[[ 9,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9,  0],\n",
      "           [19, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 10],\n",
      "           [14, 15, 16, 17, 18, 19, 10, 11, 12, 13, 14, 15]],\n",
      "\n",
      "          [[ 9,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9,  0],\n",
      "           [19, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 10],\n",
      "           [14, 15, 16, 17, 18, 19, 10, 11, 12, 13, 14, 15]]]]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.shape[-1])\n",
    "mid = x.shape[-1] // 2\n",
    "shift = torch.cat((x[..., [-1], mid:], x[..., [-1], :mid]), -1)\n",
    "testx = torch.cat((x, shift), dim=-2)\n",
    "print(shift)\n",
    "print(testx)\n",
    "testx = F.pad(testx, (1, 1, 0, 0, 0, 0), mode='circular')\n",
    "print(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "06a35da2-b49d-4ac2-8a09-64e23b96eb43",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn.functional' has no attribute 'CircularPad2d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m testc \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCircularPad2d\u001b[49m(x, (\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn.functional' has no attribute 'CircularPad2d'"
     ]
    }
   ],
   "source": [
    "testc = F.CircularPad2d(x, (1,1,0,1,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7175bac1-d88b-4e90-8662-a7af8fb18260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# need to load config?\n",
    "testDec = DecoderCNNPB_HEv1()\n",
    "print(testDec.encArch)\n",
    "x = torch.rand([1, 2048])\n",
    "x0 = torch.rand([1, 1])\n",
    "res = testDec.forward(x, x0)\n",
    "print(len(res))\n",
    "print(res[0].shape, res[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0bcf35-ff58-4304-b9b4-8daf9b222ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = torch.tensor(([[[1,2,3], [4,5,6]]]))\n",
    "print(test, test.shape)\n",
    "test = F.pad(test, (0, 0, 1, 1), mode = 'circular')\n",
    "print(test, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8c24d4-3fb7-4555-9c00-ca45549dc8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_layers = [1,2,3,4]\n",
    "x = [0] + [layers - 1 for layers in inp_layers]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d0a5b-1acf-43eb-a75f-f54d04eb20bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [1 + 1 * x for x in range(6)]\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01970c-756b-4895-a210-b774b820268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from DecoderCond import DecoderCNNPBv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f5c691-45cb-4c59-a734-84d0fd1b0e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = DecoderCNNPBv4()\n",
    "# takes parameters from the forward method\n",
    "summary(enc, [32, 1208], [32, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32912224-d014-4b4b-867b-87dca0f053cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source source.me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57447edd-c9fc-40ec-870a-b06e9bf9a392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the dimensions\n",
    "size = 1\n",
    "\n",
    "# Create a 3D grid of coordinates\n",
    "x, y, z = np.indices((size, size, size))\n",
    "\n",
    "# Create a 3D array to represent the cube (1s where the cube is, 0s elsewhere)\n",
    "cube = (x < size) & (y < size) & (z < size)\n",
    "\n",
    "# Plot the cube\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Draw the voxels\n",
    "for i in range(size):\n",
    "    for j in range(size):\n",
    "        for k in range(size):\n",
    "            if cube[i, j, k]:\n",
    "                ax.bar3d(i, j, k, 1, 1, 1, color='orange', edgecolor='black', linewidth=9)\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "# Set the limits\n",
    "ax.set_xlim([0, size])\n",
    "ax.set_ylim([0, size])\n",
    "ax.set_zlim([0, size])\n",
    "\n",
    "\n",
    "# Remove the grid and axis\n",
    "ax.grid(False)\n",
    "ax.axis('off')\n",
    "\n",
    "# Set equal scaling for all axes to make the voxels look square\n",
    "ax.set_box_aspect([1,1,1])\n",
    "\n",
    "# Change the view angle\n",
    "ax.view_init(elev=15, azim=15, roll = 3\n",
    "             \n",
    "            )\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

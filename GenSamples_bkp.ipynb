{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc755bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "# %env CUDA_VISIBLE_DEVICES=4\n",
    "!nvidia-smi\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9bb0e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hydra\n",
    "from hydra.utils import instantiate\n",
    "from hydra import initialize, compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eecf26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "os.chdir('/home/' + getpass.getuser() + '/Projects/CaloQVAE/')\n",
    "sys.path.insert(1, '/home/' + getpass.getuser() + '/Projects/CaloQVAE/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713dff99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#external libraries\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits\n",
    "torch.manual_seed(32)\n",
    "import numpy as np\n",
    "np.random.seed(32)\n",
    "import matplotlib.pyplot as plt\n",
    "import hydra\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import time\n",
    "\n",
    "# PyTorch imports\n",
    "from torch import device, load, save\n",
    "from torch.nn import DataParallel\n",
    "from torch.cuda import is_available\n",
    "\n",
    "# Add the path to the parent directory to augment search for module\n",
    "sys.path.append(os.getcwd())\n",
    "    \n",
    "# Weights and Biases\n",
    "import wandb\n",
    "\n",
    "#self defined imports\n",
    "from CaloQVAE import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c4521a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from data.dataManager import DataManager\n",
    "from utils.plotting.plotProvider import PlotProvider\n",
    "from engine.engine import Engine\n",
    "from models.modelCreator import ModelCreator\n",
    "\n",
    "from utils.plotting.HighLevelFeatures import HighLevelFeatures as HLF\n",
    "# HLF_1_photons = HLF('photon', filename='/raid/javier/Datasets/CaloVAE/data/atlas/binning_dataset_1_photons.xml', wandb=False)\n",
    "# HLF_1_pions = HLF('pion', filename='/raid/javier/Datasets/CaloVAE/data/atlas/binning_dataset_1_pions.xml', wandb=False)\n",
    "# HLF_1_electron = HLF('electron', filename='/raid/javier/Datasets/CaloVAE/data/atlas_dataset2and3/binning_dataset_2.xml', wandb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b23d35a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(version_base=None, config_path=\"configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a474a49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# config=compose(config_name=\"config.yaml\")\n",
    "config=compose(config_name=\"config.yaml\")\n",
    "\n",
    "HLF_1_photons = HLF('photon', filename=config.data.binning_xml_photons, wandb=False)\n",
    "HLF_1_pions = HLF('pion', filename=config.data.binning_xml_pions, wandb=False)\n",
    "HLF_1_electron = HLF('electron', filename=config.data.binning_xml_electrons, wandb=False)\n",
    "\n",
    "wandb.init(project=\"caloqvae\", entity=config.data.entity, config=config, mode='disabled')\n",
    "modelCreator = ModelCreator(cfg=config)\n",
    "dataMgr = DataManager(cfg=config)\n",
    "#initialise data loaders\n",
    "dataMgr.init_dataLoaders()\n",
    "#run pre processing: get/set input dimensions and mean of train dataset\n",
    "dataMgr.pre_processing()\n",
    "\n",
    "if config.model.activation_fct.lower()==\"relu\":\n",
    "    modelCreator.default_activation_fct=torch.nn.ReLU()\n",
    "elif config.model.activation_fct.lower()==\"tanh\":\n",
    "    modelCreator.default_activation_fct=torch.nn.Tanh()\n",
    "else:\n",
    "    logger.warning(\"Setting identity as default activation fct\")\n",
    "    modelCreator.default_activation_fct=torch.nn.Identity()\n",
    "\n",
    "#instantiate the chosen model\n",
    "#loads from file \n",
    "model=modelCreator.init_model(dataMgr=dataMgr)\n",
    "\n",
    "#create the NN infrastructure\n",
    "model.create_networks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5238a51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Not printing much useful info at the moment to avoid clutter. TODO optimise\n",
    "model.print_model_info()\n",
    "# for name, param in model.named_parameters():\n",
    "#         print(name, param.requires_grad)\n",
    "\n",
    "# Load the model on the GPU if applicable\n",
    "# dev = None\n",
    "# if (config.device == 'gpu') and config.gpu_list:\n",
    "#     logger.info('Requesting GPUs. GPU list :' + str(config.gpu_list))\n",
    "#     devids = [\"cuda:{0}\".format(x) for x in list(config.gpu_list)]\n",
    "#     logger.info(\"Main GPU : \" + devids[0])\n",
    "\n",
    "#     if is_available():\n",
    "#         print(devids[0])\n",
    "#         dev = device(devids[0])\n",
    "#         if len(devids) > 1:\n",
    "#             logger.info(f\"Using DataParallel on {devids}\")\n",
    "#             model = DataParallel(model, device_ids=list(config.gpu_list))\n",
    "#         logger.info(\"CUDA available\")\n",
    "#     else:\n",
    "#         dev = device('cpu')\n",
    "#         logger.info(\"CUDA unavailable\")\n",
    "# else:\n",
    "#     logger.info('Requested CPU or unable to use GPU. Setting CPU as device.')\n",
    "#     dev = device('cpu')\n",
    "# dev = torch.device(\"cuda:0\")\n",
    "dev = \"cuda:{0}\".format(config.gpu_list[0])\n",
    "\n",
    "# Send the model to the selected device\n",
    "# model.to(dev)\n",
    "# Log metrics with wandb\n",
    "wandb.watch(model)\n",
    "\n",
    "# For some reason, need to use postional parameter cfg instead of named parameter\n",
    "# with updated Hydra - used to work with named param but now is cfg=None \n",
    "engine=instantiate(config.engine, config)\n",
    "\n",
    "#TODO for some reason hydra double instantiates the engine in a\n",
    "#newer version if cfg=config is passed as an argument. This is a workaround.\n",
    "#Find out why that is...\n",
    "engine._config=config\n",
    "#add dataMgr instance to engine namespace\n",
    "engine.data_mgr=dataMgr\n",
    "#add device instance to engine namespace\n",
    "engine.device=dev    \n",
    "#instantiate and register optimisation algorithm\n",
    "engine.optimiser = torch.optim.Adam(model.parameters(),\n",
    "                                    lr=config.engine.learning_rate)\n",
    "#add the model instance to the engine namespace\n",
    "engine.model = model\n",
    "# add the modelCreator instance to engine namespace\n",
    "engine.model_creator = modelCreator\n",
    "engine.model = engine.model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a5adb9-8a2c-402c-be97-296677f584eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# config=compose(config_name=\"config.yaml\")\n",
    "config_2=compose(config_name=\"config.yaml\")\n",
    "wandb.init(project=\"caloqvae\", entity=\"qvae\", config=config_2, mode='disabled')\n",
    "modelCreator_2 = ModelCreator(cfg=config_2)\n",
    "dataMgr_2 = DataManager(cfg=config_2)\n",
    "#initialise data loaders\n",
    "dataMgr_2.init_dataLoaders()\n",
    "#run pre processing: get/set input dimensions and mean of train dataset\n",
    "dataMgr_2.pre_processing()\n",
    "\n",
    "if config_2.model.activation_fct.lower()==\"relu\":\n",
    "    modelCreator_2.default_activation_fct=torch.nn.ReLU()\n",
    "elif config_2.model.activation_fct.lower()==\"tanh\":\n",
    "    modelCreator_2.default_activation_fct=torch.nn.Tanh()\n",
    "else:\n",
    "    logger.warning(\"Setting identity as default activation fct\")\n",
    "    modelCreator_2.default_activation_fct=torch.nn.Identity()\n",
    "\n",
    "#instantiate the chosen model\n",
    "#loads from file \n",
    "model_2=modelCreator_2.init_model(dataMgr=dataMgr_2)\n",
    "\n",
    "#create the NN infrastructure\n",
    "model_2.create_networks()\n",
    "\n",
    "engine_2=instantiate(config_2.engine, config_2)\n",
    "\n",
    "#TODO for some reason hydra double instantiates the engine in a\n",
    "#newer version if cfg=config is passed as an argument. This is a workaround.\n",
    "#Find out why that is...\n",
    "engine_2._config=config_2\n",
    "#add dataMgr instance to engine namespace\n",
    "engine_2.data_mgr=dataMgr_2\n",
    "#add device instance to engine namespace\n",
    "engine_2.device=dev    \n",
    "#instantiate and register optimisation algorithm\n",
    "engine_2.optimiser = torch.optim.Adam(model_2.parameters(),\n",
    "                                    lr=config_2.engine.learning_rate)\n",
    "#add the model instance to the engine namespace\n",
    "engine_2.model = model_2\n",
    "# add the modelCreator instance to engine namespace\n",
    "engine_2.model_creator = modelCreator_2\n",
    "engine_2.model = engine_2.model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ecfae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader,test_loader,val_loader = engine.data_mgr.create_dataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c30117a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###LOAD MODEL\n",
    "# engine.model.prior._weight_dict['03']\n",
    "# engine.model.prior.fullyconnected\n",
    "# engine.model._config.model.fullyconnected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e8abc0-049d-416c-b6e8-b9d5ea4b3a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "engine.model._qpu_sampler.properties[\"chip_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18861900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wordly-fog-352 | CNN + cond + scaled data + \\pow(1+x, 1/4) BCE + Cyl encoderDec\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-04/19-10-12/wandb/run-20240404_191013-a690v1bu/files/GumBoltAtlasPRBMCNN_atlas_default_latest.pth\"\n",
    "modelname = 'world-fog-352'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-04/19-10-12/wandb/run-20240404_191013-a690v1bu/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=True    \n",
    "    \n",
    "    \n",
    "# # emissary-think-tank-353 | CNN + cond + scaled data + Cyl EncDec\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-05/12-01-16/wandb/run-20240405_120117-67fx57x8/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# modelname = 'emissary-think-tank-353'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-05/12-01-16/wandb/run-20240405_120117-67fx57x8/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True  \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "# nothern-microwave-356 | CNN + cond + scaled data + Cyl EncDec\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-08/17-47-59/wandb/run-20240408_174800-83zkah0g/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "modelname = 'nothern-microwave-356'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-08/17-47-59/wandb/run-20240408_174800-83zkah0g/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=True \n",
    "    \n",
    "    \n",
    "# # dark-sky-357 | CNN + cond + scaled data + Cyl EncDec\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-08/18-22-13/wandb/run-20240408_182214-ftos7bwv/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# modelname = 'dark-sky-357'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-08/18-22-13/wandb/run-20240408_182214-ftos7bwv/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True \n",
    "\n",
    "\n",
    "# # rural-cosmos-358 | CNN + cond + scaled data + Cyl EncDec\n",
    "# # run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-10/21-09-25/wandb/run-20240410_210926-1fmsh565/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-10/21-09-25/wandb/run-20240415_105702-1fmsh565/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# modelname = 'rural-cosmos-358'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-10/21-09-25/wandb/run-20240415_105702-1fmsh565/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True \n",
    "    \n",
    "    \n",
    "# # rare-lake-359 | CNN + cond + scaled data + Cyl EncDec + logits passed on encoder\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-15/17-11-53/wandb/run-20240415_171154-1p5wt0sy/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# modelname = 'rare-lake-359'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-15/17-11-53/wandb/run-20240415_171154-1p5wt0sy/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True \n",
    "    \n",
    "    \n",
    "# deft-meadow-360 | CNN + cond + scaled data + Cyl EncDec + logits passed on encoder + no BCE weight\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-17/13-20-06/wandb/run-20240417_132007-grs8jl3h/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "modelname = 'deft-meadow-360'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-17/13-20-06/wandb/run-20240417_132007-grs8jl3h/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=True \n",
    "    \n",
    "    \n",
    "# dazzling-cloud-361 | CNN + cond + scaled data + Cyl EncDec + no BCE weight + clamped logits at 10\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-18/14-02-08/wandb/run-20240418_140209-mjj5yuvx/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "modelname = 'dazzling-cloud-361'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-18/14-02-08/wandb/run-20240418_140209-mjj5yuvx/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=True \n",
    "    \n",
    "    \n",
    "# fast-bee-363 | CNN + cond + scaled data + Cyl EncDec +Fully connected RBM\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-19/19-12-27/wandb/run-20240419_191228-1wkunmev/files/GumBoltAtlasPRBMCNN_atlas_default_latest.pth\"\n",
    "modelname = 'fast-bee-363'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-19/19-12-27/wandb/run-20240419_191228-1wkunmev/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=True \n",
    "\n",
    "\n",
    "# deep-snowball-367 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log energy encoded\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-22/19-21-15/wandb/run-20240422_192116-p4gannm2/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "modelname = 'deep-snowball-367'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-22/19-21-15/wandb/run-20240422_192116-p4gannm2/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=True  \n",
    "    \n",
    "    \n",
    "# # soft-violet-374 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log energy encoded + Zephyr\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-24/15-23-11/wandb/run-20240424_152312-wn4msoz2/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# modelname = 'soft-violet-374'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-24/15-23-11/wandb/run-20240424_152312-wn4msoz2/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True \n",
    "    \n",
    "    \n",
    "# # dutiful-bird-375 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log energy encoded + CRBM\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-24/20-12-01/wandb/run-20240424_201202-so4nwdou/files/GumBoltAtlasPRBMCNN_atlas_default_latest.pth\"\n",
    "# modelname = 'dutiful-bird-375'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-24/20-12-01/wandb/run-20240424_201202-so4nwdou/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True \n",
    "    \n",
    "    \n",
    "# # sunny-firebrand-376 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log energy encoded + Zephyr+ CRBM\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-25/13-08-39/wandb/run-20240425_130840-nmqieu71/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# modelname = 'sunny-firebrand-376'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-25/13-08-39/wandb/run-20240425_130840-nmqieu71/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True \n",
    "    \n",
    "\n",
    "# graceful-plasma-378 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log energy encoded + Zephyr+ CRBM\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-29/17-29-12/wandb/run-20240429_172912-uzp3fv73/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "modelname = 'graceful-plasma-378'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-29/17-29-12/wandb/run-20240429_172912-uzp3fv73/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=True\n",
    "    \n",
    "\n",
    "# # solar-wildflower-379 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log energy encoded + CRBM\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-04-30/13-53-54/wandb/run-20240430_135355-73aho6c2/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# modelname = 'solar-wildflower-379'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-04-30/13-53-54/wandb/run-20240430_135355-73aho6c2/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True\n",
    "\n",
    "\n",
    "# feasible-dust-380 | CNN + cond + scaled data + Cyl EncDec + lin energy encoded + CRBM\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-01/13-05-50/wandb/run-20240501_130551-4rr2g0s4/files/GumBoltAtlasPRBMCNN_atlas_default_latest.pth\"\n",
    "modelname = 'feasible-dust-380'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-01/13-05-50/wandb/run-20240501_130551-4rr2g0s4/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=True\n",
    "    \n",
    "    \n",
    "# # stilted-morning-381 | CNN + cond + scaled data + Cyl EncDec + lin energy encoded + CRBM + no freeze out\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-01/19-46-04/wandb/run-20240501_194605-4f6qr1dt/files/GumBoltAtlasPRBMCNN_atlas_default_latest.pth\"\n",
    "# modelname = 'stilted-morning-381'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-01/19-46-04/wandb/run-20240501_194605-4f6qr1dt/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True\n",
    "    \n",
    "    \n",
    "# fallen-disco-383 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-02/18-46-03/wandb/run-20240502_184604-opz17u3d/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "modelname = 'fallen-disco-383'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-02/18-46-03/wandb/run-20240502_184604-opz17u3d/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=True\n",
    "    \n",
    "    \n",
    "# # breezy-smoke-389 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-06/21-43-41/wandb/run-20240506_214342-tyclqjw4/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# modelname = 'breezy-smoke-389'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-06/21-43-41/wandb/run-20240506_214342-tyclqjw4/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True\n",
    "    \n",
    "\n",
    "# # logical-dragon-394 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-08/18-58-30/wandb/run-20240508_185831-yxmk5x30/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "# modelname = 'logical-dragon-394'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-08/18-58-30/wandb/run-20240508_185831-yxmk5x30/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True\n",
    "\n",
    "# copper-vortex-404 is very similar to previous. Larger FCN at the end. Behaves very similar to previous model\n",
    "\n",
    "# northern-sunset-406 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-10/10-55-05/wandb/run-20240510_105506-8txbu380/files/AtlasConditionalQVAE_atlas_default_100.pth\"\n",
    "modelname = 'northern-sunset-406'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-10/10-55-05/wandb/run-20240510_105506-8txbu380/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=True\n",
    "    \n",
    "    \n",
    "# misunderstood-frost-410 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-12/16-24-06/wandb/run-20240512_162407-tz6u5opn/files/AtlasConditionalQVAE_atlas_default_120.pth\"\n",
    "modelname = 'misunderstood-frost-410'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-12/16-24-06/wandb/run-20240512_162407-tz6u5opn/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=True\n",
    "\n",
    "\n",
    "# # flowing-grass-411 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-13/13-18-33/wandb/run-20240513_131834-5saza00m/files/AtlasConditionalQVAE_atlas_default_best.pth\"\n",
    "# modelname = 'flowing-grass-411'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-13/13-18-33/wandb/run-20240513_131834-5saza00m/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True\n",
    "\n",
    "\n",
    "# dry-silence-412 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-15/14-28-01/wandb/run-20240515_142802-3la2tybf/files/AtlasConditionalQVAE_atlas_default_100.pth\"\n",
    "modelname = 'dry-silence-412'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-15/14-28-01/wandb/run-20240515_142802-3la2tybf/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=True\n",
    "    \n",
    "    \n",
    "# # young-wildflower-413 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-16/15-20-10/wandb/run-20240516_152011-cyeoc1or/files/AtlasConditionalQVAE_atlas_default_best.pth\"\n",
    "# modelname = 'young-wildflower-412'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-16/15-20-10/wandb/run-20240516_152011-cyeoc1or/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=True\n",
    "    \n",
    "    \n",
    "# astral-terrain-415 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-16/19-47-55/wandb/run-20240516_194756-dt99yb97/files/AtlasConditionalQVAE_atlas_default_50.pth\"\n",
    "modelname = 'astral-terrain-415'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-16/19-47-55/wandb/run-20240516_194756-dt99yb97/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=True\n",
    "    \n",
    "    \n",
    "# morning-breeze-420 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-18/15-22-04/wandb/run-20240518_152205-pi1sujcx/files/AtlasConditionalQVAE_atlas_default_150.pth\"\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-18/15-22-04/wandb/run-20240524_194939-pi1sujcx/files/AtlasConditionalQVAE_atlas_default_230.pth\"\n",
    "modelname = 'morning-breeze-420'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-18/15-22-04/wandb/run-20240524_194939-pi1sujcx/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=True\n",
    "    \n",
    "    \n",
    "# gallant-capybara-418 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 + Z\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-18/15-20-30/wandb/run-20240518_152031-zhvzuxif/files/AtlasConditionalQVAE_atlas_default_150.pth\"\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-18/15-20-30/wandb/run-20240524_194447-zhvzuxif/files/AtlasConditionalQVAE_atlas_default_250.pth\"\n",
    "modelname = 'gallant-capybara-418'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-18/15-20-30/wandb/run-20240518_152031-zhvzuxif/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=True\n",
    "    \n",
    "    \n",
    "# royal-plant-447 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-29/14-07-25/wandb/run-20240529_140726-f9sdv5v2/files/AtlasConditionalQVAE_atlas_default_10.pth\"\n",
    "modelname = 'royal-plant-447'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-29/14-07-25/wandb/run-20240529_140726-f9sdv5v2/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=False   \n",
    "    \n",
    "# brisk-bird-447 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-30/11-00-37/wandb/run-20240530_110038-oyw5vuog/files/AtlasConditionalQVAE_atlas_default_20.pth\"\n",
    "modelname = 'brisk-bird-447'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-30/11-00-37/wandb/run-20240530_110038-oyw5vuog/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=False  \n",
    "    \n",
    "    \n",
    "# #toasty-pond-448 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-30/16-39-43/wandb/run-20240530_163944-g59w6j0e/files/AtlasConditionalQVAE_atlas_default_140.pth\"\n",
    "# modelname = 'toasty-pond-448'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-30/16-39-43/wandb/run-20240530_163944-g59w6j0e/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=False\n",
    "    \n",
    "    \n",
    "# # solar-cloud-449 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-30/19-04-18/wandb/run-20240530_190419-42l10ppy/files/AtlasConditionalQVAE_atlas_default_20.pth\"\n",
    "# modelname = 'solar-cloud-449'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-30/19-04-18/wandb/run-20240530_190419-42l10ppy/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=False \n",
    "\n",
    "\n",
    "# twilight-river-450 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-05-31/19-11-05/wandb/run-20240531_191106-4dsnfwl4/files/GumBoltAtlasPRBMCNN_atlas_default_150.pth\"\n",
    "modelname = 'twilight-river-450'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-05-31/19-11-05/wandb/run-20240531_191106-4dsnfwl4/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=False \n",
    "\n",
    "\n",
    "#helpful-star-450 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-06-03/00-59-55/wandb/run-20240603_005956-nwgtxcyj/files/AtlasConditionalQVAE_atlas_default_120.pth\"\n",
    "modelname = 'helpful-star-450'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-06-03/00-59-55/wandb/run-20240603_005956-nwgtxcyj/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=False\n",
    "    \n",
    "    \n",
    "#glowing-meadow-453 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-06-03/23-59-58/wandb/run-20240603_235959-1txgiuch/files/AtlasConditionalQVAE_atlas_default_100.pth\"\n",
    "modelname = 'glowing-meadow-453'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-06-03/23-59-58/wandb/run-20240603_235959-1txgiuch/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=False\n",
    "\n",
    "\n",
    "#honest-hill-454 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-06-04/19-27-16/wandb/run-20240604_192717-n57xkuzr/files/AtlasConditionalQVAE_atlas_default_150.pth\"\n",
    "modelname = 'honest-hill-454'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-06-04/19-27-16/wandb/run-20240604_192717-n57xkuzr/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=False\n",
    "    \n",
    "    \n",
    "#pretty-shape-455 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-06-05/03-07-35/wandb/run-20240605_030736-20kaac85/files/AtlasConditionalQVAE_atlas_default_150.pth\"\n",
    "modelname = 'pretty-shape-455'\n",
    "datascaled = 'reduced'\n",
    "with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-06-05/03-07-35/wandb/run-20240605_030736-20kaac85/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "    scaled=False\n",
    "\n",
    "\n",
    "\n",
    "# #wobbly-aardvark-456 | CNN + cond + scaled data + Cyl EncDec + lin/sqrt/log LONG energy encoded + CRBM 1st Partition Binv2 +scaled\n",
    "# run_path = \"/home/javier/Projects/CaloQVAE/outputs/2024-06-06/12-49-34/wandb/run-20240606_124935-30h7h1uj/files/AtlasConditionalQVAE_atlas_default_100.pth\"\n",
    "# modelname = 'wobbly-aardvark-456'\n",
    "# datascaled = 'reduced'\n",
    "# with open(\"/home/javier/Projects/CaloQVAE/outputs/2024-06-06/12-49-34/wandb/run-20240606_124935-30h7h1uj/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "#     R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "#     reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "#     scaled=False\n",
    "\n",
    "    \n",
    "arch = config['model']['model_type']\n",
    "part = config['data']['particle_type']\n",
    "print(arch)\n",
    "print(part)\n",
    "print(scaled, reducedata)\n",
    "\n",
    "\n",
    "# load_state(model, run_path, 'cuda:{0}'.format(cfg.gpu_list[0]))\n",
    "# load_state(model, run_path, dev)\n",
    "modelCreator.load_state(run_path, dev)\n",
    "engine.model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf532b-c6e6-447d-9f60-00d2067f9320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lnZais = engine.model.stater.AIS(30).detach().cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53462efd-8ab0-4020-8286-ebd9d5950c82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lnZrais = engine.model.stater.RAIS(20).detach().cpu().item()\n",
    "print(lnZais, lnZrais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda41d50-7c3c-40a0-b4fe-babe8c48b94b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lnZais_rdm = engine_2.model.stater.AIS(30).detach().cpu().item()\n",
    "lnZrais_rdm = engine_2.model.stater.RAIS(20).detach().cpu().item()\n",
    "print(lnZais_rdm, lnZrais_rdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272b86ae-9014-4914-b327-3b5502fc3ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# engine.model.prior.bias_dict     # weight_dict['01']\n",
    "engine.model.prior.weight_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f1fa1f-6a4f-4b6d-9b01-f40f4a1f4499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File(\"/home/javier/RBM_weights.hdf5\", 'w') as hdf_file:\n",
    "    for key, value in engine.model.prior.weight_dict.items():\n",
    "        # Each key-value pair in the dictionary becomes a dataset in the HDF5 file\n",
    "        hdf_file.create_dataset(key, data=value.detach().cpu())\n",
    "        \n",
    "with h5py.File(\"/home/javier/RBM_biases.hdf5\", 'w') as hdf_file:\n",
    "    for key, value in engine.model.prior.bias_dict.items():\n",
    "        # Each key-value pair in the dictionary becomes a dataset in the HDF5 file\n",
    "        hdf_file.create_dataset(key, data=value.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2398a58b-a699-4ea7-96c8-5460ab6cc530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hfont = {'fontname':'Helvetica'}\n",
    "ds = {'electron-ds2':'Dataset 2', 'pion1':'Dataset 1: π'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4202c39e-ea8e-4ac7-ad48-dbc9717a05a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xx = next(iter(test_loader))\n",
    "in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1]) # input , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20931d8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(in_data.shape)\n",
    "plt.plot(in_data.cpu().numpy()[3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c32576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "    if True: #reducedata:\n",
    "        in_data = engine._reduce(in_data, true_energy)\n",
    "    fwd_output = engine.model((in_data, true_energy), True)\n",
    "    engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "    sample_energies, sample_data = engine._model.generate_samples_cond(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "    # sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "    engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "idx = 0\n",
    "plt.plot(in_data.cpu().numpy()[idx,:])\n",
    "plt.plot(fwd_output.output_activations.detach().cpu().numpy()[idx,:], alpha=0.5)\n",
    "plt.plot(sample_data.detach().cpu().numpy()[idx,:], alpha=0.5)\n",
    "plt.legend([\"gt\",\"recon\",\"samp\"])\n",
    "plt.xlabel(\"voxel index\")\n",
    "plt.ylabel(\"energy per voxel in new variable\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(engine._reduceinv(in_data,true_energy).cpu().numpy()[idx,:])\n",
    "plt.plot(engine._reduceinv(fwd_output.output_activations,true_energy).detach().cpu().numpy()[idx,:], alpha=0.5)\n",
    "plt.plot(engine._reduceinv(sample_data, true_energy).detach().cpu().numpy()[idx,:], alpha=0.5)\n",
    "plt.legend([\"gt\",\"recon\",\"samp\"])\n",
    "plt.xlabel(\"voxel index\")\n",
    "plt.ylabel(\"energy per voxel\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(engine._reduceinv(in_data,true_energy).cpu().numpy()[idx,:]/true_energy.cpu().numpy()[idx,0])\n",
    "plt.plot(engine._reduceinv(fwd_output.output_activations,true_energy).detach().cpu().numpy()[idx,:]/true_energy.cpu().numpy()[idx,0], alpha=0.5)\n",
    "plt.plot(engine._reduceinv(sample_data, true_energy).detach().cpu().numpy()[idx,:]/true_energy.cpu().numpy()[idx,0], alpha=0.5)\n",
    "plt.legend([\"gt\",\"recon\",\"samp\"])\n",
    "plt.xlabel(\"voxel index\")\n",
    "plt.ylabel(\"energy per voxel\")\n",
    "plt.show()\n",
    "print(true_energy[idx,:], engine._reduceinv(in_data, true_energy)[idx,:].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89ceb31-4f25-47f2-82cd-40875b6615a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "directory_path = f'/home/javier/Projects/CaloQVAE/figs/{modelname}'\n",
    "if not os.path.isdir(directory_path):\n",
    "    os.mkdir(directory_path) \n",
    "    print(modelname)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a53ea-746b-40d3-bc72-6335da7d4288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beta, beta_list, rbm_energy_list, dwave_energy_list, thrsh_met = engine.model.find_beta(num_reads=256, beta_init=4.41, lr=0.01, num_epochs = 30, delta = 4.0, method = 2, TOL=True, const = 1.0, adaptive = True)\n",
    "beta0 = beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8601f5c8-a90e-43da-985e-93e24a7a579a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(range(len(beta_list)), beta_list, linewidth=2.5, color=\"b\" )\n",
    "plt.plot(range(len(beta_list)), beta_list, linewidth=1.5, color=\"b\" )\n",
    "plt.xlabel(\"Iterations\", fontsize=15)\n",
    "plt.ylabel(\"Estimated $β_{QA}$\", fontsize=15)\n",
    "plt.legend([f'Chip {engine.model._qpu_sampler.properties[\"chip_id\"]}'], fontsize=15)\n",
    "# plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/beta_QA_{engine.model._qpu_sampler.properties[\"chip_id\"]}_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f432056-c6b8-4b3e-b394-9943a4be5c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "QA = \"$β_{QA}$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb58c0ee-87f8-448c-bf47-ed08a4e7b2a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Hoffset = -(sum([engine.model.prior.bias_dict[key].sum().detach().cpu().item() for key in engine.model.prior.bias_dict.keys()])/2 \n",
    "            + sum([engine.model.prior.weight_dict[key].sum().detach().cpu().item() for key in engine.model.prior.weight_dict.keys()])/4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97096694-96ab-4b00-b16f-399e2f0f8f64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(rbm_energy_list[-1] + Hoffset, density=True, color=\"orange\", alpha=0.7)\n",
    "plt.hist(dwave_energy_list[-1] + Hoffset, density=True, color=\"m\", alpha=0.7)\n",
    "plt.xlabel(\"RBM Energy\", fontsize=15)\n",
    "plt.ylabel(\"PDF\", fontsize=15)\n",
    "plt.legend([\"Classical samples\", \"QPU samples\"], fontsize=17)\n",
    "# plt.title(f'ln(Z)[AIS] = {np.round(Zais)}, ln(Z)[RAIS] = {np.round(Zrais)}')\n",
    "plt.figtext(0.7, 0.6, f'Est. {QA} = {np.round(beta0, 2)}', ha='center', va='top', fontsize=17, bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=1'))\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/Ising_energy_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n",
    "print(len(rbm_energy_list[-1]))\n",
    "print(len(dwave_energy_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0816824-e31e-41f3-a861-4e336c27cb40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "partition_size=config.model.n_latent_nodes_per_p\n",
    "energy_encoded_data = []\n",
    "\n",
    "engine.model.eval()\n",
    "with torch.no_grad():\n",
    "    for xx in val_loader:\n",
    "        in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "        if reducedata:\n",
    "            in_data = engine._reduce(in_data, true_energy, R=R)\n",
    "        # enIn = torch.cat((in_data, true_energy), dim=1)\n",
    "        # beta, post_logits, post_samples = engine.model.encoder(enIn, False)\n",
    "        beta, post_logits, post_samples = engine.model.encoder(in_data, true_energy, False)\n",
    "        post_samples = torch.cat(post_samples, 1)\n",
    "        post_samples_energy = engine.model.stater.energy_samples(post_samples[:,0:partition_size], post_samples[:,partition_size:2*partition_size], \n",
    "                                                 post_samples[:,2*partition_size:3*partition_size], post_samples[:,3*partition_size:4*partition_size], 1.0 )\n",
    "        energy_encoded_data.append(post_samples_energy.detach().cpu())\n",
    "\n",
    "energy_encoded_data = torch.cat(energy_encoded_data, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f5516-82f0-4819-aedc-927383707408",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# engine.model.prior_samples[:,0:512], engine.model.prior_samples[:,512:1024], engine.model.prior_samples[:,1024:1536], engine.model.prior_samples[:,1536:2048]\n",
    "energy_dwave = engine.model.stater.energy_samples(engine.model.prior_samples[1000:,0:512], engine.model.prior_samples[1000:,512:1024], \n",
    "                                                  engine.model.prior_samples[1000:,1024:1536], engine.model.prior_samples[1000:,1536:2048], 1.0)\n",
    "# _energy_rbm = engine.model.stater.energy_samples(rbm_data[-250:,0:512], rbm_data[-250:,512:1024], rbm_data[-250:,1024:1536], rbm_data[-250:,1536:2048], 1.0)\n",
    "# (rbm_data[-250:,0:512] == engine.model.prior_samples[:,0:512]).prod()\n",
    "engine.model.prior_samples.shape\n",
    "energy_dwave.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd80367-2140-4ffb-8134-77e7f71fa207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(engine.model.prior_samples[1000:,:512] == rbm_data[:,:512]).prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7a257e-ff86-4d2c-a124-c736bf9efb64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(energy_dwave.detach().cpu()+ Hoffset/2, density=True)\n",
    "plt.hist(energy_rbm_data.detach().cpu(), alpha=0.5, density=True)\n",
    "print(rbm_data.shape, energy_rbm_data.detach().cpu().mean() - energy_dwave.detach().cpu().mean(),\n",
    "     energy_rbm_data.shape, energy_dwave.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a51d69a-76fe-4f52-bc1e-b76993213854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "partition_size=config.model.n_latent_nodes_per_p\n",
    "encoded_data = []\n",
    "energy_encoded_data = []\n",
    "n_samples4_qpu = 200\n",
    "\n",
    "# encoded_data_rdm = []\n",
    "# energy_encoded_data_rdm = []\n",
    "engine.model.eval()\n",
    "# engine_2.model.eval()\n",
    "with torch.no_grad():\n",
    "    for xx in val_loader:\n",
    "    # for xx in train_loader:\n",
    "        in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "        #################################################\n",
    "        # true_energy = true_energy[:n_samples4_qpu,:]\n",
    "        # in_data = in_data[:n_samples4_qpu,:]\n",
    "        #################################################\n",
    "        if reducedata:\n",
    "            in_data = engine._reduce(in_data, true_energy, R=R)\n",
    "        # enIn = torch.cat((in_data, true_energy), dim=1)\n",
    "        # beta, post_logits, post_samples = engine.model.encoder(enIn, False)\n",
    "        beta, post_logits, post_samples = engine.model.encoder(in_data, true_energy, False)\n",
    "        post_samples = torch.cat(post_samples, 1)\n",
    "        post_samples_energy = engine.model.stater.energy_samples(post_samples[:,0:partition_size], post_samples[:,partition_size:2*partition_size], \n",
    "                                                 post_samples[:,2*partition_size:3*partition_size], post_samples[:,3*partition_size:4*partition_size], 1.0 )\n",
    "        encoded_data.append(post_samples.detach().cpu())\n",
    "        energy_encoded_data.append(post_samples_energy.detach().cpu())\n",
    "        \n",
    "        # #Rdm model\n",
    "        # # enIn = torch.cat((in_data, true_energy), dim=1)\n",
    "        # # beta, post_logits, post_samples = engine.model.encoder(enIn, False)\n",
    "        # beta, post_logits, post_samples = engine_2.model.encoder(in_data, true_energy, False)\n",
    "        # post_samples = torch.cat(post_samples, 1)\n",
    "        # post_samples_energy = engine_2.model.stater.energy_samples(post_samples[:,0:partition_size], post_samples[:,partition_size:2*partition_size], \n",
    "        #                                          post_samples[:,2*partition_size:3*partition_size], post_samples[:,3*partition_size:4*partition_size], 1.0 )\n",
    "        # encoded_data_rdm.append(post_samples.detach().cpu())\n",
    "        # energy_encoded_data_rdm.append(post_samples_energy.detach().cpu())\n",
    "\n",
    "encoded_data = torch.cat(encoded_data, dim=0)\n",
    "energy_encoded_data = torch.cat(energy_encoded_data, dim=0)\n",
    "        \n",
    "# encoded_data_rdm = torch.cat(encoded_data_rdm, dim=0)\n",
    "# energy_encoded_data_rdm = torch.cat(energy_encoded_data_rdm, dim=0)\n",
    "\n",
    "p1,p2,p3,p4 = post_samples[:,0:partition_size], post_samples[:,partition_size:2*partition_size], \\\n",
    "                                                 post_samples[:,2*partition_size:3*partition_size], post_samples[:,3*partition_size:4*partition_size]\n",
    "\n",
    "energy_rbm_data = []\n",
    "rbm_data = []\n",
    "# energy_rbm_rdm_data = []\n",
    "with torch.no_grad():\n",
    "    # for i in range(10):\n",
    "    for xx in val_loader:\n",
    "        in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "        ##################################################\n",
    "        # true_energy = true_energy[:n_samples4_qpu,:]\n",
    "        # in_data = in_data[:n_samples4_qpu,:]\n",
    "        ##################################################\n",
    "        # if i == 0:\n",
    "            # p1, p2, p3, p4 = engine.model.stater.block_gibbs_sampling_ais(1.0)\n",
    "        # else:\n",
    "            # p1, p2, p3, p4 = engine.model.stater.block_gibbs_sampling_ais(1.0, p1, p2, p3, p4)\n",
    "        engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "        if True:\n",
    "            u = engine.model.encoder.binary_energy(true_energy).to(dtype=torch.float32)\n",
    "            p1, p2, p3, p4 = engine.model.sampler.block_gibbs_sampling_cond(u)\n",
    "        else:\n",
    "            p1, p2, p3, p4 = engine.model.sampler.block_gibbs_sampling()\n",
    "        rbm_data.append(torch.cat((p1,p2,p3,p4),1))\n",
    "        rbm_samples_energy = engine.model.stater.energy_samples(p1, p2, p3, p4, 1.0)\n",
    "        energy_rbm_data.append(rbm_samples_energy.detach().cpu())\n",
    "        engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "        \n",
    "        # if i == 0:\n",
    "        #     p1_r, p2_r, p3_r, p4_r = engine_2.model.stater.block_gibbs_sampling_ais(1.0)\n",
    "        # else:\n",
    "        #     p1_r, p2_r, p3_r, p4_r = engine_2.model.stater.block_gibbs_sampling_ais(1.0, p1_r, p2_r, p3_r, p4_r)\n",
    "        # rbm_rdm_samples_energy = engine_2.model.stater.energy_samples(p1_r, p2_r, p3_r, p4_r, 1.0)\n",
    "        # energy_rbm_rdm_data.append(rbm_rdm_samples_energy.detach().cpu())\n",
    "    \n",
    "energy_rbm_data = torch.cat(energy_rbm_data, dim=0)\n",
    "rbm_data = torch.cat(rbm_data,0)\n",
    "# energy_rbm_rdm_data = torch.cat(energy_rbm_rdm_data, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59faa9fc-3dfc-4032-b66f-3287f7accb93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(energy_encoded_data.numpy(), bins=70, linewidth=2.5, color=\"b\", density=True, log=True)\n",
    "plt.hist(energy_rbm_data.numpy(), bins=20, color=\"orange\", density=True, fc=(1, 0, 1, 0.5), histtype='step', linewidth=1.5)\n",
    "plt.hist(energy_rbm_rdm_data.numpy(), bins=20, linewidth=2.5, color=\"cyan\", density=True, fc=(0.5, 1.0, 0.5, 0.8))\n",
    "plt.hist(energy_encoded_data_rdm.numpy(), bins=70, linewidth=2.5, color=\"r\", density=True)\n",
    "\n",
    "plt.xlabel(\"RBM Energy\", fontsize=15)\n",
    "plt.ylabel(\"PDF\", fontsize=15)\n",
    "plt.legend([\"Trained RBM w/ Encoded Data\", \"Trained RBM w/ Gibbs sampled data\", \"Random RBM w/ Gibbs sampled data\", \"Random RBM w/ Init Encoded Data\"], fontsize=17)\n",
    "# plt.title(f'ln(Z)[AIS] = {np.round(Zais)}, ln(Z)[RAIS] = {np.round(Zrais)}')\n",
    "# plt.title(f'LL(trained) = {np.round(-energy_encoded_data.mean() - lnZais)}, LL(Rdm) = {np.round(-energy_encoded_data_rdm.mean() - lnZrais_rdm)} \\n \\\n",
    "        # LL(trained RBM data) = {np.round(-energy_rbm_data.mean() - lnZais)}, LL(Rdm RBM data) = {np.round(-energy_rbm_rdm_data.mean() - lnZrais_rdm)}')\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/RBM_energy_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d301b8da-fcc0-4df7-9a1d-e1426e2379f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f6f54-5170-4ce1-98be-b42bc4f73b29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minVal, maxVal = min(energy_encoded_data.numpy()), max(energy_encoded_data.numpy())\n",
    "# minVal, maxVal = min(energy_dwave.detach().cpu().numpy()+ Hoffset/2), max(energy_dwave.detach().cpu().numpy()+ Hoffset/2)\n",
    "binwidth = (maxVal-minVal)/30\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(energy_encoded_data.numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), linewidth=2.5, color=\"b\", density=True, log=True, label=\"Encoded data\", alpha=0.7)\n",
    "plt.hist(energy_rbm_data.numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), color=\"orange\", density=True, fc=(1, 0, 1, 0.5), log=True, histtype='step', linewidth=2.5, label=\"MC\")\n",
    "# plt.hist(energy_dwave.detach().cpu().numpy() + Hoffset/2, bins=np.arange(minVal, maxVal + binwidth, binwidth), color=\"m\", density=True, fc=(1, 0, 1, 0.5), log=True, histtype='step', linewidth=2.5, label=\"QPU\")\n",
    "\n",
    "# plt.hist(energy_rbm_rdm_data.numpy(), bins=20, linewidth=2.5, color=\"cyan\", density=True, fc=(0.5, 1.0, 0.5, 0.8))\n",
    "# plt.hist(energy_encoded_data_rdm.numpy(), bins=70, linewidth=2.5, color=\"r\", density=True)\n",
    "\n",
    "plt.xlabel(\"RBM Energy\", fontsize=15)\n",
    "plt.ylabel(\"PDF\", fontsize=15)\n",
    "# plt.legend([\"Encoded data\", \"Gibbs sampled data\", \"QA sampled data\"], fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "# plt.title(f'ln(Z)[AIS] = {np.round(Zais)}, ln(Z)[RAIS] = {np.round(Zrais)}')\n",
    "# plt.title(f'LL(trained) = {np.round(-energy_encoded_data.mean() - lnZais)}, LL(Rdm) = {np.round(-energy_encoded_data_rdm.mean() - lnZrais_rdm)} \\n \\\n",
    "        # LL(trained RBM data) = {np.round(-energy_rbm_data.mean() - lnZais)}, LL(Rdm RBM data) = {np.round(-energy_rbm_rdm_data.mean() - lnZrais_rdm)}')\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/RBM_energy_2_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d984e56a-4104-4a57-83cc-bc21e28732d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sparsity and Energy\n",
    "# beta\n",
    "# _just_act_cool(in_data, true_energy)\n",
    "# _shift_energy(in_data, true_energy)\n",
    "sample_data_qpu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f45d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# en_labels = []\n",
    "\n",
    "xtarget_samples = []\n",
    "xrecon_samples = []\n",
    "xgen_samples = []\n",
    "xgen_samples_qpu = []\n",
    "n_samples4_qpu = 200\n",
    "\n",
    "# xrecon_samples_2 = []\n",
    "\n",
    "# labelstarget_samples = []\n",
    "# labelsrecon_samples = []\n",
    "entarget_samples = []\n",
    "with torch.no_grad():\n",
    "    for xx in val_loader:\n",
    "    # for xx in train_loader:\n",
    "        in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "        ###############################################\n",
    "        # true_energy = true_energy[:n_samples4_qpu,:]\n",
    "        # in_data = in_data[:n_samples4_qpu,:]\n",
    "        ##############################################\n",
    "        # print(in_data.shape)\n",
    "        if reducedata:\n",
    "            in_data = engine._reduce(in_data, true_energy, R=R)\n",
    "        fwd_output = engine.model((in_data, true_energy), False)\n",
    "        if reducedata:\n",
    "            in_data = engine._reduceinv(in_data, true_energy, R=R)\n",
    "            recon_data = engine._reduceinv(fwd_output.output_activations, true_energy, R=R)\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            if True:\n",
    "                sample_energies, sample_data = engine._model.generate_samples_cond(num_samples=true_energy.shape[0], true_energy=true_energy, measure_time=True)\n",
    "                # sample_energies_qpu, sample_data_qpu = engine.model.generate_samples_qpu_cond(true_energy=true_energy, num_samples=1, thrsh=30, beta=1/beta0)\n",
    "            else:\n",
    "                sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy, measure_time=True)\n",
    "                # sample_energies_qpu, sample_data_qpu = engine._model.generate_samples_qpu(num_samples=true_energy.shape[0], true_energy=true_energy, measure_time=True, beta=1/beta0)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = engine._reduceinv(sample_data, sample_energies, R=R)\n",
    "            # sample_data_qpu = engine._reduceinv(sample_data_qpu, sample_energies_qpu, R=R)\n",
    "        elif scaled:\n",
    "            in_data = torch.tensor(engine._data_mgr.inv_transform(in_data.detach().cpu().numpy()))\n",
    "            recon_data = torch.tensor(engine._data_mgr.inv_transform(fwd_output.output_activations.detach().cpu().numpy()))\n",
    "            # recon_data_2 = torch.tensor(engine._data_mgr.inv_transform(fwd_just_act.detach().cpu().numpy()))\n",
    "            # recon_data_2 = torch.tensor(engine._data_mgr.inv_transform(fwd_energy_shift.detach().cpu().numpy()))\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            \n",
    "            if True:\n",
    "                sample_energies, sample_data = engine._model.generate_samples_cond(num_samples=true_energy.shape[0], true_energy=true_energy, measure_time=True)\n",
    "                # sample_energies_qpu, sample_data_qpu = engine.model.generate_samples_qpu_cond(true_energy=true_energy[:100,:], num_samples=1, thrsh=30, beta=1/beta0)\n",
    "            else:\n",
    "                sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy, measure_time=True)\n",
    "                # sample_energies_qpu, sample_data_qpu = engine._model.generate_samples_qpu(num_samples=true_energy.shape[0], true_energy=true_energy, measure_time=True, beta=1/beta0)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = torch.tensor(engine._data_mgr.inv_transform(sample_data.detach().cpu().numpy()))\n",
    "            # sample_data_qpu = torch.tensor(engine._data_mgr.inv_transform(sample_data_qpu.detach().cpu().numpy()))\n",
    "        else:\n",
    "            in_data = in_data.detach().cpu()*1000\n",
    "            recon_data = fwd_output.output_activations.detach().cpu()*1000\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            # sample_energies, sample_data = engine._model.generate_samples(num_samples=2048)\n",
    "            sample_data = sample_data.detach().cpu()*1000\n",
    "\n",
    "\n",
    "        xtarget_samples.append(in_data.detach().cpu())\n",
    "        xrecon_samples.append( recon_data.detach().cpu())\n",
    "        xgen_samples.append( sample_data.detach().cpu())\n",
    "        # xgen_samples_qpu.append( sample_data_qpu.detach().cpu())\n",
    "        entarget_samples.append(true_energy.detach().cpu())\n",
    "\n",
    "        # xrecon_samples_2.append( recon_data_2.detach().cpu())\n",
    "    \n",
    "    \n",
    "xtarget_samples = torch.cat(xtarget_samples, dim=0)\n",
    "xrecon_samples = torch.cat(xrecon_samples, dim=0)\n",
    "xgen_samples = torch.cat(xgen_samples, dim=0)\n",
    "# xgen_samples_qpu = torch.cat(xgen_samples_qpu, dim=0)\n",
    "entarget_samples = torch.cat(entarget_samples, dim=0)\n",
    "\n",
    "# xrecon_samples_2 = torch.cat(xrecon_samples_2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64833670-8ed1-4bea-ba5d-43743c1b12e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(xgen_samples.sum(dim=0) == 0).sum()\n",
    "(xrecon_samples.sum(dim=0) == 0).sum()\n",
    "# (xtarget_samples.sum(dim=0) == 0).sum()\n",
    "# print((xgen_samples.sum(dim=0) == 0).nonzero(as_tuple=True))\n",
    "# print((xrecon_samples.sum(dim=0) == 0).nonzero(as_tuple=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed1e4d-decf-4049-9d2e-8d42ac30ce0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random RBM\n",
    "# engine.model.sampler._prbm._bias_dict = load_RBM_state(f'/home/javier/Projects/CaloQVAE/outputs/2023-11-21/13-09-06/wandb/latest-run/files/RBM/RBM_1_9_biases.pth', dev)\n",
    "# engine.model.sampler._prbm._weight_dict = load_RBM_state(f'/home/javier/Projects/CaloQVAE/outputs/2023-11-21/13-09-06/wandb/latest-run/files/RBM/RBM_1_9_weights.pth', dev)\n",
    "engine.model.sampler._prbm._bias_dict = engine_2.model.sampler._prbm._bias_dict\n",
    "engine.model.sampler._prbm._weight_dict = engine_2.model.sampler._prbm._weight_dict\n",
    "# en_labels = []\n",
    "\n",
    "xtarget_samples = []\n",
    "xrecon_samples = []\n",
    "xgen_samples = []\n",
    "xgen_samples_qpu = []\n",
    "\n",
    "# labelstarget_samples = []\n",
    "# labelsrecon_samples = []\n",
    "entarget_samples = []\n",
    "with torch.no_grad():\n",
    "    for xx in val_loader:\n",
    "    # for xx in train_loader:\n",
    "        in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "        if reducedata:\n",
    "            in_data = engine._reduce(in_data, true_energy, R=R)\n",
    "        fwd_output = engine.model((in_data, true_energy), False)\n",
    "        if reducedata:\n",
    "            in_data = engine._reduceinv(in_data, true_energy, R=R)\n",
    "            recon_data = engine._reduceinv(fwd_output.output_activations, true_energy, R=R)\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = engine._reduceinv(sample_data, sample_energies, R=R)\n",
    "        elif scaled:\n",
    "            in_data = torch.tensor(engine._data_mgr.inv_transform(in_data.detach().cpu().numpy()))\n",
    "            recon_data = torch.tensor(engine._data_mgr.inv_transform(fwd_output.output_activations.detach().cpu().numpy()))\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy, measure_time=True)\n",
    "            # sample_energies_qpu, sample_data_qpu = engine._model.generate_samples_qpu(num_samples=true_energy.shape[0], true_energy=true_energy, measure_time=True, beta=1/beta)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = torch.tensor(engine._data_mgr.inv_transform(sample_data.detach().cpu().numpy()))\n",
    "            # sample_data_qpu = torch.tensor(engine._data_mgr.inv_transform(sample_data_qpu.detach().cpu().numpy()))\n",
    "        else:\n",
    "            in_data = in_data.detach().cpu()*1000\n",
    "            recon_data = fwd_output.output_activations.detach().cpu()*1000\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            # sample_energies, sample_data = engine._model.generate_samples(num_samples=2048)\n",
    "            sample_data = sample_data.detach().cpu()*1000\n",
    "\n",
    "        # xrecon_samples.append( torch.tensor(engine._data_mgr.inv_transform(fwd_output.output_activations.detach().cpu().numpy())) )\n",
    "    #     if engine._config.engine.cl_lambda:\n",
    "    #         labelsrecon_samples.append(fwd_output.labels.detach().cpu())\n",
    "    #         labelstarget_samples.append( nn.functional.one_hot(true_energy.divide(256).log2().to(torch.int64), num_classes=15).squeeze(1).to(torch.float).detach().cpu() )\n",
    "\n",
    "    #         en_labels.append(true_energy.detach().cpu())\n",
    "\n",
    "        xtarget_samples.append(in_data.detach().cpu())\n",
    "        xrecon_samples.append( recon_data.detach().cpu())\n",
    "        xgen_samples.append( sample_data.detach().cpu())\n",
    "        # xgen_samples_qpu.append( sample_data_qpu.detach().cpu())\n",
    "        entarget_samples.append(true_energy.detach().cpu())\n",
    "\n",
    "        # xtarget_samples.append( torch.tensor(engine._data_mgr.inv_transform(xx[0][0].detach().cpu().numpy())) )\n",
    "    \n",
    "    \n",
    "xtarget_samples = torch.cat(xtarget_samples, dim=0)\n",
    "xrecon_samples = torch.cat(xrecon_samples, dim=0)\n",
    "xgen_samples = torch.cat(xgen_samples, dim=0)\n",
    "# xgen_samples_qpu = torch.cat(xgen_samples_qpu, dim=0)\n",
    "entarget_samples = torch.cat(entarget_samples, dim=0)\n",
    "\n",
    "# if engine._config.engine.cl_lambda:\n",
    "#     labelstarget_samples = torch.cat(labelstarget_samples, dim=0)\n",
    "#     labelsrecon_samples = torch.cat(labelsrecon_samples, dim=0)\n",
    "#     en_labels = torch.cat(en_labels, dim=0)\n",
    "\n",
    "#     lhat = torch.argmax(nn.Sigmoid()(labelsrecon_samples), dim=1).numpy()\n",
    "#     l = torch.argmax(labelstarget_samples, dim=1).numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b91f5b9-5cad-4674-9726-a6f0e95641c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"mean qpu time\", np.mean([engine._model.sampling_time_qpu[i][0] for i in range(9)]), np.std([engine._model.sampling_time_qpu[i][0] for i in range(9)]))\n",
    "print(\"mean gpu time\", np.mean([engine._model.sampling_time_gpu[i][0] for i in range(9)]), np.std([engine._model.sampling_time_gpu[i][0] for i in range(9)]))\n",
    "print(\"mean gpu time/mean qpu time\", np.mean([engine._model.sampling_time_gpu[i][0] for i in range(9)])/np.mean([engine._model.sampling_time_qpu[i][0] for i in range(9)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123e80bd-b119-448e-8221-5c1e9c01946c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"mean qpu time\", np.mean([engine._model.sampling_time_qpu[i][0] for i in range(9)]), np.std([engine._model.sampling_time_qpu[i][0] for i in range(9)]))\n",
    "print(\"mean gpu time\", np.mean([engine._model.sampling_time_gpu[i][0] for i in range(9)]), np.std([engine._model.sampling_time_gpu[i][0] for i in range(9)]))\n",
    "print(\"mean gpu time/mean qpu time\", np.mean([engine._model.sampling_time_gpu[i][0] for i in range(9)])/np.mean([engine._model.sampling_time_qpu[i][0] for i in range(9)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87764fc8-c3db-4d13-bd0d-c4c8ccb4561a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minVal, maxVal = min(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy()), max(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy())\n",
    "binwidth = (maxVal-minVal)/50\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7, label=\"GT\")\n",
    "plt.hist(((xrecon_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"c\", label=\"Recon\")\n",
    "plt.hist(((xgen_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=3.5, color=\"orange\", linestyle=\"dashdot\", label=\"MC\")\n",
    "# plt.hist(((xgen_samples_qpu == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=3.5, color=\"brown\", linestyle=\"dashed\", label=\"QPU\")\n",
    "plt.xlabel(\"Sparsity Index\", fontsize=15)\n",
    "plt.ylabel(\"Histogram\", fontsize=15)\n",
    "# plt.legend([\"GT\", \"Recon\", \"Samples\", \"Sample /w QPU\"], fontsize=17)\n",
    "plt.legend( fontsize=17)\n",
    "# plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sparsity_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10455e-bd04-453f-8d01-cfa5255e122b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=20, log=True, histtype='step', linewidth=2.5, color=\"b\")\n",
    "plt.hist(((xrecon_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=20, log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "plt.hist(((xgen_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=20, log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashed\")\n",
    "# plt.hist(((xgen_samples_qpu == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=20, log=True, histtype='step', linewidth=2.5, color=\"green\", linestyle=\"dashed\")\n",
    "plt.xlabel(\"Sparsity Index\")\n",
    "plt.ylabel(\"Histogram\")\n",
    "plt.legend([\"GT\", \"Recon\", \"Samples\", \"Sample /w QPU\"])\n",
    "plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sparsity_RDM_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd9cc71-7a5c-43e8-88e2-9a4d8ad7d5bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HLF_1_electron.relevantLayers = [0,5,10,15,20,25,30,35,40,45]\n",
    "plt.figure(figsize=(8,6))\n",
    "# Create a grid of subplots\n",
    "fig, axes = plt.subplots(3,3, figsize=(12, 12), sharey=True, sharex=True, tight_layout=True)\n",
    "fig.text(0.5, -0.01, 'Sparsity Index', ha='center', fontsize=15)\n",
    "fig.text(-0.01, 0.5, 'Histogram', va='center', rotation='vertical', fontsize=15)\n",
    "\n",
    "# Iterate through the columns of X and plot histograms\n",
    "for i,_ in enumerate(HLF_1_electron.relevantLayers[:-1]):\n",
    "    row_index = i // 3  # Determine the row index\n",
    "    col_index = i % 3   # Determine the column index\n",
    "    \n",
    "    ax = axes[row_index, col_index]  # Get the current subplot\n",
    "    \n",
    "    # Plot histogram for the current column\n",
    "    idx = HLF_1_electron.relevantLayers[i+1]*9*16\n",
    "    idxPrev = (HLF_1_electron.relevantLayers[i])*9*16\n",
    "    l = idx - idxPrev\n",
    "    minVal, maxVal = min(((xtarget_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy()), max(((xtarget_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy())\n",
    "    binwidth = (maxVal-minVal)/50\n",
    "    ax.hist(((xtarget_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy(),  bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7, label=\"GT\")\n",
    "    ax.hist(((xrecon_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"c\", label=\"Recon\")\n",
    "    ax.hist(((xgen_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashdot\", label=\"MC\")\n",
    "    # ax.hist(((xgen_samples_qpu[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashed\", label=\"QPU\")\n",
    "    if i == 0:\n",
    "        # ax.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], fontsize=14)\n",
    "        ax.legend(fontsize=14)\n",
    "    ax.grid(\"True\")\n",
    "    \n",
    "    # Set labels and title for the subplot\n",
    "    # ax.set_xlabel(f'Column {i + 1}')\n",
    "    # ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Layers {HLF_1_electron.relevantLayers[i]} to {HLF_1_electron.relevantLayers[i+1]-1}', fontsize=12)\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sparsity_per_layer_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9746360-eded-4c05-9be7-8ee72ee64e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), ((xrecon_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(),  marker='.', alpha=.5, color=\"b\")\n",
    "plt.scatter(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), ((xgen_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(),  marker='.', alpha=.5, color=\"orange\")\n",
    "# plt.scatter(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), ((xgen_samples_qpu == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(),  marker='.', alpha=.5, color=\"c\")\n",
    "plt.plot([0,1],[0,1], c='red', lw=2.5)\n",
    "plt.xlabel('GT Sparsity Index', fontsize=15)\n",
    "plt.ylabel('Reconstruction Sparsity Index', fontsize=15)\n",
    "plt.legend([\"Recon\", \"MC\", \"QPU\"], fontsize=17)\n",
    "# plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sparsity_scatter_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574bbfe2-32fe-4d50-a1a4-63ac22ae488c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "E_right = 100000\n",
    "E_left = 3000\n",
    "tmp = (entarget_samples < E_right) * (entarget_samples > E_left)\n",
    "idxEnFilter = (tmp == True).nonzero(as_tuple=True)[0]\n",
    "len(idxEnFilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aee82f-c2dc-4abf-a5ea-240786dd3999",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minVal, maxVal = min((xtarget_samples[idxEnFilter,:].sum(dim=1)/entarget_samples[idxEnFilter].view(-1)).numpy()), max((xtarget_samples[idxEnFilter,:].sum(dim=1)/entarget_samples[idxEnFilter].view(-1)).numpy())\n",
    "binwidth = (maxVal-minVal)/50\n",
    "plt.hist((xtarget_samples[idxEnFilter,:].sum(dim=1)/entarget_samples[idxEnFilter].view(-1)).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7, density=True, label=\"GT\")\n",
    "plt.hist((xrecon_samples[idxEnFilter,:].sum(dim=1).numpy()/entarget_samples[idxEnFilter].view(-1)).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"c\", density=True, label=\"Recon\")\n",
    "plt.hist((xgen_samples[idxEnFilter,:].sum(dim=1).numpy()/entarget_samples[idxEnFilter].view(-1)).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashdot\", density=True, label=\"MC\")\n",
    "# plt.hist((xgen_samples_qpu[idxEnFilter,:].sum(dim=1)/entarget_samples[idxEnFilter].view(-1)).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashed\", density=True, label=\"QPU\")\n",
    "\n",
    "# plt.hist((xtarget_samples.sum(dim=1)/entarget_samples.view(-1)).numpy(), bins=30, log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7, density=True)\n",
    "# plt.hist((xrecon_samples.sum(dim=1).numpy()/entarget_samples.view(-1)).numpy(), bins=30, log=True, histtype='step', linewidth=2.5, color=\"c\", density=True)\n",
    "# plt.hist((xgen_samples.sum(dim=1).numpy()/entarget_samples.view(-1)).numpy(), bins=30, log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashdot\", density=True)\n",
    "# plt.hist((xgen_samples_qpu[idxEnFilter,:].sum(dim=1)/entarget_samples[idxEnFilter].view(-1)).numpy(), bins=30, log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashed\", density=True)\n",
    "\n",
    "\n",
    "plt.xlabel(\"Energy ratio\", fontsize=15)\n",
    "# plt.xscale('log')\n",
    "\n",
    "plt.ylabel(\"Histogram\", fontsize=15)\n",
    "# plt.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "# plt.title(f'{ds[part]} \\n {E_left/1000}<E_inc<{E_right/1000} (GeV)')\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_ration_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23327d69-c91d-4674-90e8-6065cecfc3a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minVal, maxVal = min(xtarget_samples[idxEnFilter,:].sum(dim=1).numpy()/1000), max(xtarget_samples[idxEnFilter,:].sum(dim=1).numpy()/1000)\n",
    "binwidth = (maxVal-minVal)/50\n",
    "plt.hist(xtarget_samples[idxEnFilter,:].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7, density=True, label=\"GT\")\n",
    "plt.hist(xrecon_samples[idxEnFilter,:].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"c\", density=True, label=\"Recon\")\n",
    "plt.hist(xgen_samples[idxEnFilter,:].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashdot\", density=True, label=\"MC\")\n",
    "# plt.hist(xgen_samples_qpu[idxEnFilter,:].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashed\", density=True, label=\"QPU\")\n",
    "\n",
    "plt.xlabel(\"energy per event (GeV)\", fontsize=15)\n",
    "# plt.xscale('log')\n",
    "\n",
    "plt.ylabel(\"Histogram\", fontsize=15)\n",
    "# plt.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"])\n",
    "plt.legend(fontsize=18)\n",
    "# plt.title(f'{ds[part]} \\n {E_left/1000}<E_inc<{E_right/1000} (GeV)')\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_slice_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfafa50-5e03-46d1-bacb-9f8b3c80b965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HLF_1_electron.relevantLayers = [0,5,10,15,20,25,30,35,40,45]\n",
    "plt.figure(figsize=(8,6))\n",
    "# Create a grid of subplots\n",
    "fig, axes = plt.subplots(3,3, figsize=(12, 12), sharey=True, sharex=False, tight_layout=True)\n",
    "fig.text(0.5, 0.0, 'Energy per event (GeV)', ha='center', fontsize=15)\n",
    "fig.text(0.0, 0.5, 'Histogram', va='center', rotation='vertical', fontsize=15)\n",
    "\n",
    "# Iterate through the columns of X and plot histograms\n",
    "for i,_ in enumerate(HLF_1_electron.relevantLayers[:-1]):\n",
    "    row_index = i // 3  # Determine the row index\n",
    "    col_index = i % 3   # Determine the column index\n",
    "    \n",
    "    ax = axes[row_index, col_index]  # Get the current subplot\n",
    "    \n",
    "    # Plot histogram for the current column\n",
    "    idx = HLF_1_electron.relevantLayers[i+1]*9*16\n",
    "    idxPrev = (HLF_1_electron.relevantLayers[i])*9*16\n",
    "    l = idx - idxPrev\n",
    "    minVal, maxVal = min(xtarget_samples[idxEnFilter, idxPrev:idx].sum(dim=1).numpy()/1000), max(xtarget_samples[idxEnFilter, idxPrev:idx].sum(dim=1).numpy()/1000)\n",
    "    binwidth = (maxVal-minVal)/50\n",
    "    ax.hist(xtarget_samples[idxEnFilter, idxPrev:idx].sum(dim=1).numpy()/1000,  bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7, label=\"GT\")\n",
    "    ax.hist(xrecon_samples[idxEnFilter, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"c\", label=\"Recon\")\n",
    "    # ax.hist(xrecon_samples_2[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=20, log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashdot\", label=\"MC\")\n",
    "    ax.hist(xgen_samples[idxEnFilter, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashdot\", label=\"MC\")\n",
    "    # ax.hist(xgen_samples_qpu[idxEnFilter, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashed\", label=\"QPU\")\n",
    "    if i == 0:\n",
    "        # ax.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], title=f'{ds[part]}')\n",
    "        ax.legend(fontsize=15)\n",
    "    ax.grid(\"True\")\n",
    "    \n",
    "    # Set labels and title for the subplot\n",
    "    # ax.set_xlabel(f'Column {i + 1}')\n",
    "    # ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Layers {HLF_1_electron.relevantLayers[i]} to {HLF_1_electron.relevantLayers[i+1]-1}')\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_per_layer_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a20645a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minVal, maxVal = min(xtarget_samples.sum(dim=1).numpy()/1000), max(xtarget_samples.sum(dim=1).numpy()/1000)\n",
    "binwidth = (maxVal-minVal)/50\n",
    "plt.hist(xtarget_samples.sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7, label=\"GT\")\n",
    "plt.hist(xrecon_samples.sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"c\", label=\"Recon\")\n",
    "plt.hist(xgen_samples.sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"orange\", linestyle=\"dashdot\", label=\"MC\")\n",
    "# plt.hist(xgen_samples_qpu.sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"brown\", linestyle=\"dashed\", label=\"QPU\")\n",
    "# plt.hist(xtarget_samples.sum(dim=1).numpy()/1000, bins=np.arange(0, 100 + 1,2), log=True, histtype='step', linewidth=2.5, color=\"b\")\n",
    "# plt.hist(xrecon_samples.sum(dim=1).numpy()/1000, bins=np.arange(0, 100 + 1,2), log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "# plt.hist(xgen_samples.sum(dim=1).numpy()/1000, bins=np.arange(0, 100 + 1,2), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashed\")\n",
    "# plt.hist(xtarget_samples.sum(dim=1).numpy()/1000, bins=np.arange(100+1, 1000 + 1,10), log=True, histtype='step')\n",
    "# plt.hist(xrecon_samples.sum(dim=1).numpy()/1000, bins=np.arange(100+1, 1000 + 1,10), log=True, histtype='step')\n",
    "# plt.hist(xgen_samples.sum(dim=1).numpy()/1000, bins=np.arange(100+1, 1000 + 1,10), log=True, histtype='step')\n",
    "plt.xlabel(\"Energy per event (GeV)\", fontsize=15)\n",
    "# plt.xscale('log')\n",
    "\n",
    "plt.ylabel(\"Histogram\", fontsize=15)\n",
    "# plt.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], fontsize=18)\n",
    "plt.legend( fontsize=18)\n",
    "# plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n",
    "print(xgen_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a488ff-3187-41f2-a534-8f066030a145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(xtarget_samples.sum(dim=1).numpy()/1000, bins=30, log=True, histtype='step', linewidth=2.5, color=\"b\")\n",
    "plt.hist(xrecon_samples.sum(dim=1).numpy()/1000, bins=30, log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "plt.hist(xgen_samples.sum(dim=1).numpy()/1000, bins=30, log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"orange\", linestyle=\"dashed\")\n",
    "# plt.hist(xgen_samples_qpu.sum(dim=1).numpy()/1000, bins=30, log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"green\", linestyle=\"dashed\")\n",
    "# plt.hist(xtarget_samples.sum(dim=1).numpy()/1000, bins=np.arange(0, 100 + 1,2), log=True, histtype='step', linewidth=2.5, color=\"b\")\n",
    "# plt.hist(xrecon_samples.sum(dim=1).numpy()/1000, bins=np.arange(0, 100 + 1,2), log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "# plt.hist(xgen_samples.sum(dim=1).numpy()/1000, bins=np.arange(0, 100 + 1,2), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashed\")\n",
    "# plt.hist(xtarget_samples.sum(dim=1).numpy()/1000, bins=np.arange(100+1, 1000 + 1,10), log=True, histtype='step')\n",
    "# plt.hist(xrecon_samples.sum(dim=1).numpy()/1000, bins=np.arange(100+1, 1000 + 1,10), log=True, histtype='step')\n",
    "# plt.hist(xgen_samples.sum(dim=1).numpy()/1000, bins=np.arange(100+1, 1000 + 1,10), log=True, histtype='step')\n",
    "plt.xlabel(\"energy per event (GeV)\")\n",
    "# plt.xscale('log')\n",
    "\n",
    "plt.ylabel(\"Histogram\")\n",
    "plt.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"])\n",
    "plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_RDM_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n",
    "print(xgen_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d1b7fa-9e21-476c-9fac-8e518f3f178a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(xtarget_samples.sum(dim=1).numpy()/1000, xrecon_samples.sum(dim=1).numpy()/1000, marker='.', alpha=.5, color=\"b\")\n",
    "plt.scatter(xtarget_samples.sum(dim=1).numpy()/1000, xgen_samples.sum(dim=1).numpy()/1000, marker='.', alpha=.5, color=\"orange\")\n",
    "# plt.scatter(xtarget_samples.sum(dim=1).numpy()/1000, xgen_samples_qpu.sum(dim=1).numpy()/1000, marker='.', alpha=.5, color=\"cyan\")\n",
    "plt.plot([0,800],[0,800], c='red', lw=2.5, label='y=x')\n",
    "# plt.plot([0,20],[0,20], c='red', lw=2)\n",
    "# axes[0,1].set_xlabel(\"GT energy per event (GeV)\")\n",
    "plt.legend([\"Recon\", \"MC\", \"QPU\", \"y=x\"], fontsize=17)\n",
    "plt.grid(\"True\")\n",
    "plt.xlabel(\"GT energy per event (GeV)\", fontsize=15)\n",
    "plt.ylabel(\"Model output energy per \\n event (GeV)\", fontsize=15)\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_scatter_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a106b8-2a7b-47ef-812e-fce4e0f45450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(xtarget_samples.sum(dim=1).numpy()/1000, (xtarget_samples.sum(dim=1).numpy() - xrecon_samples.sum(dim=1).numpy())/1000, marker='o', alpha=0.7, color=\"b\")\n",
    "plt.scatter(xtarget_samples.sum(dim=1).numpy()/1000, (xtarget_samples.sum(dim=1).numpy() - xgen_samples.sum(dim=1).numpy())/1000, marker='o', alpha=0.4, color=\"orange\")\n",
    "# plt.scatter(xtarget_samples.sum(dim=1).numpy()/1000, (xtarget_samples.sum(dim=1).numpy() - xgen_samples_qpu.sum(dim=1).numpy())/1000, marker='o', alpha=0.2, color=\"m\")\n",
    "# plt.plot([0,20],[0,20], c='red', lw=2)\n",
    "plt.xlabel(\"GT energy per event (GeV)\", fontsize=15)\n",
    "plt.ylabel(\"Abs error (GeV)\", fontsize=15)\n",
    "plt.ylim([-40,40])\n",
    "plt.legend([\"Recon\", \"Sample\", \"Sample w/ QPU\"], fontsize=15)\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_scatter_AbsError_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee0ff6b-28ac-4bf8-8d33-b813f6b4deb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(1/(xtarget_samples.sum(dim=1).numpy()/1000), np.abs(xtarget_samples.sum(dim=1).numpy() - xrecon_samples.sum(dim=1).numpy())/(xtarget_samples.sum(dim=1).numpy()+1e-3), marker='o', alpha=.7, color=\"blue\")\n",
    "plt.scatter(1/(xtarget_samples.sum(dim=1).numpy()/1000), np.abs(xtarget_samples.sum(dim=1).numpy() - xgen_samples.sum(dim=1).numpy())/(xtarget_samples.sum(dim=1).numpy()+1e-3), marker='o', alpha=.3, color=\"orange\")\n",
    "# plt.scatter(1/(xtarget_samples.sum(dim=1).numpy()/1000), np.abs(xtarget_samples.sum(dim=1).numpy() - xgen_samples_qpu.sum(dim=1).numpy())/(xtarget_samples.sum(dim=1).numpy()+1e-3), marker='o', alpha=.1, color=\"m\")\n",
    "plt.plot([1e-3,1e1],np.sqrt([1e-3,1e1])*np.power(2,0.5), c='r', lw=2.5, label='y=sqrt(x)')\n",
    "# axes[1,1].plot([1e-9,1e-6],np.linspace(1e-9,1e-6)*np.power(10,3.5), c='c', lw=2.5, label='y=x', linestyle=\"dashed\")\n",
    "plt.grid(\"True\")\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.ylim([1e-5,1e1])\n",
    "plt.yticks([1e-5,1e-4,1e-3,1e-2,1e-1,1e0,1e1])\n",
    "plt.legend([\"Recon\", \"Sample\", \"Sample w/ QPU\", \"y=sqrt(x)\"], fontsize=15)\n",
    "plt.ylabel(\"Relative Error\", fontsize=15)\n",
    "plt.xlabel('1/(GT energy per event) (GeV)$^{-1}$', fontsize=15)\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_scatter_RelError_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8100cf5f-23aa-4c7d-93d4-8ee0bc2d0ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,2, figsize=(8,8), tight_layout=True)\n",
    "fig.text(0.5, 0.0, 'GT energy per event (GeV)', ha='center')\n",
    "# fig.text(0.5, 1.0, f'{ds[part]}', ha='center', fontsize=12)\n",
    "\n",
    "axes[0,0].scatter(xtarget_samples.sum(dim=1).numpy()/1000, xrecon_samples.sum(dim=1).numpy()/1000, marker='.', alpha=.5, color=\"b\")\n",
    "axes[0,0].scatter(xtarget_samples.sum(dim=1).numpy()/1000, xgen_samples.sum(dim=1).numpy()/1000, marker='.', alpha=.5, color=\"orange\")\n",
    "axes[0,0].plot([0,800],[0,800], c='red', lw=2.5, label='y=x')\n",
    "# axes[0,0].plot([0,3800],[0,3800], c='red', lw=2.5, label='y=x')\n",
    "axes[0,0].set_ylabel(\"Recon energy per event (GeV)\")\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(\"True\")\n",
    "axes[0,0].set_yscale('log')\n",
    "axes[0,0].set_xscale('log')\n",
    "\n",
    "axes[0,1].scatter(xtarget_samples.sum(dim=1).numpy()/1000, (xtarget_samples.sum(dim=1).numpy() - xrecon_samples.sum(dim=1).numpy())/1000, marker='.', alpha=0.6, color=\"b\")\n",
    "axes[0,1].scatter(xtarget_samples.sum(dim=1).numpy()/1000, (xtarget_samples.sum(dim=1).numpy() - xgen_samples.sum(dim=1).numpy())/1000, marker='.', alpha=0.2, color=\"orange\")\n",
    "# axes[0,1].scatter(xtarget_samples.sum(dim=1).numpy()/1000, (xtarget_samples.sum(dim=1).numpy() - xgen_samples_qpu.sum(dim=1).numpy())/1000, marker='.', alpha=0.1, color=\"m\")\n",
    "# plt.plot([0,20],[0,20], c='red', lw=2)\n",
    "# axes[0,1].set_xlabel(\"GT energy per event (GeV)\")\n",
    "axes[0,1].set_ylabel(\"Abs error (GeV)\")\n",
    "axes[0,1].set_ylim([-40,40])\n",
    "# axes[0,1].legend()\n",
    "# axes[0,1].set_yscale('log')\n",
    "axes[0,1].grid(\"True\")\n",
    "\n",
    "# axes[1,0].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy() - xtarget_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.5, color=\"blue\", label=\"Simulation\")\n",
    "# axes[1,0].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy() - xrecon_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.05, color=\"red\", label=\"Model\")\n",
    "axes[1,0].scatter(1/(entarget_samples.numpy()/1000), np.abs(entarget_samples.reshape(-1).numpy() - xtarget_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.5, color=\"blue\", label=\"Simulation\")\n",
    "axes[1,0].scatter(1/(entarget_samples.numpy()/1000), np.abs(entarget_samples.reshape(-1).numpy() - xrecon_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.05, color=\"red\", label=\"Model\")\n",
    "axes[1,0].plot([1e-3,1e0],np.power([1e-3,1e0],0.25)*np.power(10,2.0), c='orange', lw=2.5, label='slope=0.25', linestyle=\"dashdot\")\n",
    "axes[1,0].grid(\"True\")\n",
    "axes[1,0].set_yscale('log')\n",
    "axes[1,0].set_xscale('log')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].set_ylabel(\"Relative Error\")\n",
    "\n",
    "# axes[1,1].scatter(xtarget_samples.sum(dim=1).numpy()/1000, np.abs(xtarget_samples.sum(dim=1).numpy()/1000 - xrecon_samples.sum(dim=1).numpy()/1000), marker='.', alpha=.5, color=\"blue\")\n",
    "axes[1,1].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy()/1000 - xtarget_samples.sum(dim=1).numpy()/1000), marker='.', alpha=1, color=\"blue\", label=\"Simulation\")\n",
    "axes[1,1].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy()/1000 - xrecon_samples.sum(dim=1).numpy()/1000), marker='.', alpha=.2, color=\"red\", label=\"Model\")\n",
    "axes[1,1].plot([1,800],np.sqrt([1,800]), c='orange', lw=2.5, label='y=sqrt(x)', linestyle=\"dashdot\")\n",
    "axes[1,1].plot([1,800],[1,800], c='c', lw=2.5, label='y=x', linestyle=\"dashed\")\n",
    "# axes[1,1].set_title(f'{ds[part]}')\n",
    "axes[1,1].grid(\"True\")\n",
    "axes[1,1].set_yscale('log')\n",
    "axes[1,1].set_xscale('log')\n",
    "axes[1,1].set_ylabel(\"Absolute Error\")\n",
    "axes[1,1].legend()\n",
    "\n",
    "\n",
    "# Merge the first row's axes\n",
    "gs = axes[2, 0].get_gridspec()\n",
    "for ax in axes[2, :]:\n",
    "    ax.remove()\n",
    "ax_big = fig.add_subplot(gs[2, :])\n",
    "ax_big.scatter(1/(xtarget_samples.sum(dim=1).numpy()/1000), np.abs(xtarget_samples.sum(dim=1).numpy() - xrecon_samples.sum(dim=1).numpy())/(xtarget_samples.sum(dim=1).numpy()+1e-3), marker='.', alpha=.5, color=\"blue\")\n",
    "ax_big.scatter(1/(xtarget_samples.sum(dim=1).numpy()/1000), np.abs(xtarget_samples.sum(dim=1).numpy() - xgen_samples.sum(dim=1).numpy())/(xtarget_samples.sum(dim=1).numpy()+1e-3), marker='.', alpha=.5, color=\"orange\")\n",
    "# axes[1,0].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy() - xtarget_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.5, color=\"blue\", label=\"Simulation\")\n",
    "# axes[1,0].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy() - xrecon_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.05, color=\"red\", label=\"Model\")\n",
    "# axes[1,0].set_title(f'{ds[part]}')\n",
    "ax_big.plot([1e-3,1e1],np.sqrt([1e-3,1e1])*np.power(1,3.5), c='r', lw=2.5, label='y=sqrt(x)', linestyle=\"dashdot\")\n",
    "# axes[1,1].plot([1e-9,1e-6],np.linspace(1e-9,1e-6)*np.power(10,3.5), c='c', lw=2.5, label='y=x', linestyle=\"dashed\")\n",
    "ax_big.grid(\"True\")\n",
    "ax_big.set_yscale('log')\n",
    "ax_big.set_xscale('log')\n",
    "ax_big.legend()\n",
    "ax_big.set_ylim([1e-5,1e1])\n",
    "ax_big.set_yticks([1e-5,1e-4,1e-3,1e-2,1e-1,1e0,1e1])\n",
    "ax_big.set_ylabel(\"Relative Recon Error\")\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_scatter_4panels_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104498b6-af53-464f-b6eb-b7924634d099",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HLF_1_electron.relevantLayers = [0,5,10,15,20,25,30,35,40,45]\n",
    "plt.figure(figsize=(8,6))\n",
    "# Create a grid of subplots\n",
    "fig, axes = plt.subplots(3,3, figsize=(12, 12), sharey=True, sharex=False, tight_layout=True)\n",
    "fig.text(0.5, 0.0, 'Energy per event (GeV)', ha='center', fontsize=15)\n",
    "fig.text(0.0, 0.5, 'Histogram', va='center', rotation='vertical', fontsize=15)\n",
    "\n",
    "# Iterate through the columns of X and plot histograms\n",
    "for i,_ in enumerate(HLF_1_electron.relevantLayers[:-1]):\n",
    "    row_index = i // 3  # Determine the row index\n",
    "    col_index = i % 3   # Determine the column index\n",
    "    \n",
    "    ax = axes[row_index, col_index]  # Get the current subplot\n",
    "    \n",
    "    # Plot histogram for the current column\n",
    "    idx = HLF_1_electron.relevantLayers[i+1]*9*16\n",
    "    idxPrev = (HLF_1_electron.relevantLayers[i])*9*16\n",
    "    l = idx - idxPrev\n",
    "    minVal, maxVal = min(xtarget_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000), max(xtarget_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000)\n",
    "    binwidth = (maxVal-minVal)/50\n",
    "    ax.hist(xtarget_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000,  bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7)\n",
    "    ax.hist(xrecon_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"c\")\n",
    "    # ax.hist(xrecon_samples_2[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=20, log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "    ax.hist(xgen_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashdot\")\n",
    "    # ax.hist(xgen_samples_qpu[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashed\")\n",
    "    if i == 0:\n",
    "        # ax.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], title=f'{ds[part]}')\n",
    "        ax.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], fontsize=15)\n",
    "    ax.grid(\"True\")\n",
    "    \n",
    "    # Set labels and title for the subplot\n",
    "    # ax.set_xlabel(f'Column {i + 1}')\n",
    "    # ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Layers {HLF_1_electron.relevantLayers[i]} to {HLF_1_electron.relevantLayers[i+1]-1}')\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_per_layer_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a163100f-ac31-41d9-9b14-e10ef0a4996f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgen_samples2 = []\n",
    "en_input = [1,2,3,5,10,20,30,50,100,200,300,500,1000,2000,3000,5000,10000,20000]\n",
    "ll = len(en_input)\n",
    "gen_bs = 2048 #true_energy.shape[0]\n",
    "with torch.no_grad():\n",
    "    for i in en_input:\n",
    "        if reducedata:\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = engine._reduceinv(sample_data, sample_energies, R=R)\n",
    "        elif scaled:\n",
    "            engine._model.sampler._batch_size = gen_bs # true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=1000*i, measure_time=True)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = torch.tensor(engine._data_mgr.inv_transform(sample_data.detach().cpu().numpy()))\n",
    "        else:\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = sample_data.detach().cpu()*1000\n",
    "\n",
    "        xgen_samples2.append( sample_data.detach().cpu())\n",
    "\n",
    "xgen_samples2 = torch.cat(xgen_samples2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e450b-6dd3-4553-a82a-a0d17ed6ec92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "energy_gen = xgen_samples2.sum(dim=1)\n",
    "m_energy_gen = [energy_gen[i*gen_bs:gen_bs*(i+1)].sum().item()/1000 for i in range(ll)]\n",
    "sd_energy_gen = [energy_gen[i*gen_bs:gen_bs*(i+1)].std().item()/1000 for i in range(ll)]\n",
    "lin_inter = np.power(m_energy_gen,1/2) * (1 - np.array(m_energy_gen)/np.array(m_energy_gen).max()) \\\n",
    "    + np.power(m_energy_gen,1) * np.array(m_energy_gen)/np.array(m_energy_gen).max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed8495-167b-4a42-9524-63bb2abfe429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(np.array(m_energy_gen)/1000, sd_energy_gen, c='orange', lw=3.5, label='event mean energy')\n",
    "plt.plot((np.array(en_input)), sd_energy_gen, c='blue', lw=3.5, label='inc energy', linestyle=\"dashed\")\n",
    "plt.grid(\"True\")\n",
    "# plt.plot([1,10], np.sqrt([1,10])*np.power(10, -0.8))\n",
    "plt.plot(np.array(m_energy_gen)/1000, lin_inter*np.power(10, -1.8), c='red', lw=3.5, label='linear interpolation b/w sqrt and lin')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.axvline(x=1000, c='black', lw=2.5, label='max energy trained on', linestyle=\"dashdot\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"E (GeV)\")\n",
    "plt.ylabel(\"σₑ\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca60851a-cddc-4ac2-8bc0-2ce382388ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# post_samples = torch.cat(post_samples,1)\n",
    "M = post_samples.shape[1]\n",
    "post_samples_cpu = post_samples.clone().detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaf98d6-57c1-4c09-b4f1-6830b957f7eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "pres = [(torch.arange(0,M).multiply(i*np.pi/M).cos() * post_samples_cpu + torch.arange(0,M).multiply(i*np.pi/M).sin() *(1 - post_samples_cpu).abs()).divide(np.sqrt(M)).unsqueeze(2) for i in np.arange(1,M-1,1)]\n",
    "# pres = [(torch.arange(0,M).multiply(i*np.pi/M).cos()).divide(np.sqrt(M)) for i in np.arange(1,M-1,1)]\n",
    "pos_enc = torch.cat(pres,2).transpose(1,2);\n",
    "res = pos_enc.sum([1,2])/(M-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c126cc5b-2bb6-44d0-aa82-391fd5539abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.plot(pres[0][0,:,0])\n",
    "# plt.plot(pres[1][0,:,0])\n",
    "# plt.plot(pres[10][0,:,0])\n",
    "plt.xlabel(\"partition index\")\n",
    "plt.plot(pos_enc.sum([1,2]))\n",
    "# plt.plot(torch.arange(0,M).multiply(np.pi/M).cos())\n",
    "# pos_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9e11f7-db79-46e2-9887-174a6dcc8dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "post_samples.sum(dim=1).unique().shape\n",
    "pos_enc.sum([1,2]).unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc2a73-1916-4026-b8d3-87d2cad2ff0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "engine.model.encoder.binary_energy(true_energy);\n",
    "bin_en.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a6e2a2-ec4b-45fb-ba67-6c5b80f5d4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bin_en = torch.tensor([[np.random.randint(2)for i in range(M)] for j in range(50)])\n",
    "\n",
    "bin_en = engine.model.encoder.binary_energy(true_energy)\n",
    "M = bin_en.shape[1]\n",
    "\n",
    "pres = [(torch.arange(0,M).multiply(np.pi/M).cos().to(bin_en.device) * bin_en + torch.arange(0,M).multiply(np.pi/M).sin().to(bin_en.device) *(1 - bin_en).abs()).divide(np.sqrt(M)).unsqueeze(2) for i in np.arange(1,M-1,1)]\n",
    "pos_enc = torch.cat(pres,2).transpose(1,2);\n",
    "res = pos_enc.sum([1,2])/(M-1)\n",
    "res.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ef30d6-b473-4cf1-9a23-5c603fc80d96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(range(128), pos_enc.sum([1,2]).detach().cpu()/(M-1))\n",
    "# pos_enc.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbda6ee0-7c2d-4527-b8d5-b3ed43b643e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###########Create Synth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ebc743-f3c7-457c-b084-aa0fd0c4ce74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "engen_samples2 = []\n",
    "xgen_samples2 = []\n",
    "with torch.no_grad():\n",
    "    for i,xx in enumerate(train_loader):\n",
    "        in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "        if reducedata:\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples_cond(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = engine._reduceinv(sample_data, sample_energies, R=R)\n",
    "        elif scaled:\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy, measure_time=True)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = torch.tensor(engine._data_mgr.inv_transform(sample_data.detach().cpu().numpy()))\n",
    "        else:\n",
    "            engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "            sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "            engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "            sample_data = sample_data.detach().cpu()*1000\n",
    "\n",
    "        xgen_samples2.append( sample_data.detach().cpu())\n",
    "        engen_samples2.append(true_energy.detach().cpu())\n",
    "        \n",
    "        # if i > 30:\n",
    "        #     break\n",
    "\n",
    "xgen_samples2 = torch.cat(xgen_samples2, dim=0)\n",
    "engen_samples2 = torch.cat(engen_samples2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaae5da-a4ff-4f5e-a37c-57e54fe12c09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "import h5py\n",
    "\n",
    "# Convert tensors to numpy arrays as h5py does not support PyTorch tensors directly\n",
    "tensor1_np = xgen_samples2[:100000,:].numpy()\n",
    "tensor2_np = engen_samples2[:100000,:].numpy()\n",
    "\n",
    "# Create a new HDF5 file\n",
    "with h5py.File(f'/raid/javier/Datasets/CaloVAE/data/synData/dataset2_synthetic_{modelname}.hdf5', 'w') as f:\n",
    "    # Create datasets for your tensors\n",
    "    f.create_dataset('showers', data=tensor1_np)\n",
    "    f.create_dataset('incidence energy', data=tensor2_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3de6a5-fd05-4b65-a64e-79ab7d6c65b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = engine.model.prior.weight_dict['01'].sign().abs().sum(dim=1).detach().cpu().numpy()\n",
    "binwidth = 1.0\n",
    "data = {}\n",
    "for key in engine.model.prior.weight_dict.keys():\n",
    "    # data[key] = engine.model.prior.weight_dict[key].sign().abs().sum(dim=0).detach().cpu().numpy()\n",
    "    data[key] = engine.model.prior._weight_mask_dict[key].abs().sum(dim=0).detach().cpu().numpy()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f636e63-4c15-4fca-bc49-f867dce3fb21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create 2x2 grid of subplots\n",
    "fig, axs = plt.subplots(2, 3, figsize=(10, 7), sharey=True, sharex=True, tight_layout=True)  # 2x2 grid, figure size 10x10\n",
    "fig.text(0.5, 0.0, 'Couplings', ha='center', fontsize=15)\n",
    "fig.text(0.0, 0.4, 'Histogram', rotation=90, ha='center', fontsize=15)\n",
    "\n",
    "# Plot data on each subplot\n",
    "labels, counts = np.unique(data['01'], return_counts=True)\n",
    "axs[0,0].bar(labels, counts, align='center', color=\"b\", alpha=0.8)\n",
    "# axs[0, 0].hist(data['01'], bins=np.arange(min(data['01']), max(data['01']) + binwidth, binwidth), histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7, align='center')\n",
    "axs[0,0].grid(\"True\")\n",
    "axs[0,0].legend([\"v to h\"], fontsize=18)\n",
    "\n",
    "labels, counts = np.unique(data['02'], return_counts=True)\n",
    "axs[0,1].bar(labels, counts, align='center', color=\"b\", alpha=0.9)\n",
    "axs[0,1].grid(\"True\")\n",
    "axs[0,1].legend([\"v to s\"], fontsize=18)\n",
    "\n",
    "labels, counts = np.unique(data['03'], return_counts=True)\n",
    "axs[0,2].bar(labels, counts, align='center', color=\"b\", alpha=0.9)\n",
    "axs[0,2].grid(\"True\")\n",
    "axs[0,2].legend([\"v to t\"], fontsize=18)\n",
    "\n",
    "labels, counts = np.unique(data['12'], return_counts=True)\n",
    "axs[1,0].bar(labels, counts, align='center', color=\"b\", alpha=0.9)\n",
    "axs[1,0].grid(\"True\")\n",
    "axs[1,0].legend([\"h to s\"], fontsize=18)\n",
    "\n",
    "labels, counts = np.unique(data['13'], return_counts=True)\n",
    "axs[1,1].bar(labels, counts, align='center', color=\"b\", alpha=0.9)\n",
    "axs[1,1].grid(\"True\")\n",
    "axs[1,1].legend([\"h to t\"], fontsize=18)\n",
    "\n",
    "labels, counts = np.unique(data['12'], return_counts=True)\n",
    "axs[1,2].bar(labels, counts, align='center', color=\"b\", alpha=0.9)\n",
    "axs[1,2].grid(\"True\")\n",
    "axs[1,2].legend([\"s to t\"], fontsize=18)\n",
    "\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/weights_plot_zephyr.png', bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1172e4-75b8-4278-811f-6b9e7a34f385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.unique(HLF_1_pions.bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b83db1c-811d-480c-a945-0da83738bdef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xx = next(iter(val_loader))\n",
    "xx = next(iter(train_loader))\n",
    "in_data_pre, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1]) # input , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5c23ec-4e9c-4ff5-92c2-e7693bdf7dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if reducedata:\n",
    "    in_data = engine._reduce(in_data, true_energy, R=R)\n",
    "fwd_output = engine.model((in_data_pre, true_energy), False)\n",
    "if reducedata:\n",
    "    in_data = engine._reduceinv(in_data, true_energy, R=R)\n",
    "    recon_data = engine._reduceinv(fwd_output.output_activations, true_energy, R=R)\n",
    "    engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "    sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "    engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "    sample_data = engine._reduceinv(sample_data, sample_energies, R=R)\n",
    "elif scaled:\n",
    "    in_data = torch.tensor(engine._data_mgr.inv_transform(in_data_pre.detach().cpu().numpy()))\n",
    "    recon_data = torch.tensor(engine._data_mgr.inv_transform(fwd_output.output_activations.detach().cpu().numpy()))\n",
    "    engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "    # try:\n",
    "    sample_energies, sample_data = engine._model.generate_samples_cond(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "    # except:\n",
    "        # pass\n",
    "    engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "    # sample_energies, sample_data = engine._model.generate_samples(num_samples=2048)\n",
    "    sample_data = torch.tensor(engine._data_mgr.inv_transform(sample_data.detach().cpu().numpy()))\n",
    "else:\n",
    "    in_data = in_data.detach().cpu()*1000\n",
    "    recon_data = fwd_output.output_activations.detach().cpu()*1000\n",
    "    engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "    sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "    engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "    # sample_energies, sample_data = engine._model.generate_samples(num_samples=2048)\n",
    "    sample_data = sample_data.detach().cpu()*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a82abb-dce4-4c4a-ad86-aa92b696ae0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(20000/6)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90b672e-3725-4a6c-b3c4-7e4fbbcec853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "THRSH=7\n",
    "recon_data = recon_data * (recon_data > THRSH)\n",
    "sample_data = sample_data * (sample_data > THRSH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b9a4c-e9d7-42c7-9a9a-7bffabb94f01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HLF_1_pions.relevantLayers = [1,2,3,4,5,6,7]\n",
    "# np.unique(HLF_1_pions.bin_edges)\n",
    "# true_energy/1000\n",
    "# HLF_1_electron.relevantLayers\n",
    "true_energy[idx]/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547dae52-5624-4a8f-9476-ac538c899359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HLF_1_electron.relevantLayers = [0,5,10,15,20,25,30,35,40,44] #[i for i in range(0,5)] #[0,5,10,15,20,25,30,35,40,47,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb76334-d387-42a1-84f1-3564ca7f0e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (((in_data[:,0:108] - recon_data[:,0:108])/(in_data[:,0:108]))**2).sum(dim=1).argsort()[:20]\n",
    "# (((in_data - recon_data)/(in_data+1e-5))**2).sum(dim=1).argsort()[-200:-1]\n",
    "# (((in_data - recon_data))**2).sum(dim=1).argsort()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be370dc3-8afb-46d8-abfe-cbef70b47b74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xtarget_samples\n",
    "print(HLF_1_electron.DrawSingleShower(xtarget_samples[idx,:].detach().cpu().numpy(), vmax=1e+4, vmin=1e+0, cmap='rainbow', filename=None ) )\n",
    "print(HLF_1_electron.DrawSingleShower(xrecon_samples[idx,:].detach().cpu().numpy(), vmax=1e+4, vmin=1e+0, cmap='rainbow', filename=None ) )\n",
    "print(HLF_1_electron.DrawSingleShower(xgen_samples[idx,:].detach().cpu().numpy(), vmax=1e+4, vmin=1e+0, cmap='rainbow', filename=None ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10535ec8-4171-4e0f-a502-cd3f0627ec09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 45*16*9\n",
    "# probe = torch.zeros(6480)\n",
    "# probe[0] = 0.01\n",
    "# probe[1] = 0.1\n",
    "# probe[2:9] = torch.tensor([0.01*i for i in range(2,9)])\n",
    "# probe[9] = 1\n",
    "# HLF_1_electron.DrawSingleShower(probe.numpy()*1000, vmax=1e+4, vmin=1e+0, cmap='rainbow', filename=None ) \n",
    "in_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ada102-361a-48b1-9d04-ecea3d50b391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx=21\n",
    "# HLF_1_pions.DrawSingleShower(in_data[idx,:].detach().cpu().numpy(), filename=None)\n",
    "# HLF_1_pions.DrawSingleShower(in_data[idx,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/target_{idx}_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "\n",
    "HLF_1_electron.DrawSingleShower(in_data[idx,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/target_a_{idx}_{modelname}_{arch}_{datascaled}_{part}.png', vmax=1e+3, vmin=1e+0, cmap='rainbow')\n",
    "HLF_1_electron.DrawSingleShower(in_data[idx,:].detach().cpu().numpy(), vmax=1e+4, vmin=1e+0, cmap='rainbow', filename=None ) \n",
    "\n",
    "HLF_1_electron.DrawAverageShower(in_data[:,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/target_a_{idx}_{modelname}_{arch}_{datascaled}_{part}_avg.png')\n",
    "HLF_1_electron.DrawAverageShower(in_data[:,:].detach().cpu().numpy(),   vmax=1e+2, vmin=1e-2, cmap='rainbow', filename=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9706a637-40a7-4ffd-8daf-0721d37402d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HLF_1_pions.DrawSingleShower(recon_data[idx,:].detach().cpu().numpy(), filename=None)\n",
    "# HLF_1_pions.DrawSingleShower(recon_data[idx,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/recon_{idx}_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "\n",
    "HLF_1_electron.DrawSingleShower(recon_data[idx,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/recon_a_{idx}_{modelname}_{arch}_{datascaled}_{part}.png', vmax=1e+3, vmin=1e+0, cmap='rainbow')\n",
    "HLF_1_electron.DrawSingleShower(recon_data[idx,:].detach().cpu().numpy(), filename=None, vmax=1e+4, vmin=1e+0, cmap='rainbow')\n",
    "\n",
    "HLF_1_electron.DrawAverageShower(recon_data[:,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/recon_{idx}_{modelname}_{arch}_{datascaled}_{part}_avg.png')\n",
    "HLF_1_electron.DrawAverageShower(recon_data[:,:].detach().cpu().numpy(),  vmax=1e+2, vmin=1e-2, cmap='rainbow', filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad4061e-5ca2-4e00-9a8a-39286d219431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HLF_1_pions.DrawSingleShower(sample_data[idx,:].detach().cpu().numpy(), filename=None)\n",
    "# HLF_1_pions.DrawSingleShower(sample_data[1,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sample_{idx}_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "\n",
    "HLF_1_electron.DrawSingleShower(sample_data[idx,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sample_a_{idx}_{modelname}_{arch}_{datascaled}_{part}.png', vmax=1e+3, vmin=1e+0, cmap='rainbow')\n",
    "HLF_1_electron.DrawSingleShower(sample_data[idx,:].detach().cpu().numpy(), filename=None, vmax=1e+4, vmin=1e+0, cmap='rainbow')\n",
    "\n",
    "HLF_1_electron.DrawAverageShower(sample_data[:,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sample_a_{idx}_{modelname}_{arch}_{datascaled}_{part}_avg.png')\n",
    "HLF_1_electron.DrawAverageShower(sample_data[:,:].detach().cpu().numpy(),  vmax=1e+2, vmin=1e-2, cmap='rainbow', filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d80a8-d382-4c81-ada2-202e240d0d07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HLF_1_electron.DrawSingleShower(sample_data_qpu[idx,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sample_QPU_a_{idx}_{modelname}_{arch}_{datascaled}_{part}.png', vmax=1e+3, vmin=1e+0, cmap='rainbow')\n",
    "HLF_1_electron.DrawSingleShower(sample_data_qpu[idx,:].detach().cpu().numpy(), filename=None, vmax=1e+4, vmin=1e+0, cmap='rainbow')\n",
    "\n",
    "HLF_1_electron.DrawAverageShower(sample_data_qpu[:,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sample_QPU_a_{idx}_{modelname}_{arch}_{datascaled}_{part}_avg.png')\n",
    "HLF_1_electron.DrawAverageShower(sample_data_qpu[:,:].detach().cpu().numpy(),  vmax=1e+2, vmin=1e-2, cmap='rainbow', filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711e42a-09b3-41a2-9823-84b35975df5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samps = 50\n",
    "minVal, maxVal = min(xtarget_samples[:samps,:].view(-1)), max(xtarget_samples[:samps,:].view(-1))\n",
    "binwidth = (maxVal-minVal)/30\n",
    "\n",
    "plt.hist(xtarget_samples[:samps,:].view(-1), bins=np.arange(minVal, maxVal + binwidth, binwidth), density=True, log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7)\n",
    "plt.hist(xrecon_samples[:samps,:].view(-1), bins=np.arange(minVal, maxVal + binwidth, binwidth), density=True, log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"c\")\n",
    "plt.hist(xgen_samples[:samps,:].view(-1), bins=np.arange(minVal, maxVal + binwidth, binwidth), density=True, log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"orange\", linestyle=\"dashdot\")\n",
    "plt.xlabel(\"Energy per voxel (MeV)\", fontsize=15)\n",
    "\n",
    "plt.ylabel(\"Histogram\", fontsize=15)\n",
    "plt.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], fontsize=18)\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_per_voxel_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n",
    "print(xtarget_samples.view(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16347be-d694-4902-a175-e472106f60f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_qpu_time_to_train = [_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[0] for i in [128,256,512,1024]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c3a17-c141-4068-b123-4b328418ba2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %config InlineBackend.figure_format = 'retina'\n",
    "np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933cd57-fbd8-47ec-9d82-358e397c701f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[3] for i in [128,256,512,1024]],  marker='.', markersize=15, linewidth=2.5)\n",
    "# plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[3] for i in [128,256,512,1024]],  marker='o', markersize=15, linewidth=2.5)\n",
    "# plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[3] for i in [128,256,512,1024]],  marker='+', markersize=15, linewidth=2.5)\n",
    "# plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[3] for i in [128,256,512,1024]],  marker='.', markersize=15, linewidth=2.5)\n",
    "# plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[3] for i in [128,256,512,1024]],  marker='o', markersize=15, linewidth=2.5)\n",
    "# plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[3] for i in [128,256,512,1024]],  marker='+', markersize=15, linewidth=2.5)\n",
    "\n",
    "plt.plot([128,256,512,1024], np.array([_gpu_timing(temp_steps=3, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[3] for i in [128,256,512,1024]]),  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], np.array([_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[3] for i in [128,256,512,1024]]),  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], np.array([_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[3] for i in [128,256,512,1024]]),  marker='+', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], np.array([_gpu_timing(temp_steps=3, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[3] for i in [128,256,512,1024]]),  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], np.array([_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[3] for i in [128,256,512,1024]]),  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], np.array([_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[3] for i in [128,256,512,1024]]),  marker='+', markersize=15, linewidth=2.5)\n",
    "plt.xscale(\"log\")\n",
    "plt.axhline(y=1.5, color='black', linestyle='--')\n",
    "\n",
    "# plt.title(\"Milestone 4\")\n",
    "plt.xlabel(\"Training batch size\")\n",
    "plt.ylabel(\"Hours per 100 epochs\")\n",
    "plt.legend([\"steps=3, bs=256\",\"steps=5, bs=256\",\"steps=10, bs=256\", \"steps=3, bs=128\",\"steps=5, bs=128\",\"steps=10, bs=128\", \"1.5 hrs\"], title=\"βeff steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac426ba-3426-4d26-9783-34ac10878610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[2] for i in [128,256,512,1024]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[2] for i in [128,256,512,1024]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[2] for i in [128,256,512,1024]],  marker='+', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[2] for i in [128,256,512,1024]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[2] for i in [128,256,512,1024]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[2] for i in [128,256,512,1024]],  marker='+', markersize=15, linewidth=2.5)\n",
    "\n",
    "plt.title(\"Milestone 3\")\n",
    "plt.xlabel(\"Training batch size\")\n",
    "plt.ylabel(\"Hours per 100 epochs\")\n",
    "plt.legend([\"steps=5, bs=256\",\"steps=10, bs=256\",\"steps=15, bs=256\", \"steps=5, bs=128\",\"steps=10, bs=128\",\"steps=15, bs=128\"], title=\"βeff steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4073c-f2e7-4b71-bc77-c33807e4e992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[1] for i in [128,256,512,1024]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[1] for i in [128,256,512,1024]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 256)[1] for i in [128,256,512,1024]],  marker='+', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[1] for i in [128,256,512,1024]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[1] for i in [128,256,512,1024]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([128,256,512,1024], [_gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=1024, train_bs=i, temp_opt_samp_size = 128)[1] for i in [128,256,512,1024]],  marker='+', markersize=15, linewidth=2.5)\n",
    "\n",
    "plt.title(\"Milestone 2\")\n",
    "plt.xlabel(\"Training batch size\")\n",
    "plt.ylabel(\"Minutes per epoch\")\n",
    "plt.legend([\"steps=5, bs=256\",\"steps=10, bs=256\",\"steps=15, bs=256\", \"steps=5, bs=128\",\"steps=10, bs=128\",\"steps=15, bs=128\"], title=\"βeff steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eb90f5-1652-4875-8ff2-ba1271dc5038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ae3491-fb6a-49cb-9566-d20800ab0d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 256)[0] for i in [1024,2048]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 256)[0] for i in [1024,2048]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 256)[0] for i in [1024,2048]],  marker='+', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 128)[0] for i in [1024,2048]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 128)[0] for i in [1024,2048]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 128)[0] for i in [1024,2048]],  marker='+', markersize=15, linewidth=2.5)\n",
    "\n",
    "plt.title(\"Milestone 1\")\n",
    "plt.xlabel(\"Validation batch size\")\n",
    "plt.ylabel(\"Minutes per 100-epochs\")\n",
    "plt.legend([\"steps=5, bs=256\",\"steps=10, bs=256\",\"steps=15, bs=256\", \"steps=5, bs=128\",\"steps=10, bs=128\",\"steps=15, bs=128\"], title=\"βeff steps\")\n",
    "# plt.legend([\"steps=10, bs=256\",\"steps=15, bs=256\", \"steps=10, bs=128\",\"steps=15, bs=128\"], title=\"βeff steps\")\n",
    "plt.grid(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6add3d14-331e-4c98-a160-95d639799065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 256)[4] for i in [1024,2048]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 256)[4] for i in [1024,2048]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 256)[4] for i in [1024,2048]],  marker='+', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 128)[4] for i in [1024,2048]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 128)[4] for i in [1024,2048]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [10/6.0 * _gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 128)[4] for i in [1024,2048]],  marker='+', markersize=15, linewidth=2.5)\n",
    "\n",
    "plt.title(\"Milestone 1\")\n",
    "plt.xlabel(\"Validation batch size\")\n",
    "plt.ylabel(\"Minutes per 100-epochs\")\n",
    "plt.legend([\"steps=5, bs=256\",\"steps=10, bs=256\",\"steps=15, bs=256\", \"steps=5, bs=128\",\"steps=10, bs=128\",\"steps=15, bs=128\"], title=\"βeff steps\")\n",
    "# plt.legend([\"steps=10, bs=256\",\"steps=15, bs=256\", \"steps=10, bs=128\",\"steps=15, bs=128\"], title=\"βeff steps\")\n",
    "plt.grid(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4112bb13-2ff3-4cad-aac7-d6cdec2c5f77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot([1024,2048], [_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 256)[4] for i in [1024,2048]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 256)[4] for i in [1024,2048]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [_gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 256)[4] for i in [1024,2048]],  marker='+', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [_gpu_timing(temp_steps=5, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 128)[4] for i in [1024,2048]],  marker='.', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [_gpu_timing(temp_steps=10, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 128)[4] for i in [1024,2048]],  marker='o', markersize=15, linewidth=2.5)\n",
    "plt.plot([1024,2048], [_gpu_timing(temp_steps=15, training_size=80000, val_size=10000, val_bs=i, train_bs=256, temp_opt_samp_size = 128)[4] for i in [1024,2048]],  marker='+', markersize=15, linewidth=2.5)\n",
    "\n",
    "plt.title(\"Milestone 1\")\n",
    "plt.xlabel(\"Validation batch size\")\n",
    "plt.ylabel(\"Seconds per epochs\")\n",
    "plt.legend([\"steps=5, bs=256\",\"steps=10, bs=256\",\"steps=15, bs=256\", \"steps=5, bs=128\",\"steps=10, bs=128\",\"steps=15, bs=128\"], title=\"βeff steps\")\n",
    "# plt.legend([\"steps=10, bs=256\",\"steps=15, bs=256\", \"steps=10, bs=128\",\"steps=15, bs=128\"], title=\"βeff steps\")\n",
    "plt.grid(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b1c46-6b18-4bfc-9830-356a5ebcc269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def float32_to_binary(num):\n",
    "    # Check if the number is negative\n",
    "    # if num < 0:\n",
    "        # raise ValueError(\"Number must be positive\")\n",
    "\n",
    "    # Convert the float number to 32-bit binary format\n",
    "    packed = struct.pack('f', num)\n",
    "    \n",
    "    # Convert the bytes to an integer\n",
    "    i = int.from_bytes(packed, byteorder='little', signed=False)\n",
    "    \n",
    "    # Format the integer to its binary representation and pad with zeros to 32 bits\n",
    "    return format(i, '032b')\n",
    "\n",
    "# Example usage\n",
    "num = 123.456\n",
    "binary_representation = float32_to_binary(num)\n",
    "print(\"Binary representation of\", num, \":\", binary_representation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d4359-ab77-4232-b458-24c338ddfdc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num = -0.456\n",
    "binary_representation = float32_to_binary(num)\n",
    "print(\"Binary representation of\", num, \":\", binary_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60226d69-df40-4d51-87e9-25bf656c0bed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### QPU ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db30ef13-6104-4a65-94c4-ac1871a97b04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beta_KL, beta_list_KL, rbm_energy_list_KL, dwave_energies_list_KL = engine.model.find_beta(7.0, 0.01, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041124ec-bbfc-4d21-8362-3f3dd0147813",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(beta_list_KL, linewidth=2.5, color=\"b\" )\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"β QA\")\n",
    "plt.legend([f'Chip {engine.model._qpu_sampler.properties[\"chip_id\"]}'])\n",
    "# plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/beta_QA_{engine.model._qpu_sampler.properties[\"chip_id\"]}_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca5a08b-6fee-454f-922d-1be7a5478fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 1:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a90c7-395e-4001-a502-0c163bb54e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beta_Hao, beta_list_Hao, rbm_energy_list_Hao, dwave_energies_list_Hao = engine.model.find_beta(4.0, 0.01, 20, 10.0, 'Hao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4076ce2-4fa3-483c-b265-4173f298df3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(beta_list_Hao, linewidth=2.5, color=\"b\" )\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"β QA\")\n",
    "plt.legend([f'Chip {engine.model._qpu_sampler.properties[\"chip_id\"]}'])\n",
    "# plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/beta_QA_{engine.model._qpu_sampler.properties[\"chip_id\"]}_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d3f64-df35-45a0-add1-50f27e84a4a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.plot(beta_list_Hao, linewidth=2.5, color=\"b\" )\n",
    "p0_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f861eb7f-e4e7-43d2-8219-584806b8802a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beta_init = 1.8\n",
    "# lr = 0.01\n",
    "num_epochs = 20\n",
    "Δbeta = 0.2\n",
    "beta = beta_init\n",
    "beta_list = []\n",
    "rbm_energy_list = []\n",
    "dwave_energies_list = []\n",
    "mean_rbm_energy_list = []\n",
    "mean_dwave_energy_list = []\n",
    "var_rbm_energy_list = []\n",
    "var_dwave_energy_list = []\n",
    "training_results = {}\n",
    "\n",
    "for epoch in range(num_epochs+1):\n",
    "    _,_,_,_, dwave_weights_rbm, dwave_bias_rbm = engine.model.ising_model(1.0)\n",
    "    # _,_,_,_, dwave_weights_rbm, dwave_bias_rbm = engine.model.ising_model(1.0)\n",
    "    h, J, qubit_idxs, idx_dict, dwave_weights, dwave_bias = engine.model.ising_model(1.0 / beta)\n",
    "    # if epoch == 0:\n",
    "    # prbm_sampler = PGBS(self.prior, 512, 3000)\n",
    "    p0_state, p1_state, p2_state, p3_state = engine.model.sampler.block_gibbs_sampling()\n",
    "    p0_ising = p0_state * 2 - 1\n",
    "    p1_ising = p1_state * 2 - 1\n",
    "    p2_ising = p2_state * 2 - 1\n",
    "    p3_ising = p3_state * 2 - 1\n",
    "    rbm_energies = engine.model.ising_energy(p0_ising, p1_ising, p2_ising, p3_ising, dwave_weights_rbm, dwave_bias_rbm)\n",
    "    rbm_energies = rbm_energies.detach().cpu().numpy()\n",
    "\n",
    "    response = engine.model._qpu_sampler.sample_ising(h, J, num_reads=256, auto_scale=False)\n",
    "    dwave_samples, dwave_energies, origSamples = engine.model.batch_dwave_samples(response, qubit_idxs)\n",
    "    # dwave_samples, dwave_energies = self.batch_dwave_samples(response, qubit_idxs)\n",
    "    nonpl = len(idx_dict['0'])\n",
    "    dwave_1, dwave_2, dwave_3, dwave_4 = dwave_samples[:,0:nonpl], dwave_samples[:,nonpl:2*nonpl], dwave_samples[:,2*nonpl:3*nonpl], dwave_samples[:,3*nonpl:4*nonpl]\n",
    "    dwave_1_t = torch.tensor(dwave_1).to(p0_ising.device).float()\n",
    "    dwave_2_t = torch.tensor(dwave_2).to(p0_ising.device).float()\n",
    "    dwave_3_t = torch.tensor(dwave_3).to(p0_ising.device).float()\n",
    "    dwave_4_t = torch.tensor(dwave_4).to(p0_ising.device).float()\n",
    "    dwave_energies = engine.model.ising_energy(dwave_1_t, dwave_2_t, dwave_3_t, dwave_4_t, dwave_weights_rbm, dwave_bias_rbm)\n",
    "    dwave_energies = dwave_energies.detach().cpu().numpy()\n",
    "    mean_rbm_energy = np.mean(rbm_energies)\n",
    "    mean_dwave_energy = np.mean(dwave_energies)\n",
    "    var_rbm_energy = np.var(rbm_energies)\n",
    "    var_dwave_energy = np.var(dwave_energies)\n",
    "\n",
    "    rbm_energy_list.append(rbm_energies)\n",
    "    dwave_energies_list.append(dwave_energies)\n",
    "    mean_rbm_energy_list.append(mean_rbm_energy)\n",
    "    mean_dwave_energy_list.append(mean_dwave_energy)\n",
    "    var_rbm_energy_list.append(var_rbm_energy)\n",
    "    var_dwave_energy_list.append(var_dwave_energy)\n",
    "    beta_list.append(beta)\n",
    "    print (f'Epoch {epoch}: beta = {beta}, DW/RBM = {mean_dwave_energy/mean_rbm_energy}')\n",
    "    beta = beta + Δbeta #lr * (mean_dwave_energy - mean_rbm_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e94b9-9c68-4508-a35a-99e6b397acb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.plot( rbmrbm_energy_list\n",
    "plt.plot( beta_list , np.array(mean_dwave_energy_list) / np.array(mean_rbm_energy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6790ca8-2502-411e-84aa-9a0698d5c95c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "\n",
    "plt.plot(beta_list, 1 + np.array([np.var(dwave_energies_list[i]) for i in range(len(dwave_energies_list))])/mean_rbm_energy_list, marker='o', markersize=15, linewidth=2.5, c='blue' )\n",
    "plt.plot(beta_list, 1 + 2 * np.array([np.var(dwave_energies_list[i]) for i in range(len(dwave_energies_list))])/mean_dwave_energy_list, marker='.', markersize=15, linewidth=2.5, c='orange' )\n",
    "plt.plot(beta_list, 1 + 10 * np.array([np.var(dwave_energies_list[i]) for i in range(len(dwave_energies_list))])/mean_dwave_energy_list, marker='+', markersize=15, linewidth=2.5, c='red')\n",
    "plt.legend([\"1\",\"2\",\"5\"], title=\"δ\", fontsize=15)\n",
    "plt.xlabel(\"β\", fontsize=15)\n",
    "# plt.axvspan(9, 9.5, color='purple', alpha=0.3)\n",
    "# label_x = (18.5) / 2\n",
    "# label_y = 0.2  # For example, 80% of the way up the y-axis\n",
    "# plt.text(label_x, label_y, 'Fixed point', horizontalalignment='center', verticalalignment='center', rotation=90, fontsize=15)\n",
    "\n",
    "# plt.ylabel(\"δ σ**2/<H>\")\n",
    "plt.ylabel(\"f(βQA)\", fontsize=18)\n",
    "plt.grid(\"True\")\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/stability_analysis_meth2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a55d95-a992-4aad-861b-3476d73958b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(beta_list, beta_list)\n",
    "plt.plot(beta_list, beta_list * np.array(mean_dwave_energy_list)/np.array(mean_rbm_energy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3b07fe-dfac-4fda-9476-00374d26313c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax1 = plt.subplots() \n",
    "# fig.figure(figsize=(7,5), dpi=100)\n",
    "ax1.plot(beta_list, np.abs(1 + np.array([np.var(dwave_energies_list[i]) for i in range(len(dwave_energies_list))])/mean_rbm_energy_list), marker='o', markersize=15, linewidth=2.5, c='blue' )\n",
    "ax1.plot(beta_list, np.abs(1 + 2 * np.array([np.var(dwave_energies_list[i]) for i in range(len(dwave_energies_list))])/mean_dwave_energy_list), marker='.', markersize=15, linewidth=2.5, c='orange' )\n",
    "ax1.plot(beta_list, np.abs(1 + 4 * np.array([np.var(dwave_energies_list[i]) for i in range(len(dwave_energies_list))])/mean_dwave_energy_list), marker='^', markersize=15, linewidth=2.5, c='red')\n",
    "ax1.legend([\"1\",\"2\",\"4\"], title=\"δ\", fontsize=15)\n",
    "ax1.set_xlabel(\"β\", fontsize=15)\n",
    "ax1.set_ylabel(\"λ(δ)\", fontsize=18)\n",
    "ax1.grid(\"True\")\n",
    "# ax1.axhline([1], color='black', linestyle='dashed', linewidth=1)\n",
    "ax1.axhspan(0, 1, facecolor='b', alpha=0.1)\n",
    "\n",
    "# # Adding Twin Axes to plot using dataset_2\n",
    "ax2 = ax1.twinx() \n",
    "\n",
    "color = 'm' #'tab:green'\n",
    "# ax2.set_ylabel('Y2-axis', color = color) \n",
    "# ax2.plot(x, dataset_2, color = color) \n",
    "ax2.plot( beta_list , np.array(mean_dwave_energy_list) / np.array(mean_rbm_energy_list), marker='p', markersize=7, linewidth=1.5, color = color)\n",
    "ax2.tick_params(axis ='y', labelcolor = color) \n",
    "ax2.set_ylabel(\"Ratio between QA and Classical Avg Energy\", fontsize=10, color = color)\n",
    "# ax2.set_yticks([1, 0.92])\n",
    "# ax2.grid(\"True\", color='black', linestyle='dashed', linewidth=1)\n",
    "ax2.axhline([1], color='black', linestyle='dashed', linewidth=1)\n",
    "plt.subplots_adjust(left=0.1, right=0.8, bottom=0.1, top=0.9)\n",
    "\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/stability_analysis_meth2.png')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b100fe0-3ba6-46c4-8281-5a798480d3df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.scatter(np.array([[1,2],[3,4]]).reshape(-1), np.array([[1,2],[3,4]]).reshape(-1))\n",
    "\n",
    "CM1 = torch.rand(1000).numpy()\n",
    "CMsn = torch.rand(1000).numpy()\n",
    "\n",
    "np.sqrt(np.power(CM1 - CMsn, 2).sum()/np.power(CM1, 2).sum())\n",
    "hlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f47c60d-9c8f-418f-8630-baf988798e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede5526-4a50-4c81-90fa-c273148a5512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(entarget_samples/1000, (xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1])\n",
    "plt.xlabel(\"incidence energy\")\n",
    "plt.ylabel(\"sparsity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c72414-d7ce-416d-b3ad-212c57a4b033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(entarget_samples.divide(1000).multiply(-0.004).exp(), (xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1])\n",
    "plt.xlabel(\"f(incidence energy)\")\n",
    "plt.ylabel(\"sparsity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee9f3f4-134b-4d7a-b074-67ab60f7b12d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Synth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad7e0f9-5453-48ba-a141-314e47b29a51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "# import torch\n",
    "\n",
    "# Replace 'your_file.h5' with the path to your HDF5 file\n",
    "file_path = '/raid/javier/Datasets/CaloVAE/data/atlas_dataset2and3/dataset_2_2.hdf5'\n",
    "data_dict = {}\n",
    "# Open the HDF5 file\n",
    "with h5py.File(file_path, 'r') as file:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % file.keys())\n",
    "    for key in file.keys():\n",
    "        data_dict[key] = torch.tensor(file[key][:])\n",
    "        \n",
    "        \n",
    "file_path = '/raid/javier/Datasets/CaloVAE/data/atlas_dataset2and3/dataset_2_1.hdf5'\n",
    "data_dict_tr = {}\n",
    "# Open the HDF5 file\n",
    "with h5py.File(file_path, 'r') as file:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % file.keys())\n",
    "    for key in file.keys():\n",
    "        data_dict_tr[key] = torch.tensor(file[key][:])\n",
    "        \n",
    "\n",
    "\n",
    "file_path = '/raid/javier/Datasets/CaloVAE/data/synData/dataset2_synthetic_honest-hill-454.hdf5'\n",
    "data_dict_syn = {}\n",
    "# Open the HDF5 file\n",
    "with h5py.File(file_path, 'r') as file:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % file.keys())\n",
    "    for key in file.keys():\n",
    "        data_dict_syn[key] = torch.tensor(file[key][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d51c252-fb10-48b1-8975-47ff7fcda769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xtarget_samples = data_dict['showers']\n",
    "xrecon_samples = data_dict_tr['showers']\n",
    "xgen_samples = data_dict_syn['showers']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee3fb7e-2580-4474-a35b-052f9a9dc0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HLF_1_electron.relevantLayers = [0,5,10,15,20,25,30,35,40,45]\n",
    "plt.figure(figsize=(8,6))\n",
    "# Create a grid of subplots\n",
    "fig, axes = plt.subplots(3,3, figsize=(12, 12), sharey=True, sharex=False, tight_layout=True)\n",
    "fig.text(0.5, 0.0, 'Energy per event (GeV)', ha='center', fontsize=15)\n",
    "fig.text(0.0, 0.5, 'Histogram', va='center', rotation='vertical', fontsize=15)\n",
    "\n",
    "# Iterate through the columns of X and plot histograms\n",
    "for i,_ in enumerate(HLF_1_electron.relevantLayers[:-1]):\n",
    "    row_index = i // 3  # Determine the row index\n",
    "    col_index = i % 3   # Determine the column index\n",
    "    \n",
    "    ax = axes[row_index, col_index]  # Get the current subplot\n",
    "    \n",
    "    # Plot histogram for the current column\n",
    "    idx = HLF_1_electron.relevantLayers[i+1]*9*16\n",
    "    idxPrev = (HLF_1_electron.relevantLayers[i])*9*16\n",
    "    l = idx - idxPrev\n",
    "    minVal, maxVal = min(xtarget_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000), max(xtarget_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000)\n",
    "    binwidth = (maxVal-minVal)/50\n",
    "    ax.hist(xtarget_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000,  bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7)\n",
    "    ax.hist(xrecon_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"c\")\n",
    "    # ax.hist(xrecon_samples_2[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=20, log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "    ax.hist(xgen_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashdot\")\n",
    "    # ax.hist(xgen_samples_qpu[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashed\")\n",
    "    if i == 0:\n",
    "        # ax.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], title=f'{ds[part]}')\n",
    "        ax.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], fontsize=15)\n",
    "    ax.grid(\"True\")\n",
    "    \n",
    "    # Set labels and title for the subplot\n",
    "    # ax.set_xlabel(f'Column {i + 1}')\n",
    "    # ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Layers {HLF_1_electron.relevantLayers[i]} to {HLF_1_electron.relevantLayers[i+1]-1}')\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_per_layer_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411251ba-57e5-4c23-b6ee-3ead4e4fcbe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e14ea80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=5\n",
      "env: DWAVE_API_TOKEN=DEV-1ba72787de429d2af12464f7753c10b9ff6945ad\n",
      "Mon Mar 18 09:39:58 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 30%   34C    P8               6W / 250W |      5MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 30%   33C    P8              17W / 250W |      5MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 30%   31C    P8              21W / 250W |   9697MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 30%   34C    P8               1W / 250W |   7155MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 30%   31C    P8               4W / 250W |   7327MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 30%   35C    P8              21W / 250W |      5MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:B1:00.0 Off |                  N/A |\n",
      "| 30%   33C    P8               3W / 250W |      5MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:B2:00.0 Off |                  N/A |\n",
      "| 22%   33C    P8              22W / 250W |      5MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    2   N/A  N/A   1946073      C   /usr/bin/python                            9692MiB |\n",
      "|    3   N/A  N/A   4178676      C   /bin/python                                7150MiB |\n",
      "|    4   N/A  N/A   2778684      C   /usr/bin/python                            7322MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=5\n",
    "%env DWAVE_API_TOKEN=DEV-1ba72787de429d2af12464f7753c10b9ff6945ad\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "330d503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from hydra.utils import instantiate\n",
    "from hydra import initialize, compose\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "os.chdir('/home/' + getpass.getuser() + '/CaloQVAE/')\n",
    "sys.path.insert(1, '/home/' + getpass.getuser() + '/CaloQVAE/')\n",
    "\n",
    "#external libraries\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits\n",
    "torch.manual_seed(32)\n",
    "import numpy as np\n",
    "np.random.seed(32)\n",
    "import matplotlib.pyplot as plt\n",
    "import hydra\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# PyTorch imports\n",
    "from torch import device, load, save\n",
    "from torch.nn import DataParallel\n",
    "from torch.cuda import is_available\n",
    "\n",
    "# Add the path to the parent directory to augment search for module\n",
    "sys.path.append(os.getcwd())\n",
    "    \n",
    "# Weights and Biases\n",
    "import wandb\n",
    "\n",
    "#self defined imports\n",
    "from CaloQVAE import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0ee8ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from data.dataManager import DataManager\n",
    "from utils.plotting.plotProvider import PlotProvider\n",
    "from engine.engine import Engine\n",
    "from models.modelCreator import ModelCreator\n",
    "\n",
    "from utils.plotting.HighLevelFeatures import HighLevelFeatures as HLF\n",
    "HLF_1_photons = HLF('photon', filename='/fast_scratch/QVAE/data/atlas/binning_dataset_1_photons.xml', wandb=False)\n",
    "HLF_1_pions = HLF('pion', filename='/fast_scratch/QVAE/data/atlas/binning_dataset_1_pions.xml', wandb=False)\n",
    "HLF_1_electron = HLF('electron', filename='/fast_scratch/QVAE/data/atlas_dataset2and3/binning_dataset_2.xml', wandb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efdd7309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(version_base=None, config_path=\"configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ee20c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config.yaml': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "\u001b[1m[09:40:04.517]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0mLoading Data\n",
      "\u001b[1m[09:40:20.460]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f003c6d0580>: 80000 events, 625 batches\n",
      "\u001b[1m[09:40:20.461]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7effec6f8d30>: 10000 events, 10 batches\n",
      "\u001b[1m[09:40:20.462]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7effec6f8ee0>: 10000 events, 79 batches\n",
      "\u001b[1m[09:40:25.784]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mmodels.modelCreator                               \u001b[0mInitialising Model Type GumBoltAtlasPRBMCNN\n",
      "2024-03-18 09:40:25,791 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Using region metadata: [Region(code='na-west-1', name='North America', endpoint='https://na-west-1.cloud.dwavesys.com/sapi/v2/'), Region(code='eu-central-1', name='Europe', endpoint='https://eu-central-1.cloud.dwavesys.com/sapi/v2/')]\n",
      "\u001b[1m[09:40:25.791]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mUsing region metadata: [Region(code='na-west-1', name='North America', endpoint='https://na-west-1.cloud.dwavesys.com/sapi/v2/'), Region(code='eu-central-1', name='Europe', endpoint='https://eu-central-1.cloud.dwavesys.com/sapi/v2/')]\n",
      "2024-03-18 09:40:26,863 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Fetching definitions of all available solvers\n",
      "\u001b[1m[09:40:26.863]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mFetching definitions of all available solvers\n",
      "2024-03-18 09:40:28,403 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Received solver data for 7 solver(s).\n",
      "\u001b[1m[09:40:28.403]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mReceived solver data for 7 solver(s).\n",
      "2024-03-18 09:40:28,455 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage_system4.1')\n",
      "\u001b[1m[09:40:28.455]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage_system4.1')\n",
      "2024-03-18 09:40:28,465 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage2_prototype1.1')\n",
      "\u001b[1m[09:40:28.465]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage2_prototype1.1')\n",
      "2024-03-18 09:40:28,479 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage2_prototype2.2')\n",
      "\u001b[1m[09:40:28.479]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage2_prototype2.2')\n",
      "2024-03-18 09:40:28,530 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage_system6.4')\n",
      "\u001b[1m[09:40:28.530]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage_system6.4')\n",
      "2024-03-18 09:40:29,128 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Using region metadata: [Region(code='na-west-1', name='North America', endpoint='https://na-west-1.cloud.dwavesys.com/sapi/v2/'), Region(code='eu-central-1', name='Europe', endpoint='https://eu-central-1.cloud.dwavesys.com/sapi/v2/')]\n",
      "\u001b[1m[09:40:29.128]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mUsing region metadata: [Region(code='na-west-1', name='North America', endpoint='https://na-west-1.cloud.dwavesys.com/sapi/v2/'), Region(code='eu-central-1', name='Europe', endpoint='https://eu-central-1.cloud.dwavesys.com/sapi/v2/')]\n",
      "2024-03-18 09:40:30,210 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Fetching definitions of all available solvers\n",
      "\u001b[1m[09:40:30.210]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mFetching definitions of all available solvers\n",
      "2024-03-18 09:40:32,015 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Received solver data for 7 solver(s).\n",
      "\u001b[1m[09:40:32.015]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mReceived solver data for 7 solver(s).\n",
      "2024-03-18 09:40:32,082 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage_system4.1')\n",
      "\u001b[1m[09:40:32.082]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage_system4.1')\n",
      "2024-03-18 09:40:32,097 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage2_prototype1.1')\n",
      "\u001b[1m[09:40:32.097]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage2_prototype1.1')\n",
      "2024-03-18 09:40:32,110 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage2_prototype2.2')\n",
      "\u001b[1m[09:40:32.110]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage2_prototype2.2')\n",
      "2024-03-18 09:40:32,191 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage_system6.4')\n",
      "\u001b[1m[09:40:32.191]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage_system6.4')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing NetworkV3\n"
     ]
    }
   ],
   "source": [
    "# config=compose(config_name=\"config.yaml\")\n",
    "config=compose(config_name=\"config.yaml\")\n",
    "wandb.init(project=\"caloqvae\", entity=\"qvae\", config=config, mode='disabled')\n",
    "modelCreator = ModelCreator(cfg=config)\n",
    "dataMgr = DataManager(cfg=config)\n",
    "#initialise data loaders\n",
    "dataMgr.init_dataLoaders()\n",
    "#run pre processing: get/set input dimensions and mean of train dataset\n",
    "dataMgr.pre_processing()\n",
    "\n",
    "if config.model.activation_fct.lower()==\"relu\":\n",
    "    modelCreator.default_activation_fct=torch.nn.ReLU()\n",
    "elif config.model.activation_fct.lower()==\"tanh\":\n",
    "    modelCreator.default_activation_fct=torch.nn.Tanh()\n",
    "else:\n",
    "    logger.warning(\"Setting identity as default activation fct\")\n",
    "    modelCreator.default_activation_fct=torch.nn.Identity()\n",
    "\n",
    "#instantiate the chosen model\n",
    "#loads from file \n",
    "model=modelCreator.init_model(dataMgr=dataMgr)\n",
    "\n",
    "#create the NN infrastructure\n",
    "model.create_networks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d7e5479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[09:40:34.176]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mwandb                                             \u001b[0mWatching\n",
      "\u001b[1m[09:40:34.184]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engineAtlas                                \u001b[0mSetting up engine Atlas.\n",
      "\u001b[1m[09:40:34.185]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engineCaloV3                               \u001b[0mSetting up engine Calo.\n",
      "\u001b[1m[09:40:34.186]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engine                                     \u001b[0mSetting up default engine.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dev = torch.device(\"cuda:0\")\n",
    "wandb.watch(model)\n",
    "engine=instantiate(config.engine, config)\n",
    "engine._config=config\n",
    "#add dataMgr instance to engine namespace\n",
    "engine.data_mgr=dataMgr\n",
    "#add device instance to engine namespace\n",
    "engine.device=dev    \n",
    "#instantiate and register optimisation algorithm\n",
    "engine.optimiser = torch.optim.Adam(model.parameters(),\n",
    "                                    lr=config.engine.learning_rate)\n",
    "#add the model instance to the engine namespace\n",
    "engine.model = model\n",
    "# add the modelCreator instance to engine namespace\n",
    "engine.model_creator = modelCreator\n",
    "engine.model = engine.model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dff39075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[09:40:44.667]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f01cddb0550>: 80000 events, 625 batches\n",
      "\u001b[1m[09:40:44.668]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f01cdd61880>: 10000 events, 10 batches\n",
      "\u001b[1m[09:40:44.669]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f01cabd38b0>: 10000 events, 79 batches\n"
     ]
    }
   ],
   "source": [
    "train_loader,test_loader,val_loader = engine.data_mgr.create_dataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "887b7988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state(model, run_path, device):\n",
    "        model_loc = run_path\n",
    "        \n",
    "        # Open a file in read-binary mode\n",
    "        with open(model_loc, 'rb') as f:\n",
    "            # Interpret the file using torch.load()\n",
    "            checkpoint=torch.load(f, map_location=device)\n",
    "            \n",
    "            local_module_keys=list(model._modules.keys())\n",
    "            for module in checkpoint.keys():\n",
    "                if module in local_module_keys:\n",
    "                    print(\"Loading weights for module = \", module)\n",
    "                    getattr(model, module).load_state_dict(checkpoint[module])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7cbe390f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GumBoltAtlasPRBMCNN\n",
      "electron-ds2\n",
      "Loading weights for module =  _activation_fct\n",
      "Loading weights for module =  _bce_loss\n",
      "Loading weights for module =  _energy_activation_fct\n",
      "Loading weights for module =  _hit_activation_fct\n",
      "Loading weights for module =  _output_loss\n",
      "Loading weights for module =  _hit_loss\n",
      "Loading weights for module =  _hit_smoothing_dist_mod\n",
      "Loading weights for module =  _inference_energy_activation_fct\n",
      "Loading weights for module =  encoder\n",
      "Loading weights for module =  prior\n",
      "Loading weights for module =  decoder\n"
     ]
    }
   ],
   "source": [
    "# winter-snowflake-24: GumBoltAtlasPRBMCNN\n",
    "# run_path = \"/fast_scratch/sgonzalez/wandb/run-20240228_120832-q78nzust/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "\n",
    "run_path = \"/fast_scratch/sgonzalez/wandb/run-20240313_155921-4q9i8pnt/files/GumBoltAtlasPRBMCNN_atlas_default_best.pth\"\n",
    "modelname = 'macabre-candle-1372'\n",
    "datascaled = 'scaled'\n",
    "with open(\"/fast_scratch/sgonzalez/wandb/run-20240313_155921-4q9i8pnt/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    #R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    #reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "\n",
    "\n",
    "\n",
    "arch = config['model']['model_type']\n",
    "part = config['data']['particle_type']\n",
    "print(arch)\n",
    "print(part)\n",
    "\n",
    "\n",
    "# load_state(model, run_path, 'cuda:{0}'.format(cfg.gpu_list[0]))\n",
    "load_state(model, run_path, dev)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f2e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtarget_samples = []\n",
    "xrecon_samples = []\n",
    "xgen_samples = []\n",
    "scaled = True\n",
    "entarget_samples = []\n",
    "\n",
    "def itr_merge(*itrs):\n",
    "    for itr in itrs:\n",
    "        for v in itr:\n",
    "            yield v\n",
    "            \n",
    "for xx in train_loader:\n",
    "    in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "    \n",
    "    fwd_output = engine.model((in_data, true_energy), False)\n",
    "    \n",
    "    if scaled:\n",
    "        in_data = torch.tensor(engine._data_mgr.inv_transform(in_data.detach().cpu().numpy()))\n",
    "        \n",
    "        \n",
    "        recon_data = torch.tensor(engine._data_mgr.inv_transform(fwd_output.output_activations.detach().cpu().numpy()))\n",
    "        \n",
    "        ## This is how youi generate data using model\n",
    "        # ================================\n",
    "        engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "        sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy) #engine._model.generate_samples_qpu(num_samples=128, true_energy=true_energy[:128])\n",
    "        engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "        sample_data = torch.tensor(engine._data_mgr.inv_transform(sample_data.detach().cpu().numpy()))\n",
    "        # ================================\n",
    "    \n",
    "    else:\n",
    "        raise Exception(\"Script only supports scaled dataset at the moment...\")\n",
    "\n",
    "\n",
    "    xtarget_samples.append(in_data.detach().cpu())\n",
    "    xrecon_samples.append( recon_data.detach().cpu())\n",
    "    xgen_samples.append( sample_data.detach().cpu())\n",
    "    entarget_samples.append(true_energy.detach().cpu())\n",
    "    \n",
    "    \n",
    "xtarget_samples = torch.cat(xtarget_samples, dim=0)\n",
    "xrecon_samples = torch.cat(xrecon_samples, dim=0)\n",
    "xgen_samples = torch.cat(xgen_samples, dim=0)\n",
    "entarget_samples = torch.cat(entarget_samples, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a44d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfont = {'fontname':'Helvetica'}\n",
    "ds = {'electron-ds2':'Dataset 2', 'pion1':'Dataset 1: Ï€'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6ccd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=20, log=True, histtype='step', linewidth=2.5, color=\"b\")\n",
    "plt.hist(((xrecon_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=20, log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "plt.hist(((xgen_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=20, log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashed\")\n",
    "\n",
    "plt.xlabel(\"Sparsity Index\")\n",
    "plt.ylabel(\"Histogram\")\n",
    "plt.legend([\"GT\", \"Recon\", \"Samples\", \"Sample /w QPU\"])\n",
    "plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8def98",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLF_1_electron.relevantLayers = [0,5,10,15,20,25,30,35,40,45]\n",
    "# Create a grid of subplots\n",
    "fig, axes = plt.subplots(3,3, figsize=(12, 12), sharey=True, sharex=True, tight_layout=True)\n",
    "fig.text(0.5, 0.0, 'Sparsity Index', ha='center')\n",
    "fig.text(0.0, 0.5, 'Histogram', va='center', rotation='vertical')\n",
    "\n",
    "# Iterate through the columns of X and plot histograms\n",
    "for i,_ in enumerate(HLF_1_electron.relevantLayers[:-1]):\n",
    "    row_index = i // 3  # Determine the row index\n",
    "    col_index = i % 3   # Determine the column index\n",
    "    \n",
    "    ax = axes[row_index, col_index]  # Get the current subplot\n",
    "    \n",
    "    # Plot histogram for the current column\n",
    "    idx = HLF_1_electron.relevantLayers[i+1]*9*16\n",
    "    idxPrev = (HLF_1_electron.relevantLayers[i])*9*16\n",
    "    l = idx - idxPrev\n",
    "    ax.hist(((xtarget_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy(),  bins=20, log=True, histtype='step', linewidth=2.5, color=\"b\")\n",
    "    ax.hist(((xrecon_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy(), bins=20, log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "    ax.hist(((xgen_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy(), bins=20, log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashed\")\n",
    "    \n",
    "    ax.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], title=f'{ds[part]}')\n",
    "    ax.grid(\"True\")\n",
    "    \n",
    "    ax.set_title(f'Layers {HLF_1_electron.relevantLayers[i]} to {HLF_1_electron.relevantLayers[i+1]-1}')\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c394a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(entarget_samples, ((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy())\n",
    "plt.scatter(entarget_samples, ((xrecon_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy())\n",
    "\n",
    "plt.xlabel(\"Incidence Energy (GeV)\")\n",
    "plt.ylabel(\"Sparsity\")\n",
    "plt.legend([\"GT\", \"Recon\", \"Samples\", \"Sample /w QPU\"])\n",
    "plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a0b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,2, figsize=(8,8), tight_layout=True)\n",
    "fig.text(0.5, 0.0, 'GT energy per event (GeV)', ha='center')\n",
    "fig.text(0.5, 1.0, f'{ds[part]}', ha='center', fontsize=12)\n",
    "\n",
    "axes[0,0].scatter(xtarget_samples.sum(dim=1).numpy()/1000, xrecon_samples.sum(dim=1).numpy()/1000, marker='.', alpha=.5, color=\"b\")\n",
    "axes[0,0].plot([0,800],[0,800], c='red', lw=2.5, label='y=x')\n",
    "axes[0,0].set_ylabel(\"Recon energy per event (GeV)\")\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(\"True\")\n",
    "axes[0,0].set_yscale('log')\n",
    "axes[0,0].set_xscale('log')\n",
    "\n",
    "axes[0,1].scatter(xtarget_samples.sum(dim=1).numpy()/1000, (xtarget_samples.sum(dim=1).numpy() - xrecon_samples.sum(dim=1).numpy())/1000, marker='.', alpha=.5, color=\"b\")\n",
    "axes[0,1].set_ylabel(\"Abs error (GeV)\")\n",
    "axes[0,1].set_ylim([-40,40])\n",
    "# axes[0,1].legend()\n",
    "# axes[0,1].set_yscale('log')\n",
    "axes[0,1].grid(\"True\")\n",
    "\n",
    "axes[1,0].scatter(1/(entarget_samples.numpy()/1000), np.abs(entarget_samples.reshape(-1).numpy() - xtarget_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.5, color=\"blue\", label=\"Simulation\")\n",
    "axes[1,0].scatter(1/(entarget_samples.numpy()/1000), np.abs(entarget_samples.reshape(-1).numpy() - xrecon_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.05, color=\"red\", label=\"Model\")\n",
    "axes[1,0].plot([1e-3,1e0],np.power([1e-3,1e0],0.25)*np.power(10,2.0), c='orange', lw=2.5, label='slope=0.25', linestyle=\"dashdot\")\n",
    "axes[1,0].grid(\"True\")\n",
    "axes[1,0].set_yscale('log')\n",
    "axes[1,0].set_xscale('log')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].set_ylabel(\"Relative Error\")\n",
    "\n",
    "axes[1,1].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy()/1000 - xtarget_samples.sum(dim=1).numpy()/1000), marker='.', alpha=1, color=\"blue\", label=\"Simulation\")\n",
    "axes[1,1].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy()/1000 - xrecon_samples.sum(dim=1).numpy()/1000), marker='.', alpha=.2, color=\"red\", label=\"Model\")\n",
    "axes[1,1].plot([1,800],np.sqrt([1,800]), c='orange', lw=2.5, label='y=sqrt(x)', linestyle=\"dashdot\")\n",
    "axes[1,1].plot([1,800],[1,800], c='c', lw=2.5, label='y=x', linestyle=\"dashed\")\n",
    "axes[1,1].grid(\"True\")\n",
    "axes[1,1].set_yscale('log')\n",
    "axes[1,1].set_xscale('log')\n",
    "axes[1,1].set_ylabel(\"Absolute Error\")\n",
    "axes[1,1].legend()\n",
    "\n",
    "\n",
    "# Merge the first row's axes\n",
    "gs = axes[2, 0].get_gridspec()\n",
    "for ax in axes[2, :]:\n",
    "    ax.remove()\n",
    "ax_big = fig.add_subplot(gs[2, :])\n",
    "ax_big.scatter(1/(xtarget_samples.sum(dim=1).numpy()/1000), np.abs(xtarget_samples.sum(dim=1).numpy() - xrecon_samples.sum(dim=1).numpy())/(xtarget_samples.sum(dim=1).numpy()+1e-3), marker='.', alpha=.5, color=\"blue\")\n",
    "ax_big.plot([1e-3,1e1],np.sqrt([1e-3,1e1])*np.power(1,3.5), c='orange', lw=2.5, label='y=sqrt(x)', linestyle=\"dashdot\")\n",
    "ax_big.grid(\"True\")\n",
    "ax_big.set_yscale('log')\n",
    "ax_big.set_xscale('log')\n",
    "ax_big.legend()\n",
    "ax_big.set_ylim([1e-5,1e1])\n",
    "ax_big.set_yticks([1e-5,1e-4,1e-3,1e-2,1e-1,1e0,1e1])\n",
    "ax_big.set_ylabel(\"Relative Recon Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d04f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

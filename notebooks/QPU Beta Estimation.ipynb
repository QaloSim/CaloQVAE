{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b516566",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the path to the parent directory to augment search for module\n",
    "sys.path.append(os.getcwd())\n",
    "# Add the path to the parent directory to augment search for module\n",
    "par_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "if par_dir not in sys.path:\n",
    "    sys.path.append(par_dir)\n",
    "    \n",
    "# ML imports\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# DiVAE imports\n",
    "from models.rbm.chimeraRBM import ChimeraRBM\n",
    "from models.rbm.qimeraRBM import QimeraRBM\n",
    "from models.rbm.rbm import RBM\n",
    "from models.samplers.pcd import PCD\n",
    "from models.autoencoders.gumboltCaloCRBM import GumBoltCaloCRBM\n",
    "\n",
    "from nbutils import *\n",
    "\n",
    "# DWave imports\n",
    "from dwave.system import DWaveSampler, LeapHybridSampler\n",
    "import neal\n",
    "import dimod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b7cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(cfg):\n",
    "    model = GumBoltCaloCRBM(flat_input_size=[504],\n",
    "                            train_ds_mean=0.,\n",
    "                            activation_fct=torch.nn.ReLU(),\n",
    "                            cfg=cfg)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97495cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path=\"../configs\"):\n",
    "    cfg = compose(config_name=\"config-backup-oct-7-22\")\n",
    "    # this config file uses the chimera architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b4533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_model(cfg)\n",
    "model.create_networks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6656c90b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qpu_sampler = DWaveSampler(solver={\"topology__type\":\"chimera\", \"chip_id\":\"DW_2000Q_6\"})\n",
    "aux_crbm = QimeraRBM(n_visible=model.prior._n_visible, n_hidden=model.prior._n_hidden)\n",
    "aux_crbm_sampler = PCD(batch_size=850, RBM=aux_crbm, n_gibbs_sampling_steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48390169",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code to use GPU. Must specify which GPU unit to use here:\n",
    "\"\"\"\n",
    "GPU_NUM = 5\n",
    "torch.cuda.set_device(5)\n",
    "print(\"Using GPU {0}\".format(torch.cuda.current_device()))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609efe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send sampler to GPU and define ZERO and MINUS_ONE in GPU\n",
    "aux_crbm_sampler = aux_crbm_sampler.to(device)\n",
    "ZERO = torch.tensor(0., dtype=torch.float).to(device)\n",
    "MINUS_ONE = torch.tensor(-1., dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_ising(n_vis, n_hid):\n",
    "    \"\"\"\n",
    "    This function randomly initializes an Ising model with random J and h in the given ranges\n",
    "    Inputs: nunmbers of visible and hidden nodes\n",
    "    Output: Ising Weights and Biases\n",
    "    * UPDATE: J is now drawn from a Gaussian distribution instead of a Uniform distribution\n",
    "    \"\"\"\n",
    "    #wlim = [-0.5,0.5]\n",
    "    #ising_weights = torch.nn.Parameter((wlim[1]-wlim[0])*torch.rand(n_vis, n_hid) + wlim[0], requires_grad=False) \n",
    "    ising_weights = torch.normal(0, 0.2, size=(n_hid, n_hid))\n",
    "    hlim = [-2,2]\n",
    "    ising_vbias = torch.nn.Parameter((hlim[1]-hlim[0])*torch.rand(n_vis)+hlim[0], requires_grad=False)\n",
    "    ising_hbias = torch.nn.Parameter((hlim[1]-hlim[0])*torch.rand(n_hid)+hlim[0], requires_grad=False)\n",
    "    return ising_weights, ising_vbias, ising_hbias\n",
    "\n",
    "ising_weights, ising_vbias, ising_hbias = initialize_ising(1000,1000)\n",
    "\n",
    "# Check to ensure J is in the valid DWAVE coupling range\n",
    "min_J = np.min(ising_weights.cpu().detach().numpy())\n",
    "max_J = np.max(ising_weights.cpu().detach().numpy())\n",
    "print(\"J is between: {0} and {1}\".format(min_J,max_J))\n",
    "\n",
    "# the initialization below is necessary to run the function in\n",
    "# the following block\n",
    "dwave_energies = 0\n",
    "dwave_samples = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502844c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_fixed_qpu(num_iterations:int=10, lr:float=0.01, beta_init=10., n_reads:int=100, qpu_sampler=None, \n",
    "                   aux_crbm_sampler=None, ising_weights=None, ising_vbias=None, ising_hbias=None, \n",
    "                   dwave_energies=0, dwave_samples=0, newDwave = 0):\n",
    "    \"\"\"Estimate the temperature associated with a given QPU configuration\n",
    "    \n",
    "    :param num_iterations (int) : Number of iterations\n",
    "    :param lr (float) : Learning rate\n",
    "    :param beta_init (float) : Initial estimate of the QPU temperature\n",
    "    :param n_qpu_samples (int) : Number of QPU samples\n",
    "    :param qpu_sampler\n",
    "    \n",
    "    \"\"\"\n",
    "    assert qpu_sampler is not None\n",
    "    assert aux_crbm_sampler is not None\n",
    "    \n",
    "    beta = beta_init\n",
    "    betas = [beta]\n",
    "    \n",
    "    # Auxiliary scaled RBM\n",
    "    aux_crbm = aux_crbm_sampler.rbm\n",
    "    aux_crbm_edgelist = aux_crbm.pruned_edge_list\n",
    "    \n",
    "    # Setup QPU control variables\n",
    "    n_vis = len(aux_crbm.visible_qubit_idxs)\n",
    "    n_hid = len(aux_crbm.visible_qubit_idxs)\n",
    "    print(\"n_vis is {0} and n_hid is {1}\\n\".format(n_vis,n_hid))\n",
    "    qubit_idxs = aux_crbm.visible_qubit_idxs+aux_crbm.hidden_qubit_idxs\n",
    "    \n",
    "    visible_idx_map = {visible_qubit_idx:i for i, visible_qubit_idx in enumerate(aux_crbm.visible_qubit_idxs)}\n",
    "    hidden_idx_map = {hidden_qubit_idx:i for i, hidden_qubit_idx in enumerate(aux_crbm.hidden_qubit_idxs)}\n",
    "    \"\"\"\n",
    "    Send Ising weights and biases to GPU is available\n",
    "    \"\"\"\n",
    "    ising_weights = ising_weights.to(device)\n",
    "    ising_vbias = ising_vbias.to(device)\n",
    "    ising_hbias = ising_hbias.to(device)    \n",
    "    \"\"\"\n",
    "    Also note that we are using a Chimera RBM architecture. Thus we have to transform \n",
    "    our Ising model by modifying the couplings to get the Chimera RBM architecture.\n",
    "    We do this by masking the corresponding RBM weights of our ising_model\n",
    "    and then reverting the rbm model back to the ising model. \n",
    "    \"\"\"\n",
    "    aux_crbm_weights = 4.*ising_weights # weights of the corresponding RBM\n",
    "    aux_crbm_weights = aux_crbm_weights*aux_crbm.weights_mask # mask to get Chimera RBM architecture\n",
    "    ising_weights = aux_crbm_weights*0.25 # revert back to ising model\n",
    "    \n",
    "    dwave_weights_np = -ising_weights.detach().cpu().numpy()\n",
    "    print(\"J range = ({0}, {1})\".format(np.min(dwave_weights_np),\n",
    "                                        np.max(dwave_weights_np)))\n",
    "    \n",
    "    vbias_list = list(ising_vbias.detach().cpu().numpy())\n",
    "    hbias_list = list(ising_hbias.detach().cpu().numpy())\n",
    "    hVis = {v_qubit_idx:-vbias_list[visible_idx_map[v_qubit_idx]] for v_qubit_idx in aux_crbm.visible_qubit_idxs}\n",
    "    hHid = {h_qubit_idx:-hbias_list[hidden_idx_map[h_qubit_idx]] for h_qubit_idx in aux_crbm.hidden_qubit_idxs}\n",
    "    h = {**hVis,**hHid}\n",
    "    J = {}\n",
    "    for edge in aux_crbm_edgelist:\n",
    "        if edge[0] in aux_crbm.visible_qubit_idxs:\n",
    "            J[edge] = dwave_weights_np[visible_idx_map[edge[0]]][hidden_idx_map[edge[1]]]\n",
    "        else:\n",
    "            J[edge] = dwave_weights_np[visible_idx_map[edge[1]]][hidden_idx_map[edge[0]]]\n",
    "    \n",
    "    if (newDwave==1):\n",
    "        response = qpu_sampler.sample_ising(h, J, num_reads=n_reads, auto_scale=False)\n",
    "        dwave_samples, dwave_energies = batch_dwave_samples(response, qubit_idxs) \n",
    "    dwave_samples = torch.tensor(dwave_samples, dtype=torch.float)  \n",
    "    \n",
    "    dwave_energy_exp = np.mean(dwave_energies, axis=0) # we use energies returned by DWAVE API to get expectation\n",
    "\n",
    "    print(\"dwave_energy_exp : {0}\".format(dwave_energy_exp))\n",
    "    \n",
    "    \"\"\"\n",
    "    Recall that in each iteration of the beta_eff* estimation we change the RBM parameters. However\n",
    "    we still sample from the same RBM which has been initialized above. Hence, we keep track \n",
    "    of the original parameters by the following:\n",
    "    \"\"\"\n",
    "\n",
    "    rbm_orig_vis = torch.nn.Parameter(2.*(ising_vbias - torch.sum(ising_weights, dim=1)), requires_grad=False).to(device)\n",
    "    rbm_orig_hid = torch.nn.Parameter(2.*(ising_hbias - torch.sum(ising_weights, dim=0)), requires_grad=False).to(device)\n",
    "    rbm_orig_weights = ising_weights*4\n",
    " \n",
    "    classical_energies = [0]*num_iterations # classical energies is a 2D array containing \n",
    "                                            # classical energy distributions computed at each iteration\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        aux_crbm.weights = rbm_orig_weights*beta\n",
    "        aux_crbm._visible_bias = torch.nn.Parameter(rbm_orig_vis*beta, requires_grad=False) \n",
    "        aux_crbm._hidden_bias = torch.nn.Parameter(rbm_orig_hid*beta, requires_grad=False)\n",
    "        \n",
    "        \n",
    "        aux_crbm_sampler.rbm = aux_crbm\n",
    "        \n",
    "        aux_crbm_vis, aux_crbm_hid = aux_crbm_sampler.block_gibbs_sampling()\n",
    "        \n",
    "        \"\"\"\n",
    "        Finding energy using RBM method\n",
    "        The code below computes the same ising energy energy expectation using RBM weights and biases.\n",
    "        rbm_energy_exp is basically the same as aux_crbm_energy_exp and thus has been commented out\n",
    "        \"\"\"\n",
    "        # ising_energy_rbm_params = ising_energy_rbm(rbm_orig_weights, rbm_orig_vis, rbm_orig_hid, aux_crbm_vis, aux_crbm_hid)\n",
    "        # rbm_energy_exp = torch.mean(ising_energy_rbm_params, axis=0)        \n",
    "        \n",
    "        aux_crbm_vis = torch.where(aux_crbm_vis == ZERO, MINUS_ONE, aux_crbm_vis)\n",
    "        aux_crbm_hid = torch.where(aux_crbm_hid == ZERO, MINUS_ONE, aux_crbm_hid)\n",
    "        \n",
    "        aux_crbm_energy_exp = ising_energies_exp(ising_weights, ising_vbias, ising_hbias, aux_crbm_vis, aux_crbm_hid)\n",
    "        aux_crbm_energy_exps = -aux_crbm_energy_exp.detach().cpu().numpy()\n",
    "        classical_energies[i] = aux_crbm_energy_exps\n",
    "        aux_crbm_energy_exp = -torch.mean(aux_crbm_energy_exp, axis=0)\n",
    "        \n",
    "        print(\"aux_crbm_energy_exp : {0}, beta : {1} and epoch {2}\".format(aux_crbm_energy_exp, beta, i+1))\n",
    "        beta = beta - lr*(-float(aux_crbm_energy_exp)+float(dwave_energy_exp))\n",
    "        betas.append(beta)\n",
    "        \n",
    "    return betas, dwave_energies, aux_crbm_energy_exps, ising_weights, J, h, qubit_idxs, classical_energies, dwave_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597dad51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# newDwave = 1 means we are getting new dwave samples and energies\n",
    "# newDwave = 0 means we are using the previously computed dwave samples and energies\n",
    "betas, dwave_energies,  aux_crbm_energy_exps, ising_weights, J, h, qubit_idxs, classical_energies, dwave_samples = beta_fixed_qpu(num_iterations=15,\n",
    "                       lr=0.095,\n",
    "                       beta_init=9.6,\n",
    "                       n_reads=850,\n",
    "                       qpu_sampler=qpu_sampler,\n",
    "                       aux_crbm_sampler=aux_crbm_sampler,\n",
    "                       ising_weights = ising_weights,\n",
    "                       ising_vbias = ising_vbias,\n",
    "                       ising_hbias = ising_hbias,\n",
    "                       dwave_energies = dwave_energies,\n",
    "                       dwave_samples = dwave_samples,\n",
    "                       newDwave = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2b0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_betas(betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ab1a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energies(energies1, energies2, binwidth):\n",
    "    \"\"\"\n",
    "    Plot the energies of the samples produced by the histograms   \n",
    "    UPDATE: bin now found using bin boundaries\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(40, 16))\n",
    "    data = np.concatenate((energies1,energies2), axis=0)\n",
    "    bins =  np.arange(min(data), max(data) + binwidth, binwidth)\n",
    "    ax.hist(energies1, bins=bins, label = \"dwave energies\")  \n",
    "    ax.hist(energies2, bins=bins, label = \"auxiliary RBM energies\", alpha=0.5) \n",
    "    plt.legend(loc='upper right', fontsize=30)\n",
    "    ax.set_xlabel(\"Energy\", fontsize=60)\n",
    "    ax.set_ylabel(\"Frequency\", fontsize=60)\n",
    "    \n",
    "    ax.tick_params(axis='both', which='major', labelsize=60)\n",
    "    ax.grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b775db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(classical_energies)):\n",
    "    plot_energies(dwave_energies, classical_energies[i], 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2362c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# this will give dwave energy distributions in 58 second intervals \n",
    "def getDwavePlots(num_iter, n_reads, ising_weights, ising_vbias, ising_hbias):\n",
    "    dwave_array = [0]*num_iter\n",
    "    for i in range(num_iter):\n",
    "        betas, dwave_energies,  aux_crbm_energy_exps, ising_weights, J, h, qubit_idxs, classical_energies, dwave_samples = beta_fixed_qpu(num_iterations=1,\n",
    "                               lr=0.05,\n",
    "                               beta_init=9.27, \n",
    "                               n_reads=n_reads,\n",
    "                               qpu_sampler=qpu_sampler,\n",
    "                               aux_crbm_sampler=aux_crbm_sampler,\n",
    "                               ising_weights = ising_weights,\n",
    "                               ising_vbias = ising_vbias,\n",
    "                               ising_hbias = ising_hbias,\n",
    "                               dwave_energies = 0,\n",
    "                               dwave_samples = 0,\n",
    "                               newDwave = 1) \n",
    "        dwave_array[i] = dwave_energies\n",
    "        if (i!=num_iter-1):\n",
    "            time.sleep(58)\n",
    "    return dwave_array\n",
    "dwave_array = getDwavePlots(4,2000, ising_weights, ising_vbias, ising_hbias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

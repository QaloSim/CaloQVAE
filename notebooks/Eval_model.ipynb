{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0330e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: DWAVE_API_TOKEN=DEV-1ba72787de429d2af12464f7753c10b9ff6945ad\n",
      "Thu Jun 13 18:44:33 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.67                 Driver Version: 550.67         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A6000               Off |   00000000:1B:00.0 Off |                  Off |\n",
      "| 30%   45C    P2            112W /  300W |    7490MiB /  49140MiB |     42%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000               Off |   00000000:1C:00.0 Off |                  Off |\n",
      "| 30%   30C    P8             28W /  300W |       5MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA RTX A6000               Off |   00000000:4F:00.0 Off |                  Off |\n",
      "| 30%   30C    P8             20W /  300W |    5547MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA RTX A6000               Off |   00000000:50:00.0 Off |                  Off |\n",
      "| 30%   30C    P8             23W /  300W |       4MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   4  NVIDIA RTX A6000               Off |   00000000:9C:00.0 Off |                  Off |\n",
      "| 30%   38C    P2            103W /  300W |    7602MiB /  49140MiB |     22%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   5  NVIDIA RTX A6000               Off |   00000000:9D:00.0 Off |                  Off |\n",
      "| 30%   24C    P8             28W /  300W |       5MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A    248874      C   python                                       7482MiB |\n",
      "|    2   N/A  N/A   4004897      C   /usr/bin/python                              5540MiB |\n",
      "|    4   N/A  N/A    265264      C   python                                       7594MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "# %env CUDA_VISIBLE_DEVICES=5\n",
    "%env DWAVE_API_TOKEN=DEV-1ba72787de429d2af12464f7753c10b9ff6945ad\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e71cd2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[17:21:40.678]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mCaloQVAE                                          \u001b[0mWillkommen!\n",
      "\u001b[1m[17:21:40.680]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mCaloQVAE                                          \u001b[0mLoading configuration.\n"
     ]
    }
   ],
   "source": [
    "import hydra\n",
    "from hydra.utils import instantiate\n",
    "from hydra import initialize, compose\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "# Path to where your CaloQVAE dir is\n",
    "PATH = '/home/' + getpass.getuser() + '/CaloQVAE/'\n",
    "os.chdir(PATH)\n",
    "sys.path.insert(1, PATH)\n",
    "\n",
    "#external libraries\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits\n",
    "torch.manual_seed(32)\n",
    "import numpy as np\n",
    "np.random.seed(32)\n",
    "import matplotlib.pyplot as plt\n",
    "import hydra\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# PyTorch imports\n",
    "from torch import device, load, save\n",
    "from torch.nn import DataParallel\n",
    "from torch.cuda import is_available\n",
    "\n",
    "# Add the path to the parent directory to augment search for module\n",
    "sys.path.append(os.getcwd())\n",
    "    \n",
    "# Weights and Biases\n",
    "import wandb\n",
    "\n",
    "#self defined imports\n",
    "from CaloQVAE import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04365d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from data.dataManager import DataManager\n",
    "from utils.plotting.plotProvider import PlotProvider\n",
    "from engine.engine import Engine\n",
    "from models.modelCreator import ModelCreator\n",
    "\n",
    "from utils.plotting.HighLevelFeatures import HighLevelFeatures as HLF\n",
    "#HLF_1_photons = HLF('photon', filename='/fast_scratch/QVAE/data/atlas/binning_dataset_1_photons.xml', wandb=False)\n",
    "#HLF_1_pions = HLF('pion', filename='/fast_scratch/QVAE/data/atlas/binning_dataset_1_pions.xml', wandb=False)\n",
    "#HLF_1_electron = HLF('electron', filename='/fast_scratch/QVAE/data/atlas_dataset2and3/binning_dataset_2.xml', wandb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0396de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or reload config files\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(version_base=None, config_path=\"../configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c9d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instatiate model\n",
    "config=compose(config_name=\"config.yaml\")\n",
    "HLF_1_photons = HLF(‘photon’, filename=config.data.binning_xml_photons, wandb=False)\n",
    "HLF_1_pions = HLF(‘pion’, filename=config.data.binning_xml_pions, wandb=False)\n",
    "HLF_1_electron = HLF(‘electron’, filename=config.data.binning_xml_electrons, wandb=False)\n",
    "wandb.init(project=\"caloqvae\", entity=\"qvae\", config=config, mode='disabled')\n",
    "modelCreator = ModelCreator(cfg=config)\n",
    "dataMgr = DataManager(cfg=config)\n",
    "#initialise data loaders\n",
    "dataMgr.init_dataLoaders()\n",
    "#run pre processing: get/set input dimensions and mean of train dataset\n",
    "dataMgr.pre_processing()\n",
    "\n",
    "if config.model.activation_fct.lower()==\"relu\":\n",
    "    modelCreator.default_activation_fct=torch.nn.ReLU()\n",
    "elif config.model.activation_fct.lower()==\"tanh\":\n",
    "    modelCreator.default_activation_fct=torch.nn.Tanh()\n",
    "else:\n",
    "    logger.warning(\"Setting identity as default activation fct\")\n",
    "    modelCreator.default_activation_fct=torch.nn.Identity()\n",
    "\n",
    "#instantiate the chosen model\n",
    "#loads from file \n",
    "model=modelCreator.init_model(dataMgr=dataMgr)\n",
    "\n",
    "#create the NN infrastructure\n",
    "model.create_networks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73495240",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.print_model_info()\n",
    "dev = \"cuda:{0}\".format(config.gpu_list[0])\n",
    "\n",
    "# Log metrics with wandb\n",
    "wandb.watch(model)\n",
    "\n",
    "# For some reason, need to use postional parameter cfg instead of named parameter\n",
    "# with updated Hydra - used to work with named param but now is cfg=None \n",
    "engine=instantiate(config.engine, config)\n",
    "\n",
    "#TODO for some reason hydra double instantiates the engine in a\n",
    "#newer version if cfg=config is passed as an argument. This is a workaround.\n",
    "#Find out why that is...\n",
    "engine._config=config\n",
    "#add dataMgr instance to engine namespace\n",
    "engine.data_mgr=dataMgr\n",
    "#add device instance to engine namespace\n",
    "engine.device=dev    \n",
    "#instantiate and register optimisation algorithm\n",
    "# engine.optimiser = torch.optim.Adam(model.parameters(),\n",
    "#                                     lr=config.engine.learning_rate)\n",
    "#add the model instance to the engine namespace\n",
    "engine.model = model\n",
    "# add the modelCreator instance to engine namespace\n",
    "engine.model_creator = modelCreator\n",
    "engine.model = engine.model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b0e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader,test_loader,val_loader = engine.data_mgr.create_dataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c85e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chip 6.4 is pegasus\n",
    "engine.model._qpu_sampler.properties[\"chip_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6f0201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa1f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'macabre-candle-1372'\n",
    "run_path = \"/fast_scratch/sgonzalez/wandb/run-20240422_172049-e167mmxd/files/GumBoltAtlasPCRBMCNN_atlas_default_best.pth\"\n",
    "datascaled = 'scaled'\n",
    "# with open(\"/fast_scratch/sgonzalez/wandb/run-20240422_172049-e167mmxd/files/config.yaml\", 'r') as file:\n",
    "#     model_config = yaml.safe_load(file)\n",
    "    \n",
    "arch = config['model']['model_type']\n",
    "part = config['data']['particle_type']\n",
    "print(arch)\n",
    "print(part)\n",
    "\n",
    "modelCreator.load_state(run_path, dev)\n",
    "engine.model.eval();\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef1e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = PATH + f'figs/{modelname}'\n",
    "if not os.path.isdir(directory_path):\n",
    "    os.makedirs(directory_path) \n",
    "    print(modelname)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dbd117",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtarget_samples = []\n",
    "xrecon_samples = []\n",
    "xgen_samples = []\n",
    "scaled = True\n",
    "entarget_samples = []\n",
    "            \n",
    "# for xx in train_loader:\n",
    "for xx in val_loader:\n",
    "    in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "    \n",
    "    fwd_output = engine.model((in_data, true_energy), False)\n",
    "    \n",
    "    if scaled:\n",
    "        in_data = torch.tensor(engine._data_mgr.inv_transform(in_data.detach().cpu().numpy()))\n",
    "        \n",
    "        \n",
    "        recon_data = torch.tensor(engine._data_mgr.inv_transform(fwd_output.output_activations.detach().cpu().numpy()))\n",
    "        \n",
    "        ## This is how youi generate data using model\n",
    "        # ================================\n",
    "        engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "        sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy) #engine._model.generate_samples_qpu(num_samples=128, true_energy=true_energy[:128])\n",
    "        engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "        sample_data = torch.tensor(engine._data_mgr.inv_transform(sample_data.detach().cpu().numpy()))\n",
    "        # ================================\n",
    "    \n",
    "    else:\n",
    "        raise Exception(\"Script only supports scaled dataset at the moment...\")\n",
    "\n",
    "\n",
    "    xtarget_samples.append(in_data.detach().cpu())\n",
    "    xrecon_samples.append( recon_data.detach().cpu())\n",
    "    xgen_samples.append( sample_data.detach().cpu())\n",
    "    entarget_samples.append(true_energy.detach().cpu())\n",
    "    \n",
    "    \n",
    "xtarget_samples = torch.cat(xtarget_samples, dim=0)\n",
    "xrecon_samples = torch.cat(xrecon_samples, dim=0)\n",
    "xgen_samples = torch.cat(xgen_samples, dim=0)\n",
    "entarget_samples = torch.cat(entarget_samples, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56fcae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta, beta_list, rbm_energy_list, dwave_energy_list, thrsh_met = engine.model.find_beta(num_reads=256, beta_init=4.5, lr=0.01, num_epochs = 30, delta = 4.0, method = 2, TOL=True, const = 1.0, adaptive = True)\n",
    "# beta0 = beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f3659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(range(len(beta_list)), beta_list, linewidth=2.5, color=\"b\" )\n",
    "# plt.plot(range(len(beta_list)), beta_list, linewidth=1.5, color=\"b\" )\n",
    "# plt.xlabel(\"Iterations\", fontsize=15)\n",
    "# plt.ylabel(\"Estimated $β_{QA}$\", fontsize=15)\n",
    "# plt.legend([f'Chip {engine.model._qpu_sampler.properties[\"chip_id\"]}'], fontsize=15)\n",
    "# # plt.title(f'{ds[part]}')\n",
    "# plt.grid(\"True\")\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/beta_QA_{engine.model._qpu_sampler.properties[\"chip_id\"]}_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9487c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA = \"$β_{QA}$\"\n",
    "# Hoffset = -(sum([engine.model.prior.bias_dict[key].sum().detach().cpu().item() for key in engine.model.prior.bias_dict.keys()])/2 + sum([engine.model.prior.weight_dict[key].sum().detach().cpu().item() for key in engine.model.prior.weight_dict.keys()])/4)\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.hist(rbm_energy_list[-1] + Hoffset, density=True, color=\"orange\", alpha=0.7)\n",
    "# plt.hist(dwave_energy_list[-1] + Hoffset, density=True, color=\"m\", alpha=0.7)\n",
    "# plt.xlabel(\"RBM Energy\", fontsize=15)\n",
    "# plt.ylabel(\"PDF\", fontsize=15)\n",
    "# plt.legend([\"Classical samples\", \"QPU samples\"], fontsize=17)\n",
    "# # plt.title(f'ln(Z)[AIS] = {np.round(Zais)}, ln(Z)[RAIS] = {np.round(Zrais)}')\n",
    "# plt.figtext(0.7, 0.6, f'Est. {QA} = {np.round(beta, 2)}', ha='center', va='top', fontsize=17, bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=1'))\n",
    "# plt.subplots_adjust(bottom=0.2)\n",
    "# plt.grid(\"True\")\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/Ising_energy_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "# plt.show()\n",
    "# print(len(rbm_energy_list[-1]))\n",
    "# print(len(dwave_energy_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc1b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition_size=config.model.n_latent_nodes_per_p\n",
    "# encoded_data = []\n",
    "# energy_encoded_data = []\n",
    "\n",
    "# engine.model.eval()\n",
    "# # engine_2.model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for xx in val_loader:\n",
    "#         in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "#         if reducedata:\n",
    "#             in_data = engine._reduce(in_data, true_energy, R=R)\n",
    "#         beta, post_logits, post_samples = engine.model.encoder(in_data, true_energy, False)\n",
    "#         post_samples = torch.cat(post_samples, 1)\n",
    "#         post_samples_energy = engine.model.stater.energy_samples(post_samples[:,0:partition_size], post_samples[:,partition_size:2*partition_size], \n",
    "#                                                  post_samples[:,2*partition_size:3*partition_size], post_samples[:,3*partition_size:4*partition_size], 1.0 )\n",
    "#         encoded_data.append(post_samples.detach().cpu())\n",
    "#         energy_encoded_data.append(post_samples_energy.detach().cpu())\n",
    "        \n",
    "# encoded_data = torch.cat(encoded_data, dim=0)\n",
    "# energy_encoded_data = torch.cat(energy_encoded_data, dim=0)\n",
    "        \n",
    "# p1,p2,p3,p4 = post_samples[:,0:partition_size], post_samples[:,partition_size:2*partition_size], \\\n",
    "#                                                  post_samples[:,2*partition_size:3*partition_size], post_samples[:,3*partition_size:4*partition_size]\n",
    "\n",
    "# energy_rbm_data = []\n",
    "# with torch.no_grad():\n",
    "#     # for i in range(10):\n",
    "#     for xx in val_loader:\n",
    "#         in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "#         engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "#         if True:\n",
    "#             u = engine.model.encoder.binary_energy(true_energy).to(dtype=torch.float32)\n",
    "#             p1, p2, p3, p4 = engine.model.sampler.block_gibbs_sampling_cond(u)\n",
    "#         else:\n",
    "#             p1, p2, p3, p4 = engine.model.sampler.block_gibbs_sampling()\n",
    "#         rbm_samples_energy = engine.model.stater.energy_samples(p1, p2, p3, p4, 1.0)\n",
    "#         energy_rbm_data.append(rbm_samples_energy.detach().cpu())\n",
    "#         engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "        \n",
    "# energy_rbm_data = torch.cat(energy_rbm_data, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a6bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minVal, maxVal = min(energy_encoded_data.numpy()), max(energy_encoded_data.numpy())\n",
    "# binwidth = (maxVal-minVal)/50\n",
    "\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.hist(energy_encoded_data.numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), linewidth=2.5, color=\"b\", density=True, log=True, label=\"Encoded data\", alpha=0.7)\n",
    "# plt.hist(energy_rbm_data.numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), color=\"orange\", density=True, fc=(1, 0, 1, 0.5), log=True, histtype='step', linewidth=2.5, label=\"Classically sampled data\")\n",
    "# # plt.hist(energy_dwave.detach().cpu().numpy(), bins=20, color=\"m\", density=True, fc=(1, 0, 1, 0.5), log=True, histtype='step', linewidth=2.5, label=\"QPU sampled data\")\n",
    "\n",
    "# plt.xlabel(\"RBM Energy\", fontsize=15)\n",
    "# plt.ylabel(\"PDF\", fontsize=15)\n",
    "# plt.legend(fontsize=18)\n",
    "# plt.grid(\"True\")\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/RBM_energy_2_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6008e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "minVal, maxVal = min(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy()), max(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy())\n",
    "binwidth = (maxVal-minVal)/50\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7)\n",
    "plt.hist(((xrecon_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"c\")\n",
    "plt.hist(((xgen_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashdot\")\n",
    "# plt.hist(((xgen_samples_qpu == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=50, log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashed\")\n",
    "plt.xlabel(\"Sparsity Index\", fontsize=15)\n",
    "plt.ylabel(\"Histogram\", fontsize=15)\n",
    "plt.legend([\"GT\", \"Recon\", \"Samples\", \"Sample /w QPU\"], fontsize=17)\n",
    "plt.grid(\"True\")\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sparsity_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97955ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLF_1_electron.relevantLayers = [0,5,10,15,20,25,30,35,40,45]\n",
    "plt.figure(figsize=(8,6))\n",
    "# Create a grid of subplots\n",
    "fig, axes = plt.subplots(3,3, figsize=(12, 12), sharey=True, sharex=True, tight_layout=True)\n",
    "fig.text(0.5, -0.01, 'Sparsity Index', ha='center', fontsize=15)\n",
    "fig.text(-0.01, 0.5, 'Histogram', va='center', rotation='vertical', fontsize=15)\n",
    "\n",
    "# Iterate through the columns of X and plot histograms\n",
    "for i,_ in enumerate(HLF_1_electron.relevantLayers[:-1]):\n",
    "    row_index = i // 3  # Determine the row index\n",
    "    col_index = i % 3   # Determine the column index\n",
    "    \n",
    "    ax = axes[row_index, col_index]  # Get the current subplot\n",
    "    \n",
    "    # Plot histogram for the current column\n",
    "    idx = HLF_1_electron.relevantLayers[i+1]*9*16\n",
    "    idxPrev = (HLF_1_electron.relevantLayers[i])*9*16\n",
    "    l = idx - idxPrev\n",
    "    minVal, maxVal = min(((xtarget_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy()), max(((xtarget_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy())\n",
    "    binwidth = (maxVal-minVal)/30\n",
    "    ax.hist(((xtarget_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy(),  bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7)\n",
    "    ax.hist(((xrecon_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"c\")\n",
    "    ax.hist(((xgen_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy(), bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashdot\")\n",
    "    # ax.hist(((xgen_samples_qpu[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy(), bins=30, log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashed\")\n",
    "    if i == 0:\n",
    "        ax.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], fontsize=14)\n",
    "    ax.grid(\"True\")\n",
    "    \n",
    "    # Set labels and title for the subplot\n",
    "    # ax.set_xlabel(f'Column {i + 1}')\n",
    "    # ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Layers {HLF_1_electron.relevantLayers[i]} to {HLF_1_electron.relevantLayers[i+1]-1}', fontsize=12)\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sparsity_per_layer_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb8c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), ((xrecon_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(),  marker='.', alpha=.5, color=\"b\")\n",
    "plt.scatter(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), ((xgen_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(),  marker='.', alpha=.5, color=\"orange\")\n",
    "plt.plot([0,1],[0,1], c='red', lw=2.5)\n",
    "plt.xlabel('GT Sparsity Index', fontsize=15)\n",
    "plt.ylabel('Reconstruction Sparsity Index', fontsize=15)\n",
    "plt.grid(\"True\")\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sparsity_scatter_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba03e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "minVal, maxVal = min(xtarget_samples.sum(dim=1).numpy()/1000), max(xtarget_samples.sum(dim=1).numpy()/1000)\n",
    "binwidth = (maxVal-minVal)/50\n",
    "plt.hist(xtarget_samples.sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7)\n",
    "plt.hist(xrecon_samples.sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"c\")\n",
    "plt.hist(xgen_samples.sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"orange\", linestyle=\"dashdot\")\n",
    "# plt.hist(xgen_samples_qpu.sum(dim=1).numpy()/1000, bins=50, log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"m\", linestyle=\"dashed\")\n",
    "# plt.hist(xtarget_samples.sum(dim=1).numpy()/1000, bins=np.arange(0, 100 + 1,2), log=True, histtype='step', linewidth=2.5, color=\"b\")\n",
    "# plt.hist(xrecon_samples.sum(dim=1).numpy()/1000, bins=np.arange(0, 100 + 1,2), log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "# plt.hist(xgen_samples.sum(dim=1).numpy()/1000, bins=np.arange(0, 100 + 1,2), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashed\")\n",
    "# plt.hist(xtarget_samples.sum(dim=1).numpy()/1000, bins=np.arange(100+1, 1000 + 1,10), log=True, histtype='step')\n",
    "# plt.hist(xrecon_samples.sum(dim=1).numpy()/1000, bins=np.arange(100+1, 1000 + 1,10), log=True, histtype='step')\n",
    "# plt.hist(xgen_samples.sum(dim=1).numpy()/1000, bins=np.arange(100+1, 1000 + 1,10), log=True, histtype='step')\n",
    "plt.xlabel(\"Energy per event (GeV)\", fontsize=15)\n",
    "\n",
    "plt.ylabel(\"Histogram\", fontsize=15)\n",
    "plt.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], fontsize=18)\n",
    "plt.grid(\"True\")\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n",
    "print(xgen_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4743b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xtarget_samples.sum(dim=1).numpy()/1000, xrecon_samples.sum(dim=1).numpy()/1000, marker='.', alpha=.5, color=\"b\")\n",
    "plt.scatter(xtarget_samples.sum(dim=1).numpy()/1000, xgen_samples.sum(dim=1).numpy()/1000, marker='.', alpha=.5, color=\"orange\")\n",
    "plt.plot([0,800],[0,800], c='red', lw=2.5, label='y=x')\n",
    "plt.legend()\n",
    "plt.grid(\"True\")\n",
    "plt.xlabel(\"GT energy per event (GeV)\", fontsize=15)\n",
    "plt.ylabel(\"Recon energy per event (GeV)\", fontsize=15)\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_scatter_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9d3677",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,2, figsize=(8,8), tight_layout=True)\n",
    "fig.text(0.5, 0.0, 'GT energy per event (GeV)', ha='center')\n",
    "# fig.text(0.5, 1.0, f'{ds[part]}', ha='center', fontsize=12)\n",
    "\n",
    "axes[0,0].scatter(xtarget_samples.sum(dim=1).numpy()/1000, xrecon_samples.sum(dim=1).numpy()/1000, marker='.', alpha=.5, color=\"b\")\n",
    "axes[0,0].plot([0,800],[0,800], c='red', lw=2.5, label='y=x')\n",
    "# axes[0,0].plot([0,3800],[0,3800], c='red', lw=2.5, label='y=x')\n",
    "axes[0,0].set_ylabel(\"Recon energy per event (GeV)\")\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(\"True\")\n",
    "axes[0,0].set_yscale('log')\n",
    "axes[0,0].set_xscale('log')\n",
    "\n",
    "axes[0,1].scatter(xtarget_samples.sum(dim=1).numpy()/1000, (xtarget_samples.sum(dim=1).numpy() - xrecon_samples.sum(dim=1).numpy())/1000, marker='.', alpha=0.6, color=\"b\")\n",
    "axes[0,1].scatter(xtarget_samples.sum(dim=1).numpy()/1000, (xtarget_samples.sum(dim=1).numpy() - xgen_samples.sum(dim=1).numpy())/1000, marker='.', alpha=0.2, color=\"orange\")\n",
    "# axes[0,1].scatter(xtarget_samples.sum(dim=1).numpy()/1000, (xtarget_samples.sum(dim=1).numpy() - xgen_samples_qpu.sum(dim=1).numpy())/1000, marker='.', alpha=0.1, color=\"m\")\n",
    "# plt.plot([0,20],[0,20], c='red', lw=2)\n",
    "# axes[0,1].set_xlabel(\"GT energy per event (GeV)\")\n",
    "axes[0,1].set_ylabel(\"Abs error (GeV)\")\n",
    "axes[0,1].set_ylim([-40,40])\n",
    "# axes[0,1].legend()\n",
    "# axes[0,1].set_yscale('log')\n",
    "axes[0,1].grid(\"True\")\n",
    "\n",
    "# axes[1,0].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy() - xtarget_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.5, color=\"blue\", label=\"Simulation\")\n",
    "# axes[1,0].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy() - xrecon_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.05, color=\"red\", label=\"Model\")\n",
    "axes[1,0].scatter(1/(entarget_samples.numpy()/1000), np.abs(entarget_samples.reshape(-1).numpy() - xtarget_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.5, color=\"blue\", label=\"Simulation\")\n",
    "axes[1,0].scatter(1/(entarget_samples.numpy()/1000), np.abs(entarget_samples.reshape(-1).numpy() - xrecon_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.05, color=\"red\", label=\"Model\")\n",
    "axes[1,0].plot([1e-3,1e0],np.power([1e-3,1e0],0.25)*np.power(10,2.0), c='orange', lw=2.5, label='slope=0.25', linestyle=\"dashdot\")\n",
    "axes[1,0].grid(\"True\")\n",
    "axes[1,0].set_yscale('log')\n",
    "axes[1,0].set_xscale('log')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].set_ylabel(\"Relative Error\")\n",
    "\n",
    "# axes[1,1].scatter(xtarget_samples.sum(dim=1).numpy()/1000, np.abs(xtarget_samples.sum(dim=1).numpy()/1000 - xrecon_samples.sum(dim=1).numpy()/1000), marker='.', alpha=.5, color=\"blue\")\n",
    "axes[1,1].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy()/1000 - xtarget_samples.sum(dim=1).numpy()/1000), marker='.', alpha=1, color=\"blue\", label=\"Simulation\")\n",
    "axes[1,1].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy()/1000 - xrecon_samples.sum(dim=1).numpy()/1000), marker='.', alpha=.2, color=\"red\", label=\"Model\")\n",
    "axes[1,1].plot([1,800],np.sqrt([1,800]), c='orange', lw=2.5, label='y=sqrt(x)', linestyle=\"dashdot\")\n",
    "axes[1,1].plot([1,800],[1,800], c='c', lw=2.5, label='y=x', linestyle=\"dashed\")\n",
    "# axes[1,1].set_title(f'{ds[part]}')\n",
    "axes[1,1].grid(\"True\")\n",
    "axes[1,1].set_yscale('log')\n",
    "axes[1,1].set_xscale('log')\n",
    "axes[1,1].set_ylabel(\"Absolute Error\")\n",
    "axes[1,1].legend()\n",
    "\n",
    "\n",
    "# Merge the first row's axes\n",
    "gs = axes[2, 0].get_gridspec()\n",
    "for ax in axes[2, :]:\n",
    "    ax.remove()\n",
    "ax_big = fig.add_subplot(gs[2, :])\n",
    "ax_big.scatter(1/(xtarget_samples.sum(dim=1).numpy()/1000), np.abs(xtarget_samples.sum(dim=1).numpy() - xrecon_samples.sum(dim=1).numpy())/(xtarget_samples.sum(dim=1).numpy()+1e-3), marker='.', alpha=.5, color=\"blue\")\n",
    "ax_big.scatter(1/(xtarget_samples.sum(dim=1).numpy()/1000), np.abs(xtarget_samples.sum(dim=1).numpy() - xtarget_samples.sum(dim=1).numpy())/(xtarget_samples.sum(dim=1).numpy()+1e-3), marker='.', alpha=.5, color=\"orange\")\n",
    "# axes[1,0].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy() - xtarget_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.5, color=\"blue\", label=\"Simulation\")\n",
    "# axes[1,0].scatter(entarget_samples.numpy()/1000, np.abs(entarget_samples.reshape(-1).numpy() - xrecon_samples.sum(dim=1).numpy())/(entarget_samples.reshape(-1).numpy()+1e-3), marker='.', alpha=.05, color=\"red\", label=\"Model\")\n",
    "# axes[1,0].set_title(f'{ds[part]}')\n",
    "ax_big.plot([1e-3,1e1],np.sqrt([1e-3,1e1])*np.power(1,3.5), c='orange', lw=2.5, label='y=sqrt(x)', linestyle=\"dashdot\")\n",
    "# axes[1,1].plot([1e-9,1e-6],np.linspace(1e-9,1e-6)*np.power(10,3.5), c='c', lw=2.5, label='y=x', linestyle=\"dashed\")\n",
    "ax_big.grid(\"True\")\n",
    "ax_big.set_yscale('log')\n",
    "ax_big.set_xscale('log')\n",
    "ax_big.legend()\n",
    "ax_big.set_ylim([1e-5,1e1])\n",
    "ax_big.set_yticks([1e-5,1e-4,1e-3,1e-2,1e-1,1e0,1e1])\n",
    "ax_big.set_ylabel(\"Relative Recon Error\")\n",
    "# plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_scatter_4panels_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2289d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLF_1_electron.relevantLayers = [0,5,10,15,20,25,30,35,40,45]\n",
    "plt.figure(figsize=(8,6))\n",
    "# Create a grid of subplots\n",
    "fig, axes = plt.subplots(3,3, figsize=(12, 12), sharey=True, sharex=False, tight_layout=True)\n",
    "fig.text(0.5, 0.0, 'Energy per event (GeV)', ha='center', fontsize=15)\n",
    "fig.text(0.0, 0.5, 'Histogram', va='center', rotation='vertical', fontsize=15)\n",
    "\n",
    "# Iterate through the columns of X and plot histograms\n",
    "for i,_ in enumerate(HLF_1_electron.relevantLayers[:-1]):\n",
    "    row_index = i // 3  # Determine the row index\n",
    "    col_index = i % 3   # Determine the column index\n",
    "    \n",
    "    ax = axes[row_index, col_index]  # Get the current subplot\n",
    "    \n",
    "    # Plot histogram for the current column\n",
    "    idx = HLF_1_electron.relevantLayers[i+1]*9*16\n",
    "    idxPrev = (HLF_1_electron.relevantLayers[i])*9*16\n",
    "    l = idx - idxPrev\n",
    "    minVal, maxVal = min(xtarget_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000), max(xtarget_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000)\n",
    "    binwidth = (maxVal-minVal)/30\n",
    "    ax.hist(xtarget_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000,  bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7)\n",
    "    ax.hist(xrecon_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"c\")\n",
    "    # ax.hist(xrecon_samples_2[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=20, log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "    ax.hist(xgen_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=np.arange(minVal, maxVal + binwidth, binwidth), log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashdot\")\n",
    "    # ax.hist(xgen_samples_qpu[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=20, log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashed\")\n",
    "    if i == 0:\n",
    "        # ax.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], title=f'{ds[part]}')\n",
    "        ax.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], fontsize=15)\n",
    "    ax.grid(\"True\")\n",
    "    \n",
    "    # Set labels and title for the subplot\n",
    "    # ax.set_xlabel(f'Column {i + 1}')\n",
    "    # ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Layers {HLF_1_electron.relevantLayers[i]} to {HLF_1_electron.relevantLayers[i+1]-1}')\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_per_layer_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b45d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLF_1_electron.relevantLayers = [0,5,10,15,20,25,30,35,40,44]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a442d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=21\n",
    "\n",
    "HLF_1_electron.DrawSingleShower(in_data[idx,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/target_a_{idx}_{modelname}_{arch}_{datascaled}_{part}.png', vmax=1e+3, vmin=1e+0, cmap='rainbow')\n",
    "HLF_1_electron.DrawSingleShower(in_data[idx,:].detach().cpu().numpy(), vmax=1e+4, vmin=1e+0, cmap='rainbow', filename=None ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HLF_1_electron.DrawSingleShower(recon_data[idx,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/recon_a_{idx}_{modelname}_{arch}_{datascaled}_{part}.png', vmax=1e+3, vmin=1e+0, cmap='rainbow')\n",
    "HLF_1_electron.DrawSingleShower(recon_data[idx,:].detach().cpu().numpy(), filename=None, vmax=1e+4, vmin=1e+0, cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f986502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HLF_1_electron.DrawSingleShower(sample_data[idx,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sample_a_{idx}_{modelname}_{arch}_{datascaled}_{part}.png', vmax=1e+3, vmin=1e+0, cmap='rainbow')\n",
    "HLF_1_electron.DrawSingleShower(sample_data[idx,:].detach().cpu().numpy(), filename=None, vmax=1e+4, vmin=1e+0, cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473300b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLF_1_electron.DrawSingleShower(sample_data_qpu[idx,:].detach().cpu().numpy(), filename=f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sample_QPU_a_{idx}_{modelname}_{arch}_{datascaled}_{part}.png', vmax=1e+3, vmin=1e+0, cmap='rainbow')\n",
    "HLF_1_electron.DrawSingleShower(sample_data_qpu[idx,:].detach().cpu().numpy(), filename=None, vmax=1e+4, vmin=1e+0, cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6bd7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "minVal, maxVal = min(xtarget_samples[:30,:].view(-1)), max(xtarget_samples[:30,:].view(-1))\n",
    "binwidth = (maxVal-minVal)/30\n",
    "\n",
    "plt.hist(xtarget_samples[:30,:].view(-1), bins=50, density=True, log=True, histtype='stepfilled', linewidth=2.5, color=\"b\", alpha=0.7)\n",
    "plt.hist(xrecon_samples[:30,:].view(-1), bins=40, density=True, log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"c\")\n",
    "plt.hist(xgen_samples[:30,:].view(-1), bins=40, density=True, log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"orange\", linestyle=\"dashdot\")\n",
    "plt.xlabel(\"Energy per voxel (MeV)\", fontsize=15)\n",
    "\n",
    "plt.ylabel(\"Histogram\", fontsize=15)\n",
    "plt.legend([\"GT\", \"Recon\", \"Sample\", \"Sample w/ QPU\"], fontsize=18)\n",
    "plt.grid(\"True\")\n",
    "plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_per_voxel_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()\n",
    "print(xtarget_samples.view(-1).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

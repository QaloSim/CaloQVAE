{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b0e8727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=4\n",
      "Tue Nov 21 11:00:00 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 43%   59C    P8    11W / 250W |  10987MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 49%   81C    P2   173W / 250W |  10157MiB / 11264MiB |     49%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 30%   32C    P8    20W / 250W |      3MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 30%   35C    P8     1W / 250W |      3MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 31%   34C    P0    55W / 250W |      3MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 44%   71C    P2   153W / 250W |   5695MiB / 11264MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce ...  Off  | 00000000:B1:00.0 Off |                  N/A |\n",
      "| 40%   66C    P2   100W / 250W |  11007MiB / 11264MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce ...  Off  | 00000000:B2:00.0 Off |                  N/A |\n",
      "| 22%   37C    P8    23W / 250W |      3MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     57821      C   python                          10984MiB |\n",
      "|    1   N/A  N/A     58707      C   python                          10154MiB |\n",
      "|    5   N/A  N/A     62522      C   /usr/bin/python                  5692MiB |\n",
      "|    6   N/A  N/A     47931      C   /usr/bin/python                  5692MiB |\n",
      "|    6   N/A  N/A     62523      C   /usr/bin/python                  5312MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=4\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1efecb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[11:00:08.610]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mCaloQVAE                                          \u001b[0mWillkommen!\n",
      "\u001b[1m[11:00:08.614]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mCaloQVAE                                          \u001b[0mLoading configuration.\n"
     ]
    }
   ],
   "source": [
    "import hydra\n",
    "from hydra.utils import instantiate\n",
    "from hydra import initialize, compose\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "os.chdir('/home/' + getpass.getuser() + '/CaloQVAE/')\n",
    "sys.path.insert(1, '/home/' + getpass.getuser() + '/CaloQVAE/')\n",
    "\n",
    "#external libraries\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits\n",
    "torch.manual_seed(32)\n",
    "import numpy as np\n",
    "np.random.seed(32)\n",
    "import matplotlib.pyplot as plt\n",
    "import hydra\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# PyTorch imports\n",
    "from torch import device, load, save\n",
    "from torch.nn import DataParallel\n",
    "from torch.cuda import is_available\n",
    "\n",
    "# Add the path to the parent directory to augment search for module\n",
    "sys.path.append(os.getcwd())\n",
    "    \n",
    "# Weights and Biases\n",
    "import wandb\n",
    "\n",
    "#self defined imports\n",
    "from CaloQVAE import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69321c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 11:00:11,357 dwave.cloud \u001b[1;95mINFO \u001b[1;0m MainThread Log level for 'dwave.cloud' namespace set to 0\n",
      "\u001b[1m[11:00:11.357]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud                                       \u001b[0mLog level for 'dwave.cloud' namespace set to 0\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from data.dataManager import DataManager\n",
    "from utils.plotting.plotProvider import PlotProvider\n",
    "from engine.engine import Engine\n",
    "from models.modelCreator import ModelCreator\n",
    "\n",
    "from utils.plotting.HighLevelFeatures import HighLevelFeatures as HLF\n",
    "HLF_1_photons = HLF('photon', filename='/fast_scratch/QVAE/data/atlas/binning_dataset_1_photons.xml', wandb=False)\n",
    "HLF_1_pions = HLF('pion', filename='/fast_scratch/QVAE/data/atlas/binning_dataset_1_pions.xml', wandb=False)\n",
    "HLF_1_electron = HLF('electron', filename='/fast_scratch/QVAE/data/atlas_dataset2and3/binning_dataset_2.xml', wandb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08aa071a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(version_base=None, config_path=\"configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e2281da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config.yaml': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "\u001b[1m[11:00:17.207]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0mLoading Data\n",
      "\u001b[1m[11:00:29.406]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f20255d79d0>: 80000 events, 625 batches\n",
      "\u001b[1m[11:00:29.409]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f202558f070>: 10000 events, 10 batches\n",
      "\u001b[1m[11:00:29.410]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdata.dataManager                                  \u001b[0m<torch.utils.data.dataloader.DataLoader object at 0x7f21f3193a30>: 10000 events, 10 batches\n",
      "\u001b[1m[11:00:35.195]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mmodels.modelCreator                               \u001b[0mInitialising Model Type GumBoltAtlasCRBMCNNDCond\n",
      "2023-11-21 11:00:35,201 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Using region metadata: [Region(code='na-west-1', name='North America', endpoint='https://na-west-1.cloud.dwavesys.com/sapi/v2/'), Region(code='eu-central-1', name='Europe', endpoint='https://eu-central-1.cloud.dwavesys.com/sapi/v2/')]\n",
      "\u001b[1m[11:00:35.201]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mUsing region metadata: [Region(code='na-west-1', name='North America', endpoint='https://na-west-1.cloud.dwavesys.com/sapi/v2/'), Region(code='eu-central-1', name='Europe', endpoint='https://eu-central-1.cloud.dwavesys.com/sapi/v2/')]\n",
      "2023-11-21 11:00:35,591 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Fetching definitions of all available solvers\n",
      "\u001b[1m[11:00:35.591]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mFetching definitions of all available solvers\n",
      "2023-11-21 11:00:38,971 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Received solver data for 6 solver(s).\n",
      "\u001b[1m[11:00:38.971]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mReceived solver data for 6 solver(s).\n",
      "2023-11-21 11:00:39,118 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage_system4.1')\n",
      "\u001b[1m[11:00:39.118]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage_system4.1')\n",
      "2023-11-21 11:00:39,156 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage2_prototype1.1')\n",
      "\u001b[1m[11:00:39.156]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage2_prototype1.1')\n",
      "2023-11-21 11:00:39,320 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage_system6.3')\n",
      "\u001b[1m[11:00:39.320]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage_system6.3')\n",
      "2023-11-21 11:00:39,950 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Using region metadata: [Region(code='na-west-1', name='North America', endpoint='https://na-west-1.cloud.dwavesys.com/sapi/v2/'), Region(code='eu-central-1', name='Europe', endpoint='https://eu-central-1.cloud.dwavesys.com/sapi/v2/')]\n",
      "\u001b[1m[11:00:39.950]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mUsing region metadata: [Region(code='na-west-1', name='North America', endpoint='https://na-west-1.cloud.dwavesys.com/sapi/v2/'), Region(code='eu-central-1', name='Europe', endpoint='https://eu-central-1.cloud.dwavesys.com/sapi/v2/')]\n",
      "2023-11-21 11:00:40,282 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Fetching definitions of all available solvers\n",
      "\u001b[1m[11:00:40.282]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mFetching definitions of all available solvers\n",
      "2023-11-21 11:00:43,417 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Received solver data for 6 solver(s).\n",
      "\u001b[1m[11:00:43.417]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mReceived solver data for 6 solver(s).\n",
      "2023-11-21 11:00:43,512 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage_system4.1')\n",
      "\u001b[1m[11:00:43.512]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage_system4.1')\n",
      "2023-11-21 11:00:43,537 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage2_prototype1.1')\n",
      "\u001b[1m[11:00:43.537]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage2_prototype1.1')\n",
      "2023-11-21 11:00:43,650 dwave.cloud.client.base \u001b[1;95mINFO \u001b[1;0m MainThread Adding solver StructuredSolver(id='Advantage_system6.3')\n",
      "\u001b[1m[11:00:43.650]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mdwave.cloud.client.base                           \u001b[0mAdding solver StructuredSolver(id='Advantage_system6.3')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40105 28512\n",
      "Initializing NetworkV3\n"
     ]
    }
   ],
   "source": [
    "# config=compose(config_name=\"config.yaml\")\n",
    "config=compose(config_name=\"config.yaml\")\n",
    "wandb.init(project=\"caloqvae\", entity=\"qvae\", config=config, mode='disabled')\n",
    "modelCreator = ModelCreator(cfg=config)\n",
    "dataMgr = DataManager(cfg=config)\n",
    "#initialise data loaders\n",
    "dataMgr.init_dataLoaders()\n",
    "#run pre processing: get/set input dimensions and mean of train dataset\n",
    "dataMgr.pre_processing()\n",
    "\n",
    "if config.model.activation_fct.lower()==\"relu\":\n",
    "    modelCreator.default_activation_fct=torch.nn.ReLU()\n",
    "elif config.model.activation_fct.lower()==\"tanh\":\n",
    "    modelCreator.default_activation_fct=torch.nn.Tanh()\n",
    "else:\n",
    "    logger.warning(\"Setting identity as default activation fct\")\n",
    "    modelCreator.default_activation_fct=torch.nn.Identity()\n",
    "\n",
    "#instantiate the chosen model\n",
    "#loads from file \n",
    "model=modelCreator.init_model(dataMgr=dataMgr)\n",
    "\n",
    "#create the NN infrastructure\n",
    "model.create_networks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80f5251d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[11:00:52.288]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mwandb                                             \u001b[0mWatching\n",
      "/usr/local/lib/python3.8/dist-packages/coffea/util.py:154: FutureWarning: In coffea version v0.8.0 (target date: 31 Dec 2022), this will be an error.\n",
      "(Set coffea.deprecations_as_errors = True to get a stack trace now.)\n",
      "ImportError: coffea.hist is deprecated\n",
      "  warnings.warn(message, FutureWarning)\n",
      "\u001b[1m[11:00:54.891]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engineAtlas                                \u001b[0mSetting up engine Atlas.\n",
      "\u001b[1m[11:00:54.892]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engineCaloV3                               \u001b[0mSetting up engine Calo.\n",
      "\u001b[1m[11:00:54.893]\u001b[0m \u001b[1;95mINFO \u001b[1;0m  \u001b[1mengine.engine                                     \u001b[0mSetting up default engine.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dev = torch.device(\"cuda:0\")\n",
    "wandb.watch(model)\n",
    "engine=instantiate(config.engine, config)\n",
    "engine._config=config\n",
    "#add dataMgr instance to engine namespace\n",
    "engine.data_mgr=dataMgr\n",
    "#add device instance to engine namespace\n",
    "engine.device=dev    \n",
    "#instantiate and register optimisation algorithm\n",
    "engine.optimiser = torch.optim.Adam(model.parameters(),\n",
    "                                    lr=config.engine.learning_rate)\n",
    "#add the model instance to the engine namespace\n",
    "engine.model = model\n",
    "# add the modelCreator instance to engine namespace\n",
    "engine.model_creator = modelCreator\n",
    "engine.model = engine.model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d14d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader,test_loader,val_loader = engine.data_mgr.create_dataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a768c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state(model, run_path, device):\n",
    "        model_loc = run_path\n",
    "        \n",
    "        # Open a file in read-binary mode\n",
    "        with open(model_loc, 'rb') as f:\n",
    "            # Interpret the file using torch.load()\n",
    "            checkpoint=torch.load(f, map_location=device)\n",
    "            \n",
    "            local_module_keys=list(model._modules.keys())\n",
    "            for module in checkpoint.keys():\n",
    "                if module in local_module_keys:\n",
    "                    print(\"Loading weights for module = \", module)\n",
    "                    #if module==\"prior\":\n",
    "                        #print(checkpoint[module])\n",
    "                        #print(checkpoint[module]['_weights'])\n",
    "                        #print(checkpoint[module]['_visible_bias'])\n",
    "                        #print(checkpoint[module]['_hidden_bias'])\n",
    "                        #checkpoint[module]['_weights'] *= 0\n",
    "                        #checkpoint[module]['_weights'] += 1e20\n",
    "                        #checkpoint[module]['_visible_bias'] *= 0\n",
    "                        #checkpoint[module]['_hidden_bias'] += 0.5\n",
    "                        #print(checkpoint[module]['_weights'])\n",
    "                        #print(checkpoint[module]['_visible_bias'])\n",
    "                        #print(checkpoint[module]['_hidden_bias'])\n",
    "                    getattr(model, module).load_state_dict(checkpoint[module])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ceecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_path = \"/home/sgonzalez/CaloQVAE/outputs/2023-10-30/10-30-17/wandb/run-20231030_103022-00s3l2jo/files/GumBoltAtlasCRBMCNNDCond_atlas_default_kl_off_end.pth\"\n",
    "run_path = \"/home/sgonzalez/CaloQVAE/outputs/2023-10-31/13-19-49/wandb/run-20231031_131954-5h3j81dd/files/GumBoltAtlasCRBMCNNDCond_atlas_default_best.pth\"\n",
    "modelname = 'macabre-candle-1372'\n",
    "datascaled = 'scaled'\n",
    "with open(\"/home/sgonzalez/CaloQVAE/outputs/2023-10-31/13-19-49/wandb/run-20231031_131954-5h3j81dd/files/config.yaml\", 'r') as file:\n",
    "    model_config = yaml.safe_load(file)\n",
    "    R = json.loads(model_config[\"_content\"][\"value\"]['engine'].replace(\"'\", \"\\\"\"))['r_param']\n",
    "    reducedata = True if model_config[\"_content\"][\"value\"][\"reducedata\"] == 'True' else False\n",
    "\n",
    "\n",
    "\n",
    "arch = config['model']['model_type']\n",
    "part = config['data']['particle_type']\n",
    "print(arch)\n",
    "print(part)\n",
    "\n",
    "\n",
    "# load_state(model, run_path, 'cuda:{0}'.format(cfg.gpu_list[0]))\n",
    "load_state(model, run_path, dev)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d2632",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtarget_samples = []\n",
    "xrecon_samples = []\n",
    "xgen_samples = []\n",
    "scaled = True\n",
    "entarget_samples = []\n",
    "for xx in val_loader:\n",
    "    in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "    \n",
    "    fwd_output = engine.model((in_data, true_energy), False)\n",
    "    \n",
    "    if scaled:\n",
    "        in_data = torch.tensor(engine._data_mgr.inv_transform(in_data.detach().cpu().numpy()))\n",
    "        \n",
    "        \n",
    "        recon_data = torch.tensor(engine._data_mgr.inv_transform(fwd_output.output_activations.detach().cpu().numpy()))\n",
    "        engine._model.sampler._batch_size = true_energy.shape[0]\n",
    "        sample_energies, sample_data = engine._model.generate_samples(num_samples=true_energy.shape[0], true_energy=true_energy)\n",
    "        engine._model.sampler._batch_size = engine._config.engine.rbm_batch_size\n",
    "        sample_data = torch.tensor(engine._data_mgr.inv_transform(sample_data.detach().cpu().numpy()))\n",
    "        \n",
    "        #Filter out large energies (MeV)\n",
    "        total_energy = in_data.sum(dim=1)\n",
    "        max_eng = 1e25\n",
    "        keep = total_energy<max_eng\n",
    "        in_data = in_data[keep]\n",
    "        true_energy = true_energy[keep]\n",
    "        recon_data = recon_data[keep]\n",
    "        #print(\"sample_data before: \", sample_data.size(), torch.max(sample_data.sum(dim=1)))\n",
    "        sample_total_energy = sample_data.sum(dim=1)\n",
    "        keep = sample_total_energy<max_eng\n",
    "        sample_data = sample_data[keep]\n",
    "        #print(\"in_data: \", in_data.size(), torch.max(in_data.sum(dim=1)))\n",
    "        #print(\"sample_data: \", sample_data.size(), torch.max(sample_data.sum(dim=1)))\n",
    "        #break\n",
    "    \n",
    "    else:\n",
    "        raise Exception(\"Script only supports scaled dataset at the moment...\")\n",
    "\n",
    "\n",
    "    xtarget_samples.append(in_data.detach().cpu())\n",
    "    xrecon_samples.append( recon_data.detach().cpu())\n",
    "    xgen_samples.append( sample_data.detach().cpu())\n",
    "    entarget_samples.append(true_energy.detach().cpu())\n",
    "    \n",
    "    \n",
    "xtarget_samples = torch.cat(xtarget_samples, dim=0)\n",
    "xrecon_samples = torch.cat(xrecon_samples, dim=0)\n",
    "xgen_samples = torch.cat(xgen_samples, dim=0)\n",
    "entarget_samples = torch.cat(entarget_samples, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5154d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_engs = xtarget_samples.sum(dim=1).numpy()\n",
    "recon_engs = xrecon_samples.sum(dim=1).numpy()\n",
    "\n",
    "plt.scatter(target_engs, recon_engs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a15ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfont = {'fontname':'Helvetica'}\n",
    "ds = {'electron-ds2':'Dataset 2'}\n",
    "\n",
    "plt.hist(((xtarget_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=20, log=True, histtype='step', linewidth=2.5, color=\"b\")\n",
    "plt.hist(((xrecon_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=20, log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "plt.hist(((xgen_samples == 0).sum(dim=1)/xtarget_samples.shape[1]).numpy(), bins=20, log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashed\")\n",
    "plt.xlabel(\"Sparsity Index\")\n",
    "plt.ylabel(\"Histogram\")\n",
    "plt.legend([\"GT\", \"Recon\", \"Samples\"])\n",
    "plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "#plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sparsity_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e018ce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLF_1_electron.relevantLayers = [0,5,10,15,20,25,30,35,40,45]\n",
    "# Create a grid of subplots\n",
    "fig, axes = plt.subplots(3,3, figsize=(12, 12), sharey=True, sharex=True, tight_layout=True)\n",
    "fig.text(0.5, 0.0, 'Sparsity Index', ha='center')\n",
    "fig.text(0.0, 0.5, 'Histogram', va='center', rotation='vertical')\n",
    "\n",
    "# Iterate through the columns of X and plot histograms\n",
    "for i,_ in enumerate(HLF_1_electron.relevantLayers[:-1]):\n",
    "    row_index = i // 3  # Determine the row index\n",
    "    col_index = i % 3   # Determine the column index\n",
    "    \n",
    "    ax = axes[row_index, col_index]  # Get the current subplot\n",
    "    \n",
    "    # Plot histogram for the current column\n",
    "    idx = HLF_1_electron.relevantLayers[i+1]*9*16\n",
    "    idxPrev = (HLF_1_electron.relevantLayers[i])*9*16\n",
    "    l = idx - idxPrev\n",
    "    ax.hist(((xtarget_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy(),  bins=20, log=True, histtype='step', linewidth=2.5, color=\"b\")\n",
    "    ax.hist(((xrecon_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy(), bins=20, log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "    ax.hist(((xgen_samples[:, idxPrev:idx] == 0).sum(dim=1)/l).numpy(), bins=20, log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashed\")\n",
    "    ax.legend([\"GT\", \"Recon\", \"Sample\"], title=f'{ds[part]}')\n",
    "    ax.grid(\"True\")\n",
    "    \n",
    "    # Set labels and title for the subplot\n",
    "    # ax.set_xlabel(f'Column {i + 1}')\n",
    "    # ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Layers {HLF_1_electron.relevantLayers[i]} to {HLF_1_electron.relevantLayers[i+1]-1}')\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/sparsity_per_layer_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae98d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(xtarget_samples.sum(dim=1).numpy()/1000, bins=30, log=True, histtype='step', linewidth=2.5, color=\"b\")\n",
    "plt.hist(xrecon_samples.sum(dim=1).numpy()/1000, bins=30, log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "plt.hist(xgen_samples.sum(dim=1).numpy()/1000, bins=30, log=True, histtype='step', alpha=1.0, linewidth=2.5, color=\"orange\", linestyle=\"dashed\")\n",
    "# plt.hist(xtarget_samples.sum(dim=1).numpy()/1000, bins=np.arange(0, 100 + 1,2), log=True, histtype='step')\n",
    "# plt.hist(xrecon_samples.sum(dim=1).numpy()/1000, bins=np.arange(0, 100 + 1,2), log=True, histtype='step')\n",
    "# plt.hist(xgen_samples.sum(dim=1).numpy()/1000, bins=np.arange(0, 100 + 1,2), log=True, histtype='step')\n",
    "# plt.hist(xtarget_samples.sum(dim=1).numpy()/1000, bins=np.arange(100+1, 1000 + 1,10), log=True, histtype='step')\n",
    "# plt.hist(xrecon_samples.sum(dim=1).numpy()/1000, bins=np.arange(100+1, 1000 + 1,10), log=True, histtype='step')\n",
    "# plt.hist(xgen_samples.sum(dim=1).numpy()/1000, bins=np.arange(100+1, 1000 + 1,10), log=True, histtype='step')\n",
    "plt.xlabel(\"energy per event (GeV)\")\n",
    "# plt.xscale('log')\n",
    "\n",
    "plt.ylabel(\"Histogram\")\n",
    "plt.legend([\"GT\", \"Recon\", \"Sample\"])\n",
    "plt.title(f'{ds[part]}')\n",
    "plt.grid(\"True\")\n",
    "#plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def5bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLF_1_electron.relevantLayers = [0,5,10,15,20,25,30,35,40,45]\n",
    "# Create a grid of subplots\n",
    "fig, axes = plt.subplots(3,3, figsize=(12, 12), sharey=True, sharex=False, tight_layout=True)\n",
    "fig.text(0.5, 0.0, 'Energy per event (GeV)', ha='center')\n",
    "fig.text(0.0, 0.5, 'Histogram', va='center', rotation='vertical')\n",
    "\n",
    "# Iterate through the columns of X and plot histograms\n",
    "for i,_ in enumerate(HLF_1_electron.relevantLayers[:-1]):\n",
    "    row_index = i // 3  # Determine the row index\n",
    "    col_index = i % 3   # Determine the column index\n",
    "    \n",
    "    ax = axes[row_index, col_index]  # Get the current subplot\n",
    "    \n",
    "    # Plot histogram for the current column\n",
    "    idx = HLF_1_electron.relevantLayers[i+1]*9*16\n",
    "    idxPrev = (HLF_1_electron.relevantLayers[i])*9*16\n",
    "    l = idx - idxPrev\n",
    "    ax.hist(xtarget_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000,  bins=20, log=True, histtype='step', linewidth=2.5, color=\"b\")\n",
    "    ax.hist(xrecon_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=20, log=True, histtype='step', linewidth=2.5, color=\"m\", linestyle=\"dashdot\")\n",
    "    ax.hist(xgen_samples[:, idxPrev:idx].sum(dim=1).numpy()/1000, bins=20, log=True, histtype='step', linewidth=2.5, color=\"orange\", linestyle=\"dashed\")\n",
    "    ax.legend([\"GT\", \"Recon\", \"Sample\"], title=f'{ds[part]}')\n",
    "    ax.grid(\"True\")\n",
    "    \n",
    "    # Set labels and title for the subplot\n",
    "    # ax.set_xlabel(f'Column {i + 1}')\n",
    "    # ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Layers {HLF_1_electron.relevantLayers[i]} to {HLF_1_electron.relevantLayers[i+1]-1}')\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'/home/javier/Projects/CaloQVAE/figs/{modelname}/energy_per_layer_{modelname}_{arch}_{datascaled}_{part}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64581148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_exp(rbm_vis, rbm_hid):\n",
    "        w, vbias, hbias = engine._model.prior.weights, engine._model.prior.visible_bias, engine._model.prior.hidden_bias\n",
    "        w = w.to(rbm_vis.device) # + torch.zeros((rbm_vis.size(0),) + w.size(), device=rbm_vis.device)\n",
    "        vbias = vbias.to(rbm_vis.device)\n",
    "        hbias = hbias.to(rbm_hid.device)\n",
    "        \n",
    "        vis = rbm_vis.unsqueeze(2).permute(0, 2, 1)\n",
    "        hid = rbm_hid.unsqueeze(2)\n",
    "        \n",
    "        batch_energy = (- torch.matmul(vis, torch.matmul(w, hid)).reshape(-1)\n",
    "                        - torch.matmul(rbm_vis, vbias)\n",
    "                        - torch.matmul(rbm_hid, hbias))\n",
    "        \n",
    "        return batch_energy\n",
    "    \n",
    "def bad_energy_exp(rbm_vis, rbm_hid):\n",
    "        w, vbias, hbias = engine._model.prior.weights, engine._model.prior.visible_bias, engine._model.prior.hidden_bias\n",
    "        w = w.to(rbm_vis.device) * 0 + torch.randn((rbm_vis.size(0),) + w.size(), device=rbm_vis.device)*0.1\n",
    "        vbias = vbias.to(rbm_vis.device)*0\n",
    "        hbias = hbias.to(rbm_hid.device)*0\n",
    "        \n",
    "        vis = rbm_vis.unsqueeze(2).permute(0, 2, 1)\n",
    "        hid = rbm_hid.unsqueeze(2)\n",
    "        \n",
    "        batch_energy = (- torch.matmul(vis, torch.matmul(w, hid)).reshape(-1)\n",
    "                        - torch.matmul(rbm_vis, vbias)\n",
    "                        - torch.matmul(rbm_hid, hbias))\n",
    "        \n",
    "        return batch_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d8c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "energies = []\n",
    "bad_energies = []\n",
    "num_iter_samples = 100\n",
    "\n",
    "for i in range(num_iter_samples):\n",
    "    rbm_vis, rbm_hid = engine._model.sampler.block_gibbs_sampling()\n",
    "    energy_samples = energy_exp(rbm_vis, rbm_hid)\n",
    "    bad_energy_samples = bad_energy_exp(rbm_vis, rbm_hid)\n",
    "    \n",
    "    energies.append(energy_samples)\n",
    "    bad_energies.append(bad_energy_samples)\n",
    "energies_prior = torch.cat(energies, dim=0)\n",
    "bad_energies_prior = torch.cat(bad_energies, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b56f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "xapprox_post_samples = []\n",
    "energies = []\n",
    "\n",
    "scaled = True\n",
    "with torch.no_grad():\n",
    "    for xx in val_loader:\n",
    "        in_data, true_energy, in_data_flat = engine._preprocess(xx[0],xx[1])\n",
    "        #in_data = torch.cat([in_data, true_energy], dim=1)\n",
    "        \n",
    "        _, _, post_samples = engine.model.encoder(in_data, true_energy, False)\n",
    "        rbm_vis = post_samples[0].detach().cpu()\n",
    "        rbm_hid = post_samples[1].detach().cpu()\n",
    "\n",
    "        energy_samples = energy_exp(rbm_vis, rbm_hid)\n",
    "        energies.append(energy_samples)\n",
    "        \n",
    "\n",
    "\n",
    "    energies_post = torch.cat(energies, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf4831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(energies_prior.detach().cpu().numpy(), bins=50, alpha=0.5, density=True, label=\"Best Prior Samples\")\n",
    "#plt.hist(bad_energies_prior.detach().cpu().numpy(), bins=50, alpha=0.5, density=True, label=\"Random Prior Samples\")\n",
    "plt.hist(energies_post.detach().cpu().numpy(), bins=50, alpha=0.5, density=True, label=\" Best Approx. Posterior Samples\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65a50226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.stats.crbm_partition import Stats\n",
    "\n",
    "stats = Stats(model.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c81beb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zais = stats.AIS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7a3a905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1028.1007, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zrais = stats.AIS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e0a289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
